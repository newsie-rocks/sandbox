{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSS reader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://www.w3schools.com/xml/xml_rss.asp\n",
    "- https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feedparser in /opt/homebrew/lib/python3.11/site-packages (6.0.10)\n",
      "Requirement already satisfied: openapi in /opt/homebrew/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/homebrew/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (1.25.0)\n",
      "Requirement already satisfied: qdrant-client in /opt/homebrew/lib/python3.11/site-packages (1.3.1)\n",
      "Requirement already satisfied: uuid in /opt/homebrew/lib/python3.11/site-packages (1.30)\n",
      "Requirement already satisfied: sgmllib3k in /opt/homebrew/lib/python3.11/site-packages (from feedparser) (1.0.0)\n",
      "Requirement already satisfied: inflection>=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from openapi) (0.5.1)\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in /opt/homebrew/lib/python3.11/site-packages (from openapi) (4.17.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.11/site-packages (from beautifulsoup4) (2.4.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (1.56.0)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (1.56.0)\n",
      "Requirement already satisfied: httpx[http2]>=0.14.0 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (0.24.1)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (2.7.0)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.8 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (1.10.9)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=4.0.0 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (4.5.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.14 in /opt/homebrew/lib/python3.11/site-packages (from qdrant-client) (1.26.16)\n",
      "Requirement already satisfied: protobuf<5.0dev,>=4.21.6 in /opt/homebrew/lib/python3.11/site-packages (from grpcio-tools>=1.41.0->qdrant-client) (4.23.3)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from grpcio-tools>=1.41.0->qdrant-client) (67.6.1)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (2023.5.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/homebrew/lib/python3.11/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (0.17.2)\n",
      "Requirement already satisfied: idna in /opt/homebrew/lib/python3.11/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.11/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (1.3.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /opt/homebrew/lib/python3.11/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=2.6.0->openapi) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=2.6.0->openapi) (0.19.3)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /opt/homebrew/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /opt/homebrew/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client) (4.0.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from httpcore<0.18.0,>=0.15.0->httpx[http2]>=0.14.0->qdrant-client) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/homebrew/lib/python3.11/site-packages (from httpcore<0.18.0,>=0.15.0->httpx[http2]>=0.14.0->qdrant-client) (3.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "%pip install feedparser openapi python-dotenv beautifulsoup4 numpy qdrant-client uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSS feeds\n",
    "\n",
    "First, we need to import the RSS feeds.\n",
    "There is a top level `channel`, with:\n",
    "\n",
    "- `title`\n",
    "- `link`\n",
    "- `description`\n",
    "- `category`: optional\n",
    "- `copyright`: optional\n",
    "- `image`: optional, has `url`, `title`, `link`\n",
    "- `language`: optional\n",
    "- `pubDate`: optional\n",
    "- a list of `items`\n",
    "\n",
    "Each item has:\n",
    "\n",
    "- `title`\n",
    "- `link`\n",
    "- `description`\n",
    "- `author`: optional\n",
    "- `comments`: optional\n",
    "- `pubDate`: optional\n",
    "- `enclosure`: optional, `url`, `length`, `type` attributes\n",
    "- `content.encoded`: optional, wrapped in `![CDATA[` + `]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'description': 'Links for the intellectually curious, ranked by readers.',\n",
      "    'items': [   {   'comments': 'https://news.ycombinator.com/item?id=36491514',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36491514\">Comments</a>',\n",
      "                     'link': 'https://neal.fun/deep-sea/',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'The Deep Sea (2019)'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36491704',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36491704\">Comments</a>',\n",
      "                     'link': 'https://saurabhs.org/advanced-macos-commands',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'macOS command-line tools you might not know '\n",
      "                              'about'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36475846',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36475846\">Comments</a>',\n",
      "                     'link': 'https://blogs.loc.gov/loc/2023/06/bloomsday-the-librarys-one-of-a-kind-copy-of-ulysses/',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Bloomsday: The library’s one-of-a-kind copy of '\n",
      "                              '“Ulysses”'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36489847',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36489847\">Comments</a>',\n",
      "                     'link': 'https://github.com/wolfi-dev',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Wolfi: A community Linux OS designed for the '\n",
      "                              'container and cloud-native era'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36492033',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36492033\">Comments</a>',\n",
      "                     'link': 'https://www.gibney.org/a_syntax_for_self-tracking',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'A Syntax for Self-Tracking (2020)'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36480470',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36480470\">Comments</a>',\n",
      "                     'link': 'https://www.visuality.pl/posts/a-simple-guide-to-pessimistic-locking-in-rails',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'A simple guide to pessimistic locking in Rails'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36489288',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36489288\">Comments</a>',\n",
      "                     'link': 'https://rigtorp.se/ringbuffer/',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Optimizing a ring buffer for throughput (2021)'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36491647',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36491647\">Comments</a>',\n",
      "                     'link': 'https://news.ycombinator.com/item?id=36491647',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Text Blaze (YC W21) is hiring a growth engineer '\n",
      "                              'to pioneer LLM driven strategies'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36491735',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36491735\">Comments</a>',\n",
      "                     'link': 'https://twitter.com/paulg/status/1673622294227308546',\n",
      "                     'pubDate': None,\n",
      "                     'title': \"It's weird that people get mocked for changing \"\n",
      "                              'their minds'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36478772',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36478772\">Comments</a>',\n",
      "                     'link': 'https://www.nytimes.com/2023/06/20/magazine/hotel-bars.html',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'The best place to drink is the emptiest bar in '\n",
      "                              'the city'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36488356',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36488356\">Comments</a>',\n",
      "                     'link': 'https://akashrajpurohit.com/blog/build-your-own-docker-with-linux-namespaces-cgroups-and-chroot-handson-guide/',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Build your own Docker with Linux namespaces, '\n",
      "                              'cgroups, and chroot'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36480200',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36480200\">Comments</a>',\n",
      "                     'link': 'http://www.solipsys.co.uk/new/UnexpectedInteractionOfFeatures.html?wf26hn',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Unexpected Interaction of Features'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36480687',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36480687\">Comments</a>',\n",
      "                     'link': 'https://mofi.loud.red/',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Show HN: Mofi –\\xa0Content-aware fill for audio '\n",
      "                              'to change a song to any duration'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36488735',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36488735\">Comments</a>',\n",
      "                     'link': 'https://x0axz.com/blog/autograd.html',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Show HN: An Interactive Guide to Teach '\n",
      "                              'Derivatives and Backpropagation'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36491677',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36491677\">Comments</a>',\n",
      "                     'link': 'https://phys.org/news/2023-06-ninth-dedekind-scientists-long-known-problem.html',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Ninth Dedekind number discovered: long-known '\n",
      "                              'problem in mathematics solved'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36478854',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36478854\">Comments</a>',\n",
      "                     'link': 'https://spin.atomicobject.com/2023/06/26/dexec-docker/',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Working with Docker containers with the dexec '\n",
      "                              'bash script'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36487574',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36487574\">Comments</a>',\n",
      "                     'link': 'https://eatrightindia.gov.in/dart/',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Detect Food Adulteration with Easy Home Tests'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36469086',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36469086\">Comments</a>',\n",
      "                     'link': 'https://marctenbosch.com/news/2023/03/4d-toys-update-v-1-8-rotating-the-3d-slice-2d-faces-projections-marble-scenes-and-many-more/',\n",
      "                     'pubDate': None,\n",
      "                     'title': '4D Toys Update 8: Rotating the 3D Slice, 2D '\n",
      "                              'Faces Projections, Marble Scenes'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36479683',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36479683\">Comments</a>',\n",
      "                     'link': 'https://people.inf.ethz.ch/omutlu/pub/RowPress_isca23.pdf',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'RowPress: Amplifying read disturbance in modern '\n",
      "                              'DRAM chips [pdf]'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36488871',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36488871\">Comments</a>',\n",
      "                     'link': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'LLM Powered Autonomous Agents'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36486512',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36486512\">Comments</a>',\n",
      "                     'link': 'https://www.dialup.net/wingpt/tls.html',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Modern TLS/SSL on 16-bit Windows'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36485597',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36485597\">Comments</a>',\n",
      "                     'link': 'https://doubleagent.net/2023/05/21/a-car-battery-monitor-tracking-your-location',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Discovering that a Bluetooth car battery '\n",
      "                              'monitor is siphoning location data'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36490784',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36490784\">Comments</a>',\n",
      "                     'link': 'https://barrgroup.com/embedded-systems/how-to/network-processors',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'How Network Processors Work'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36480230',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36480230\">Comments</a>',\n",
      "                     'link': 'https://news.ycombinator.com/item?id=36480230',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Launch HN: Argonaut (YC S21) – Easily Deploy '\n",
      "                              'Apps and Infra to AWS and GCP'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36480460',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36480460\">Comments</a>',\n",
      "                     'link': 'https://vivaldi.com/blog/how-to/5-reasons-why-a-browser-and-mail-combination-is-worth-it/',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Why a browser and mail combination is worth it'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36478206',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36478206\">Comments</a>',\n",
      "                     'link': 'https://matan-h.com/google-has-a-secret-browser-hidden-inside-the-settings/',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Google has a secret browser hidden inside the '\n",
      "                              'settings'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36484502',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36484502\">Comments</a>',\n",
      "                     'link': 'https://www.nature.com/articles/d41586-023-02065-y',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Hunter-gatherer lifestyle fosters thriving gut '\n",
      "                              'microbiome'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36475083',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36475083\">Comments</a>',\n",
      "                     'link': 'http://meta-studies.net/pmwiki/pmwiki.php?n=Site.Introduction',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'Things That Count'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36475755',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36475755\">Comments</a>',\n",
      "                     'link': 'https://time.com/6286931/how-to-steal-a-masterpiece-advice-from-the-worlds-greatest-art-thief/',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'How to steal a masterpiece: Advice from the '\n",
      "                              'world’s greatest art thief'},\n",
      "                 {   'comments': 'https://news.ycombinator.com/item?id=36487883',\n",
      "                     'content_encoded': None,\n",
      "                     'description': '<a '\n",
      "                                    'href=\"https://news.ycombinator.com/item?id=36487883\">Comments</a>',\n",
      "                     'link': 'https://opnsense.org/',\n",
      "                     'pubDate': None,\n",
      "                     'title': 'OPNsense: Open-source security platform'}],\n",
      "    'link': 'https://news.ycombinator.com/',\n",
      "    'title': 'Hacker News'}\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import pprint\n",
    "\n",
    "def extract_feed(url: str):\n",
    "    \"\"\"\n",
    "    Extracts the feed from the given URL\n",
    "    \"\"\"\n",
    "    parsed_feed = feedparser.parse(f)\n",
    "    feed = {}\n",
    "    \n",
    "    feed['title'] = parsed_feed.feed.get('title', None)\n",
    "    feed['description'] = parsed_feed.feed.get('description', None)\n",
    "    feed['link'] = parsed_feed.feed.get('link', None)\n",
    "    if 'image' in parsed_feed.feed:\n",
    "        feed['image_title'] = parsed_feed.feed.image.get('title', None)\n",
    "        feed['image_link'] = parsed_feed.feed.image.get('link', None)\n",
    "    feed['items'] = []\n",
    "\n",
    "    for e in parsed_feed.entries:\n",
    "        item = {}\n",
    "        item['title'] = e.get('title', None)\n",
    "        item['link'] = e.get('link', None)\n",
    "        item['description'] = e.get('description', None)\n",
    "        item['pubDate'] = e.get('pubDate', None)\n",
    "        item['comments'] = e.get('comments', None)\n",
    "        item['content_encoded'] = e.get('content.encoded', None)\n",
    "        if 'image' in e:\n",
    "            item['image_title'] = e.image.get('title', None)\n",
    "            item['image_link'] = e.image.get('link', None)\n",
    "        feed['items'].append(item)\n",
    "\n",
    "    return feed    \n",
    "\n",
    "feeds_list = ['https://news.ycombinator.com/rss']\n",
    "# , 'https://themacrocompass.substack.com/feed']\n",
    "feeds = []\n",
    "for f in feeds_list:\n",
    "    feed = extract_feed(f)\n",
    "    pprint.pprint(feed, indent=4)\n",
    "    feeds.append(feed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the text content with `BeautifulSoup` and `lxml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hacker News\n",
      "---\n",
      "The Deep Sea (2019)\n",
      "The Deep SeaThe Deep SeaMade withby Neal AgarwalManateeBottlenose Dolphin DiveGreen Sea TurtleBeluga WhaleSea LionVelvet CrabStaghorn CoralKiller WhaleBarramundiGreat BarracudaSpotted BassStriped BassBlack DrumBlue FishSpiny dogfishDentexMahi-mahiFlounderBull SharkGreat White SharkBlue SharkGummy SharkMako SharkSunfishHumanAtlantic MackerelQueen SnapperPelagic StingrayDeepest dive of a NarwhalFrilled SharkViperfishAnglerfishLeatherback Sea TurtleOlive Ridly Sea TurtleSea PenDragonfishOrange RoughyWolf EelSwordfishChain CatsharkAtlantic CodPacific CodEuropean pilchardAtlantic SalmonChinook SalmonBlue TangClown FishHaddockVampire SquidJapanese Spider CrabFirefly SquidSperm Whale DiveYeti CrabBig Red JellyfishJewel SquidCockatoo SquidPhronimaBubblegum CoralGiant IsopodCoelacanthColossal SquidGoblin SharkChimaerasBlack SwallowerMonkfishGiant Pacific OctopusSixgill SharkEmperor Penguin DiveElephant Seal DiveBaird's Beaked WhaleLeptoserisGigantactisBigeye TunaBamboo CoralNautilusHatchetfishGiant OarfishGiant Tube WormTelescope OctopusBarreleye FishSquidwormSea AngelMarrus orthocannaScaly-foot SnailVigtorniella WormTerrible Claw LobsterVenus Flytrap Sea AnemoneLeafy Sea DragonHeadless Chicken FishGreenland HalibutKing CrabGreenland SharkBlobfishZombie WormPolar BearKelpThick-Billed Murre DiveBarnacleAt 332 meters, this is the deepest any human has ever scuba dived. Set by Ahmed Gabr in 2014.No sunlight is able to reach this deep.Many deep-sea creatures cope by creating light themselves - also known as bioluminescence.Narwhals dive to this depth up to 15 times a day in search for food.The Japanese Spider Crab is the largest known crab with a maximum leg span of 3.8m.Coelacanths were thought to be extinct until found alive in 1938.Leatherback Sea Turtles are the oldest sea turtle species.Giant Oarfish can grow up to 11m long.Sixgill Sharks spend the day in deep waters and the night in shallow waters. They can be found all over the world.Telescope Octopus are almost completely transparent and have unique protruding eyes.Barreleye Fish have a transparent head that allows their eyes to collect more light.Black Swallowers can swallow entire fish whole - even those vastly larger than themselves!Vampire Squids eat marine snow - organic material that falls from shallower waters.Headless Chicken Fish are sea cucumbers with wing-like fins that allow them to swim.Colossal Squid are the largest known squid species. They can reach a length of 10 meters and weigh up to 700 kg.The Orange Roughy can live up to 200 years. Deep sea life often have elongated life spans.Meals are rare in the deep sea. Deep sea creatures have adapted to this - one Giant Isopod in captivity went five years without eating.Many deep sea species use the color red as camouflage since it's the first color to leave the spectrum as you dive deeper.Goblin Sharks are known as \"living fossils\" because they're the only living species of a lineage that has existed for 125 million years.Is it a squid, or a worm? It’s a worm.Sea Angels are majestic sea slugs that use wings to propel themselves.The Scaly-Foot Snail gets its name from the iron plates on its foot and the iron shell it makes out of Iron Sulphide.Anglerfish have a large bioluminescent lure used to attract prey in the darkness.Giant Tube Worms get their nutrients from hydrothermal vents.Hydrothermal vents are formed from seawater passing through extremely hot volcanic rocks. They release heavy metals that are toxic to most animals.But even in those extreme conditions specialized life finds a way to survive.Yeti Crabs live on hydrothermal vents.The Midnight ZoneThe Twilight ZoneGulper EelAmphipodaPatagonian ToothfishFlabby WhalefishAtolla JellyfishFangtoothTitanic WreckageCarideaCuvier's Beaked Whale DiveLizardfishHarp SpongeDumbo OctopusCosmic JellyfishBrittle StarSea PigMegamouth SharkStoplight LoosejawTripod FishFaceless FishCookiecutter SharkGlass SpongeAbyssal SpiderfishThis is the average depth of the ocean.But in some places it goes deeper.Much deeper.Cuvier's Beaked Whales are the deepest diving mammals.On April 14th, 1912 the Titanic sank to its final resting place at a depth of 3,800 meters.This is the deepest point of the Manila Trench in the South China Sea.Patagonian Toothfish have antifreeze proteins in its tissues to prevent freezing in sub zero temperatures.Megamouth sharks are one of the largest growing shark species with some reaching 7 meters long.The temperature here is near freezing and very few animals can survive the extreme pressure.This shark takes cookie-shaped chunks out of its prey.The Abyssal ZoneComb JellyHadal SnailfishUSS Johnston ShipwreckGrenadierCusk EelChitonYou have scrolled the height of Mount Everest.Comb Jellies have been around for 500 million years. Despite looking like jellyfish, they are not closely related.This is the lowest point of the Puerto Rico Trench.This is the deepest point of the Java Trench in the Indian Ocean.The USS Johnston sank in WWII and is the deepest shipwreck ever found.More people have been to the Moon than the Hadal Zone.Most of the Hadal Zone takes place in deep sea trenches.Deep sea trenches form by a process called \"subduction\" where the Earth's tectonic plates meet and push together.The deep sea can be a lonely place.Life here is sparse - the extreme conditions make survival difficult.But still not impossible.So little is known about life in these deep environments. Almost every expedition uncovers something new.The Hadal ZoneHadal AmphipodMany probes and submarines have been lost trying to reach the deepest parts of the ocean.On January 23rd, 1960, about 9 years before the moon landing, humans went where they never had before.Two men, Jacques Piccard and Don Walsh, onboard the submarine Trieste slowly descended into the Mariana Trench.Their goal was to reach The Challenger Deep - the deepest point in the ocean.The submarine used a re-breather system that would later be used in spacecraft. There was barely enough space inside the pressure sphere for both of them.The immense pressure of the deep sea means any mistake would mean certain death.During the descent, one of the window panes cracked and shook the entire vessel.Nevertheless, they continued.Even at these unfathomable depths, Jacques and Don could still see life out the window. Life can survive unimaginable environments.After 4 hours and 47 minutes of anxiety and claustrophobia...They succeeded and became the first humans to reach the deepest point in the ocean.The Challenger Deep0 METERS DEEPThe Deep SeaMade withbyNeal AgarwalSpecial thanks to Dr. Harri Pettitt-Wade for help with editing and feedback.Buy me a coffee!More posts on Neal.fun\n",
      "---\n",
      "macOS command-line tools you might not know about\n",
      "Advanced macOS Commands - saurabhs.orgSaurabh😎Advanced macOS Command-Line ToolsmacOS is fortunate to have access to the huge arsenal of standard Unix tools. There are also a good number of macOS-specific command-line utilities that provide unique macOS functionality. To view the full documentation for any of these commands, runman <command>.caffeinate- set Mac sleep behaviorRunningcaffeinatewith no flags or arguments prevents your Mac from going to sleep as long as the command continues to run.caffeinate -u -t <seconds>prevents sleep for the specified number of seconds.Adding the-dflag also prevents the display from going to sleep.Specifying an existing process with-w <pid>automatically exits the caffeinate command once the specified process exits.Passing a command withcaffeinate <command>starts the given command in a new process and will prevent sleep until that process exits.textutil- document file convertertextutilcan convert files to and from Microsoft Word, plain text, rich text, and HTML formats.textutil -convert html journal.docconvertsjournal.docintojournal.html.The possible values for-convertare:txt,html,rtf,rtfd,doc,docx.mdfind- search with Spotlightmdfind <query>performs a keyword-based Spotlight search with the given query.mdfind kMDItemAppStoreHasReceipt=1finds all apps installed from the Mac App Store.mdfind -name <name>searches for all files matching the given name.The-onlyin <dir>flag restricts the search to the given directory.networkQuality- measure Internet speedRunnetworkQualityto run an Internet speed test from your Mac.Add the-vflag to view more detailed information.Use the-iflag to run the network test on a specific network interface.screencapture- take screenshotsscreencapture -ctakes a screenshot and copies it to the clipboard.screencapture <file>takes a screenshot and saves it to the given file.Add the-T <seconds>flag to take the screenshot after the given delay in seconds.pbcopy,pbpaste- interact with system clipboard<command> | pbcopycopies the output of the command to the clipboard.pbpasteoutputs the contents of the clipboard to stdout.taskpolicy- control scheduling of processestaskpolicy -b <command>starts executing the given command in the background. On Apple silicon Macs, the process will only run on the efficiency cores.taskpolicy -b -p <pid>downgrades an existing process to run in the background.taskpolicy -B -p <pid>removes the specified process from running in the background. On Apple silicon Macs, the process may now run on the efficiency or performance cores. Note that this only works on processes that have been downgraded to the background, and not processes that started in the background.taskpolicy -s <command>starts the given command in the suspended state. This is useful to allow a debugger to attach to the process right at the start of execution.say- text-to-speech enginesay <message>announces the given message.say -f input.txt -o output.aiffwill create an audiobook from the given text file.sips- image manipulationsips -z <height> <width> <image>resizes the specified image, ignoring the previous aspect ratio.sips -Z <size> <image>resizes the largest side of the specified image, preserving the aspect ratio.sips -r <degrees> <image>rotate the image by the specified degrees.open- open files and applicationsopen -a <app> <file>opens the given file with the specified application.open .opens the current directory in a new Finder window.pmset- configure power managementpmset -gprints all available power configuration information.pmset -g assertionsdisplays information about power-related assertions made by other processes. This can be useful for finding a process that is preventing your Mac from going to sleep.pmset -g thermlogdisplays information about any processes that have been throttled (useful when running benchmarks).pmset displaysleepnowimmediately puts the display to sleep without putting the rest of the system to sleep.pmset sleepnowimmediately puts the entire system to sleep.networksetup- configure network settingsnetworksetup -listnetworkserviceorderprints a list of available network services.networksetup -getinfo <networkservice>prints information about the specified network service.networksetup -getdnsservers <networkservice>prints the DNS servers for the specified network service.networksetup -setairportnetwork <device> <network> [password]joins the specified Wi-Fi network. (In most cases, the <device> argument should be \"en0\".)qlmanage- manage Quick Lookqlmanage -p <file>opens a Quick Look preview window of the given file.qlmanage -mprints status information about the Quick Look server process.qlmanage -rrestarts the Quick Look server process.qlmanage -r cacheresets the Quick Look thumbnail cache.softwareupdate- manage OS updatessoftwareupdate --listprints out available software updates.sudo softwareupdate -iainstalls all available updates.softwareupdate --fetch-full-installer --full-installer-version <version>tries to download the full installer of the specified macOS version to /Applications.\n",
      "---\n",
      "Bloomsday: The library’s one-of-a-kind copy of “Ulysses”\n",
      "Bloomsday! The Library’s One-of-a-Kind Copy of “Ulysses” | TimelessTop of pageSkip to contentTimelessStories from the Library of CongressISSN 2836-9459Share & Subscribe to this blogThis BlogEverythingAudio RecordingsBooksFilms, VideosLegislationManuscripts/Mixed MaterialsMapsNotated MusicNewspapersPeriodicalsPersonal NarrativesPhotos, Prints, DrawingsSoftware, E-ResourcesArchived Web SitesWeb Pages3-D ObjectsGoHomeBloomsday! The Library's One-of-a-Kind Copy of \"Ulysses\"MenuAbout this blogCategoriesAbraham LincolnAfrican AmericanAfrican American HistoryAfrican and Middle Eastern DivisionAlexander HamiltonAmerican Folklife CenterAmerican RevolutionArab/Arab AmericanAsian AmericanAsian American HistoryAsian DivisionAudiovisualBaseballBloggingBooksBy the PeopleCapitol HillCatalogingCenter for the BookChristmasCivil RightsCivil WarCollectionsComicsConcertsCongressCongress BlogsCopyrightCOVID-19Crime and PunishmentCrime Classics SeriesCuratorsEducationEventsExhibitionsFarm Security Administration PhotographsFilmFolksonomiesFree to Use and ReuseGazetteGenealogyGeography and Maps DivisionGershwin Prize for Popular SongHalloweenHerenciaHispanic and LatinoHispanic DivisionHistoryHolocaustInflueza/Covid-19Jay I. Kislak CollectionJewish American HistoryJunior Fellows ProgramKidsKluge CenterLavine/Ken Burns Prize for FilmLaw LibraryLC Web siteLCMLessing J. Rosenwald CollectionLGBTQLibrariesLibrary of Congress Crime ClassicsLibrary of Congress Prize for American FictionLibrary Work and EmployeesLiteracyLiteracy AwardsManuscriptsMapsMusicMy JobMystery Photo ContestNational Ambassador for Young People's LiteratureNational Audio-Visual Conservation CenterNational Book FestivalNational Film Preservation BoardNational Film RegistryNational Library Service (NLS)National Recording RegistryNative AmericansNew OnlineNew Visitors ExperienceNewsNewspapersPerforming ArtsPhotosPic of the WeekPinterestPodcastsPoetryPreservationPreservation and ConservationRare Book and Special CollectionsRare Book of the MonthResearcher StoriesScienceShakespeareSocial MediaTechnologyTechnology & Business DivisionThanksgivingTheaterThomas JeffersonThomas Jefferson BuildingToday in HistoryU.S. Poet LaureateU.S. PresidentsUncategorizedVeterans History ProjectVideoWashington DCWomen's HistoryWorld War IWorld War IIWritersARCHIVESJune 2023May 2023April 2023March 2023February 2023January 2023December 2022November 2022October 2022September 2022August 2022July 2022June 2022May 2022April 2022March 2022February 2022January 2022December 2021November 2021October 2021September 2021August 2021July 2021June 2021May 2021April 2021March 2021February 2021January 2021December 2020November 2020October 2020September 2020August 2020July 2020June 2020May 2020April 2020March 2020February 2020January 2020December 2019November 2019October 2019September 2019August 2019July 2019June 2019May 2019April 2019March 2019February 2019January 2019December 2018November 2018October 2018September 2018August 2018July 2018June 2018May 2018April 2018March 2018February 2018January 2018December 2017November 2017October 2017September 2017August 2017July 2017June 2017May 2017April 2017March 2017February 2017January 2017December 2016November 2016October 2016September 2016August 2016July 2016June 2016May 2016April 2016March 2016February 2016January 2016December 2015November 2015October 2015September 2015August 2015July 2015June 2015May 2015April 2015March 2015February 2015January 2015December 2014November 2014October 2014September 2014August 2014July 2014June 2014May 2014April 2014March 2014February 2014January 2014December 2013November 2013October 2013September 2013August 2013July 2013June 2013May 2013April 2013March 2013February 2013January 2013December 2012November 2012October 2012September 2012August 2012July 2012June 2012May 2012April 2012March 2012February 2012January 2012December 2011September 2011August 2011July 2011June 2011May 2011April 2011March 2011February 2011January 2011December 2010November 2010October 2010September 2010August 2010July 2010June 2010May 2010April 2010March 2010February 2010January 2010December 2009November 2009October 2009September 2009August 2009July 2009June 2009May 2009April 2009March 2009February 2009January 2009December 2008November 2008October 2008September 2008August 2008July 2008June 2008May 2008April 2008March 2008February 2008January 2008December 2007November 2007October 2007September 2007August 2007July 2007June 2007May 2007April 2007Bloomsday! The Library’s One-of-a-Kind Copy of “Ulysses”June 16, 2023Posted by:Neely TuckerShare this post:James Joyce in 1915. Photo: Alex Ehrenzweig. Public domain, Wikimedia Commons.It’s Bloomsday, the annual celebration of James Joyce’s landmark modernist masterpiece, “Ulysses.” Published 101 years ago, Joyce’s book famously examines one day — June 16, 1904 — in the life of Leopold Bloom of Dublin, Ireland. The book’s stream-of-consciousness style and dense symbolism have made it a cult favorite to fans around the world, who celebrate today with readings, festivals, dressing in period costumes and, if possible, wandering around Dublin themselves. Pubs do bang-up business.Across the Atlantic, the Library has some of the most extraordinary copies of the book ever printed. But first, a quick recap:Paris, 1922: Sylvia Beach, proprietor of Shakespeare and Company, the famous bookshop, decides to publish “Ulysses.” This is risky because pre-publication excerpts had been declared obscene by U.S. courts.Beach limited her first edition to 1,000 copies. All were numbered, and 100 were signed by Joyce. It was a brilliant decision. The novel went on to be regarded as one of the premier literary works of the 20th century and Joyce one of the era’s great authors. Copies of that first print run became some of the most sought-after books of the age. (A first edition famously sold at auction in London in 2009 for the equivalent today of of $636,000; signed and personal copies have sold for much more.)The bespoke calfskin cover of the LIbrary’s edition of “Ulysses.” Photo: Shawn Miller.And yet all of that scarcely begins to describe the first edition of “Ulysses” acquired in 2021 by the Library. It’s a marvel to behold: Copy #361 is bound in bespoke calfskin, front and back covers initialed by the author, the title page inscribed by Joyce to a friend, with inserts that include Joyce’s guide to deciphering the book.Two other “Ulysses” first editions were included in the acquisition ofthe Aramont Library(the property of a private owner), including the signed #1 copy — the first copy of the first edition, an almost unbelievable find of such an important book.“All of these copies are exceptional, but there is one that is truly unique,” said Stephanie Stillo of the Rare Book and Special Collections Division, indicating the custom-made copy.Joyce, a native of Ireland, spent years laboring over the complicated novel while living in Europe. It’s modeled on Homer’s epic poem “The Odyssey,” told in 18 chapters in almost bewildering fashion. One sentence runs 4,391 words. As the British Library sums it up “… each episode is represented by a different organ of the body, colour, symbol, technique, art, place and particular time of day.”Beach, a friend of many modernist artists, published the first copies on Feb. 2, 1922, Joyce’s 40thbirthday.While finishing the book, Joyce befriended a young French admirer, Jacques Benoist-Méchin. Just 20 years old, Benoist-Méchin was a promising intellectual who helped Joyce finalize the book’s famous last sentences, a soliloquy by the fictional Molly Bloom.They apparently worked together to make #361 an unforgettable copy. Joyce inscribed the copy to him. A sketch map of Dublin adorned the front, as it was the book’s setting. The back cover was a map of Gibraltar. This was a nod to Benoist-Méchin’s help in interpreting Molly’s famous closing scene; in the book, she is born in Gibraltar.Detail of Joyce’s explanation of the book’s themes and symbols. Photo: Shawn Miller.But the real gems were at the back.A four-page scheme, or outline, explains the book’s convoluted plot and its symbolism, including Joyce’s notation that the book was based on “The Odyssey,” without which the world might never have noticed the connection. (Only seven of these outlines are known to exist.) Then, another stunner — a full-color foldout anatomical chart of a human body, likely taken from a medical textbook, annotated in red ink, noting how each body part relates to the plot.Tucked inside the back cover is this drawing of a human body, with notes showing how various body parts correspond to different chapters. Photo: Shawn Miller.Finally, tucked inside this copy are portraits of Joyce (likely taken by famed photographer Man Ray) and Beach. There’s also a letter from Joyce to Benoist-Méchin.The final twist: Benoist-Méchin grew into a prominence of his own as a historian and journalist who enthusiastically collaborated with Nazi Germany’s takeover of France in World War II. He was condemned to death as a traitor after the war and eventually had his sentence commuted after seven years in prison.All of that 20th-century history, bound in one completely original book. It’s something to behold.The rear cover of the book features this map of Gibraltar. Photo: Shawn Miller.Subscribeto the blog— it’s free!CategoriesLCMRare Book and Special CollectionsWritersSee All CommentsAdd a CommentCancel replyThis blog is governed by the general rules of respectful civil discourse. You are fully responsible for everything that you post. The content of all comments is released into the public domain unless clearly stated otherwise. The Library of Congress does not control the content posted. Nevertheless, the Library of Congress may monitor any user-generated content as it chooses and reserves the right to remove content for any reason whatever, without consent. Gratuitous links to sites are viewed as spam and may result in removed comments. We further reserve the right, in our sole discretion, to remove a user's privilege to post content on the Library site. Read ourComment and Posting Policy.Required fields are indicated with an * asterisk.Name (no commercial URLs)*Email (will not be published)*Comment:ΔPrevious post:Ralph Ellison’s “Juneteenth” Lives on at the LibraryBlog HomeNext post:Historical Newspapers Reveal Hidden LGBTQ+ HistoryBack to topDisclaimer & PoliciesThese blogs are governed by the general rules of respectful civil discourse. By commenting on our blogs, you are fully responsible for everything that you post.                  The content of all comments is released into the public domain unless clearly stated otherwise. The Library of Congress does not control the content posted.                  Nevertheless, the Library of Congress may monitor any user-generated content as it chooses and reserves the right to remove content for any reason whatever,                  without consent. Gratuitous links to sites are viewed as spam and may result in removed comments. We further reserve the right, in our sole discretion, to                  remove a user's privilege to post content on the Library site.Read our Comment and Posting Policy.Links to external Internet sites on Library of Congress Web pages do not constitute the Library's endorsement of the content of their Web sites or of their policies or products. Please read our Standard Disclaimer.Please read our Standard Disclaimer.Please read our Comment & Posting Policy.Connect with the LibraryVisit the Library of Congress WebsiteFind us onEmailSubscribe & commentRSS & E-MailBlogsDownload & playPodcastsWebcastsiTunesUExternalQuestionsAsk a LibrarianContact UsAboutPressCareersDonateInspector GeneralLegalAccessibilityExternal Link DisclaimerUSA.govOpens in a new window\n",
      "---\n",
      "Wolfi: A community Linux OS designed for the container and cloud-native era\n",
      "Wolfi · GitHubSkip to contentToggle navigationSign upwolfi-devProductActionsAutomate any workflowPackagesHost and manage packagesSecurityFind and fix vulnerabilitiesCodespacesInstant dev environmentsCopilotWrite better code with AICode reviewManage code changesIssuesPlan and track workDiscussionsCollaborate outside of codeExploreAll featuresDocumentationGitHub SkillsBlogSolutionsForEnterpriseTeamsStartupsEducationBy SolutionCI/CD & AutomationDevOpsDevSecOpsCase StudiesCustomer StoriesResourcesOpen SourceGitHub SponsorsFund open source developersThe ReadME ProjectGitHub community articlesRepositoriesTopicsTrendingCollectionsPricingIn this organizationAll GitHub↵Jump to↵No suggested jump to resultsIn this organizationAll GitHub↵Jump to↵SearchAll GitHub↵Jump to↵In this organizationAll GitHub↵Jump to↵Sign inSign upYou signed in with another tab or window.Reloadto refresh your session.You signed out in another tab or window.Reloadto refresh your session.You switched accounts on another tab or window.Reloadto refresh your session.WolfiWolfi OS github home.265followershttps://wolfi.devVerifiedWe've verified that the organizationwolfi-devcontrols the domain:wolfi.devLearn more about verified organizationsOverviewRepositoriesDiscussionsProjectsPackagesPeopleMoreOverviewRepositoriesDiscussionsProjectsPackagesPeopleREADME.mdWolfi OSWolfi is a community Linux OS designed for the container and cloud-native era. Chainguard started the Wolfi project to enable buildingChainguard Images, our collection of curateddistrolessimages that meet the requirements of a secure software supply chain. This required a Linux distribution with components at the appropriate granularity and with support for bothglibcandmusl, something that was not yet available in the cloud-native Linux ecosystem.Wolfi is a stripped-down distro designed for the cloud-native era. It doesn't have a kernel of its own, instead relying on the environment (such as the container runtime) to provide one. This separation of concerns in Wolfi means it is adaptable to a range of environments.Wolfi FeaturesWolfi, whose name was inspired by theworld's smallest octopus, has some key features that differentiates it from other distributions that focus on container/cloud-native environments:Provides a high-quality, build-time SBOM as standard for all packagesPackages are designed to be granular and independent, to support minimal imagesUses the proven and reliable apk package formatFully declarative and reproducible build systemDesigned to support glibc and muslWhere's the Source?bootstrap-stage1contains the stage1 bootstrap repository which is used with Alpine.bootstrap-stage2contains the stage2 bootstrap repository which is used with Alpine and the stage1 toolchain to bootstrap stage3.bootstrap-stage3contains the stage3 bootstrap repository which is a micro GNU/Linux distribution built with stage2 and used to bootstrap Wolfi.oscontains the core Wolfi OS repository.FAQWhat is Wolfi and how does it compare to Alpine?Wolfi is a Linuxundistrodesigned from the ground up to support newer computing paradigms such as containers. Although Wolfi has a few similar design principles as Alpine (such as using apk), it is a different distribution that is  focused on supply chain security. Unlike Alpine, Wolfi does not currently build its own Linux kernel, instead relying on the host environment (e.g. a container runtime) to provide one.Is Wolfi free to use?Yes, Wolfi is free and will always be.Can I use Wolfi on the Desktop?No. Wolfi is an un-distro, or distroless base to be used within the container / OCI ecosystem. Desktop distributions require additional software that is out of scope for Wolfi's roadmap.Who maintains Wolfi?Wolfi was created and is currently maintained byChainguard.What are the plans for long-term Wolfi governance?We intend for Wolfi to be a community-driven project, which means over time it will have multi-vendor governance and maintainers. For now we're focused on building the project and community, and will revisit this in several months when a community has formed.Where can I get security feeds for Wolfi?SeeSECURITY.mdfor information about reporting security incidents concerning and consuming security data about Wolfi.PinnedosPublicMain package repository for production Wolfi imagesShell39365RepositoriesTypeSelect typeAllPublicSourcesForksArchivedMirrorsTemplatesLanguageSelect languageAllGoHCLMakefileShellSortSelect orderLast updatedNameStarsosPublicMain package repository for production Wolfi imagesShell3936586(3 issues need help)36UpdatedJun 27, 2023advisoriesPublicSecurity advisory data for WolfiShell6Apache-2.0700UpdatedJun 27, 2023toolsPublicVarious tools, images, etc. to support the Wolfi OSS projectHCL10Apache-2.0722UpdatedJun 26, 2023wolfictlPublicA CLI used to work with the Wolfi OSS projectGo29Apache-2.01915(1 issue needs help)12UpdatedJun 19, 2023dagPublicGenerate DAGs of Melange packages4Apache-2.0401UpdatedMar 27, 2023communityPublicDocuments and tools powering the Wolfi OS community12Apache-2.0220UpdatedMar 8, 2023secdbPublicTool for generating Wolfi security databasesGo7Apache-2.0301UpdatedFeb 25, 2023wolfi-update-mapperPublic1100UpdatedFeb 24, 2023container-entrypointPublicSimple script for use as entrypoint to a containerShell5Apache-2.0100UpdatedFeb 21, 2023bootstrap-stage3PublicStage3 bootstrap for WolfiMakefile3602UpdatedFeb 17, 2023View all repositoriesPeopleTop languagesShellMakefileGoHCLMost used topicsLoading…Footer© 2023 GitHub, Inc.Footer navigationTermsPrivacySecurityStatusDocsContact GitHubPricingAPITrainingBlogAboutYou can’t perform that action at this time.\n",
      "---\n",
      "A Syntax for Self-Tracking (2020)\n",
      "A Syntax for Self-TrackingMarek GibneyHomeNotesToolsContactA Syntax for Self-TrackingFor a while now, I have been doing self-tracking in a text file. The reason is that I want to track not only one aspect of life, like fitness or health or nutrition, but anything that I suspect might be interesting to analyze later. Like how the time I wake up impacts my mood. Or which eye drops work best to prevent dry eyes. Or how the temperature of my bedroom impacts my energy the next day. Did I wake up with a headache because I ate pizza late at night? Or because I slept with the window wide open? Maybe I should avoid one of these in the future?If a completely context-free self-tracking app exists, I am not aware of it. Every tracking app seems to apply only to a certain narrow topic - often sport or food. And then all the apps send the data to a central server, which makes me uncomfortable.To get started experimenting with context-free self-tracking, I tried it in a simple text file. As it turns out, it is surprisingly doable, and it has led me to a bunch of interesting results already.It has led to a data structure that I find useful to do context-free self-tracking. A bit like the Git data structure: you can manipulate it with simple tools, and if you are nerd enough you might stick with those. I, for example, use only raw Git to do version control. And I only use Vim to operate on the self-tracking data structure I describe in this article. The general population would probably prefer higher-level tools (i.e., an app), which I will probably write later on. But first I want to get the data structure right.I started with a simple space-separated approach of \"date time event\":2020-05-28 18:41 Eat Pizza2020-05-29 09:00 Slept with the window open2020-05-29 09:00 HeadachesEverything is freeform. There is just one rule:1: Every line starts with the date and timeThis gives me the complete freedom to log whatever data I want. But I knew there would be more than just free text logging in the future. Structured logging of quantities (how many kilometers I ran, how many hours I slept), fine-grain data on multiple levels (How strong is the headache? Is it on the right or left side?), proper A/B tests, etc. I wanted to keep the option to introduce all this into the syntax without losing the freedom of logging free text. So I made this second rule:2: Everything until [^a-z ] describes an observation(A non-technical way to put it: Everything that only consists of the characters A-Z plus the space sign describes an observation.)To do away with any confusion about capitalization, I decided to make everything case-insensitive:3: Uppercase characters equal their lowercase counterpartsThis way, I can write anything into the log that comes to my mind without thinking about syntax at all. As long as I stick to the characters A-Z and the space, I can log anything in any way I like.Another early design decision about my self-tracking was that it is OK to write events into the log at any time. So I wrote all three log entries above at 09:00 in the morning, even the one about 18:41 of the last day. It is impossible to proactively track everything that could be of interest later. This is different to scientific studies where you would usually define upfront which causes to measure against which outcomes. But I think it is still useful to retroactively log data in the hopes that you can later make sense of it. That is how the human mind works. It's normal to think about past events when you try to find causes for the current situation. And I think a proper lifelong log can help us with this, even if we do not set up A/B tests - but we will, further down in this article.As you can see, I also took the liberty to log observations about the past. \"Slept with the window open.\" An acceptable alternative is to retroactively put the beginning of the event into the log, like I did with the pizza:2020-05-28 18:41 Eat Pizza2020-05-28 23:20 Go to bed with the window open2020-05-29 09:00 HeadachesThe idea is to log a lot of data quickly when I feel like logging it. The data can be dirty. No problem - clean it up later. Keep it in Git to have a track record how it changed.A nice convenience in Vim is that you can make it suggest the next word by pressing CTRL+N. This makes logging very fast. Instead of typing \"Headache\" you can just type H and CTRL+N and it will give you a list of every word with H you already have in your log. It also prevents typos and makes the data cleaner.For even greater convenience, I added another rule to my syntax:4: _ equals space.This means that instead of writing \"Slept with the window open\" I can write \"Slept_with_the_window_open\". From a data perspective, the two are equivalent. But for typing, now all I have to do is type S-CTRL+N and I get the whole event suggested by Vim \"Slept_with_the_window_open\". Which makes typing this event a matter of three keystrokes and keeps the data clean as I will always write it the same way.At this point, writing the events was already super fast. The most cumbersome part of logging was typing the date and time manually. So I added a shortcut to Vim:nnoremap <space>t o<C-r>=strftime(\"%F %H:%M \")<cr>Now all I have to do to add a log line is to hit space+t and I will be on a line that already has the date and time. So I can directly start typing the event that I want to log. Making a log entry now usually only takes about three seconds as the date/time is automatically inserted and the event is usually suggested too after I type the first few characters.After dabbling with freeform log events for a while, I wanted multiple levels of an observation. So instead of2020-06-01 18:41 Meeting with Hugo MayerI started writing:2020-06-01 17:00 Meeting: Hugo MayerSo the colon has a special meaning:5: A colon begins another level of the observationI use this for measurements all the time:2020-06-02 11:00 Temperature: 22°C2020-06-02 11:00 Humidity: 43%And also for subjective measurements:2020-06-02 12:15 Mood: Very Good2020-06-04 13:20 Sore eyes: MediumThere can be multiple colons in one line. For example, the following would log that I had sore eyes and felt it mostly in my left eye:2020-06-04 13:20 Sore eyes: Medium: Mostly LeftA/B TestsWhat about A/B tests? Maybe it is not the pizza that causes headaches the next day, but that eating pizza and having a headache the next day have the same root cause, like not eating enough for breakfast?Here comes the question mark:2020-06-05 22:30 Eat: Pizza? YesA question mark marks a coin flip. So if I say to myself, \"I am hungry, but should I really eat pizza at this time?\" then I write down the thing I am about to do and add a question mark. This means I will now have to do a coin flip and decide between Yes and No. Yes means the event left to the coin flip took place. No means it did not.To make this easier, I added this shortcut to my bashrc:alias coindecide='if (( RANDOM % 2 == 0 )); then echo Yes; else echo No; fi'So now I can just type \"coindecide<enter>\" to get a decision by coin flip. And since bash has autocompletion, I usually just type \"coi<tab><enter>\" and have my decision. Super fast.I could have put a coindecide macro into Vim, of course. But it is a nice tool in many situations, not only when writing. So I added it to the shell instead.Additional informationTo be able to put more info into the log even in lines structured according to the aforementioned six rules, I use parenthesis:2020-07-08 12:30 Take a walk? Yes (60min)7: Parenthesis can be used to add additional informationOrderSince I want a human-friendly format, the time is only tracked by the minute. This means that the order of events that are happening within the same minute is defined by their order in the log. This is important when using tools on the log to convert, filter, or merge it with other logs. Or when importing it into a database. Order always has to be preserved.8: Order is importantSo these are the eight rules I have been developing over the last five months of self-tracking:1: Every line starts with the date and time2: Everything until [^a-z ] describes an observation3: Uppercase characters equal their lowercase counterparts4: _ equals space5: A colon begins another level of the observation6: A question mark indicates a coin flip7: Parenthesis can be used to add more information8: Order is importantDiscussions about this text are taking place onTwitterandLobste.rs\n",
      "---\n",
      "A simple guide to pessimistic locking in Rails\n",
      " Modern CPUs consist of multiple cores, so software developers can benefit. Nowadays programming languages with concurrency features support the usage of multi-cores. Ruby is no exception, let's see how this it could be done.Read meJan GrelaSoftware engineerWe commit to your success in the digital world. We build web & mobile apps. Our clients value high ownership, business-driven approach and top engineering standards.Tech StackRuby on RailsReact.JSProgressive Web AppsGoServicesOngoing projectsProjects from scratchUX/UIOur officeOdolańska 5602-562 WarszawaPolandHire us+48 22 307 12 05contact@visuality.plIndustriesHR Tech Software DevelopmentSports Tech Software DevelopmentBooking Systems Software DevelopmentResourcesCompany presentationUX/UI PortfolioCase StudiesBlogOpen source that a certain process will always use the newest version of the record (or raise an exception).Pessimistic locking assumes that transaction conflicts occur frequently in the system. In such a situation optimistic locking wouldn't be much useful: it would cause irritating Stale Object errors too often. To address this challenge, a different approach is necessary.The remarkable benefit of pessimistic locking is the fact that it doesn't affect the whole system. You don't have to change the database at all. Instead, you need to explicitly specify all areas which will utilize this technique. This way you have full control of which processes needs to care about locking. It's useful for fixing places with race conditions, without affecting other functionalities.Show me the codeActiveRecord::Base.transactiondo# SELECT * FROM INVOICES WHERE id=? FOR UPDATEinvoice=Invoice.lock.find(invoice_id)returnunlessinvoice.status=='new'invoice.create_paymentinvoice.update(status:'paid')endSelecting a particular invoice uses special SQL command:SELECT ... FOR UPDATE. It \"locks\" the rows returned bySELECTand prevents other processes from retrieving it until the transaction is done. At the same time, other places in the app could use the good oldInvoice.find(invoice_id)statement without worrying about locks.Advanced stuffIt is possible to use database-specific locking by passing custom clauses to thelockmethod, such as:# raise an error if a record is already lockedinvoice=Invoice.lock(\"FOR UPDATE NOWAIT\").find(invoice_id)There is also an alternative method for locking individual records:with_lock. In this scenario, all operations happening within the block are wrapped into the transaction.invoice=Invoice.find(invoice_id)invoice.with_lockdo(..)endThe general rule is:Always use pessimistic locking within a transaction.Theoretically, you can calllock!method on records outside of it, but it doesn’t make sense and won’t simply work.Testing pessimistic lockingTesting pessimistic locking is not trivial. To simulate the real conditions, many processes must attempt to retrieve a record simultaneously. This can be achieved by using some concurrency mechanisms, like ruby threads:threads=[]3.timesdoservice.callendthreads.each(&:join)expect(invoice.payments.count).toeq1# this should fail without a lockSummaryThere are certain scenarios when pessimistic locking is perfect. It's a valuable tool for resolving race conditions and maintaining data integrity. Use it when you don't want to introduce an extraversioncolumn for optimistic locking. Or, when you need to fix a specific place in your Ruby on Rails app without affecting the rest of the system.TweetSubscribe to our blog!Get updates about new blog posts published on our website.Email AddressPrevious PostConcurrency and parallelism in Ruby (Processes, Threads, Fibers and Ractors)How to achieve concurrency and parallelism in Ruby? There are a couple of ways and I will describe these in the following article. It only covers the usage of Ruby core and standard library modules.\n",
      "---\n",
      "Optimizing a ring buffer for throughput (2021)\n",
      "Optimizing a Ring Buffer for Throughput | Erik RigtorpErik RigtorpOptimizing a ring buffer for throughput2021-12-13In this article I will take a look at the classic concurrent ring buffer and how it can be optimized to increase throughput. I will show you how to significantly increase throughput from 5.5M items/s to 112M items/s, beating theBoostandFollyimplementations. If you need a ready implementation with these optimizations checkout mySPSCQueue.hlibrary.The ringer buffer data structure is also referred to as a circular buffer or single producer single consumer (SPSC) queue. It’s a wait-free (hence also lock-free) concurrency primitive. It has a lot of uses for example it’s used to communicate network packets between NICs and OS drivers and to receive I/O completion events in the recently introducedio_uringasynchronous I/O API.The classic ring bufferFirst let’s start by implementing a simple ring buffer. In C++ it can be defined like this:structringbuffer{std::vector<int>data_;alignas(64)std::atomic<size_t>readIdx_{0};alignas(64)std::atomic<size_t>writeIdx_{0};ringbuffer(size_tcapacity):data_(capacity,0){}}In this implementation I chose to allow any queue size as opposed to allowing only sizes that are a power-of-two. This means that at least one queue item is unused in order to disambiguate between the empty queue and full queue state. You can choose to require a power-of-two size to avoid this if memory is at a premium.Another important thing to note is that read (readIdx_) and write (writeIdx_) indices are aligned to the size of a cache line (alignas(64)). This is done to reduce cache coherency traffic. On AMD64 / x86_64 and ARM a cache line is 64 bytes, on other CPUs you need to adjust to the appropriate alignment, usingstd::hardware_destructive_interference_sizeis a good choice if it’s available. It can also be interesting to try aligning to a multiple of the cache line size in case adjacent cache lines are being pre-fetched.This is quite similar to howio_uringdefines its ring buffer inside the Linux kernel:structio_uring{u32head____cacheline_aligned_in_smp;u32tail____cacheline_aligned_in_smp;};boost::lockfree::spscalso defines it’s ring buffer in pretty much the same way.We can now implement the push (or write) operation:boolpush(intval){autoconstwriteIdx=writeIdx_.load(std::memory_order_relaxed);autonextWriteIdx=writeIdx+1;if(nextWriteIdx==data_.size()){nextWriteIdx=0;}if(nextWriteIdx==readIdx_.load(std::memory_order_acquire)){returnfalse;}data_[writeIdx]=val;writeIdx_.store(nextWriteIdx,std::memory_order_release);returntrue;}Note how one item is left unused to indicate that the queue is full, whenwriteIdx_is one item behindreadIdx_the queue is full.Next we implement the pop (or read) operation:boolpop(int&val){autoconstreadIdx=readIdx_.load(std::memory_order_relaxed);if(readIdx==writeIdx_.load(std::memory_order_acquire)){returnfalse;}val=data_[readIdx];autonextReadIdx=readIdx+1;if(nextReadIdx==data_.size()){nextReadIdx=0;}readIdx_.store(nextReadIdx,std::memory_order_release);returntrue;}Again note thatreadIdx_ == writeIdx_indicates that the queue is empty.I chose a very small item size (sizeof(int) == 4) since for large item sizes the performance will be dominated by the memory copying of the items and the goal is not to measure the performance ofmemcpy(). This of course also means that if you have large items you don’t have much to gain from optimizing your ring buffer.Now lets analyze the performance of this queue. I wrotea simple benchmarkringbuffer.cppthat pushes 100M items between 2 threads through a ring buffer of size 100k. Measuring how long it takes until the reader thread has read all items. Compileringbuffer.cppas follows:g++ -Wall -O3 -march=native -std=c++20 ringbuffer.cppI ran this on a AMD Ryzen 9 3900X 12-Core Processor placing the two threads on different chiplets / core complexes (CCX):$ perf stat -e cache-misses,cache-references,l2_request_g1.change_to_x ./a.out 1 11 5513850 ops/s   Performance counter stats for './a.out 1 11':         349,857,603      cache-misses:u            #   91.228 % of all cache refs            383,497,078      cache-references:u                                                    6,673,242      l2_request_g1.change_to_x:u                                           18.137421039 seconds time elapsed        36.140630000 seconds user        0.002986000 seconds sysWe see here that we achieved a throughput of 5.5M items per second. This is in line with the performance you will see from libraries such asboost::lockfree::spscandfolly::ProducerConsumerQueue. The number of cache misses (~300M) seems to be proportional (3x) to the number of items (100M) that were processed.The optimized ring bufferWhy do we have 3 cache misses per read-write pair? Consider a read operation: the read index needs to be updated and thus that cache line is loaded into the L1 cache in exclusive state (seeMESI protocol). The write index needs to be read in order to check that the queue is not empty and is thus loaded into the L1 cache in shared state. Since a queue write operation needs to read the read index it causes the reader’s read index cache line to be evicted or transition into shared state. Now the read operation requires some cache coherency traffic to bring the read index cache line back into exclusive state. In turn a write operation will require some cache coherency traffic to bring the write index cache line back into exclusive state. In the worst case there will be one cache line transition from shared to exclusive for every read and write operation. These cache line state transitions are counted as cache misses. We don’t know the exact implementation details of the cache coherency protocol, but it will behave roughly as the MESI protocol.To reduce the amount of coherency traffic the reader and writer can keep a cached copy of the write and read index respectively. In this case when a reader first observes thatNitems are available to read, it caches this information and theN-1subsequent reads won’t need to read the write index. Similarly when a writer first observes thatNitems are available for writing, it caches this information and theN-1subsequent writes won’t need to read the read index.The new ring buffer is defined as follows:structringbuffer2{std::vector<int>data_{};alignas(64)std::atomic<size_t>readIdx_{0};alignas(64)size_twriteIdxCached_{0};alignas(64)std::atomic<size_t>writeIdx_{0};alignas(64)size_treadIdxCached_{0};ringbuffer2(size_tcapacity):data_(capacity,0){}}The push operation is updated to first consult the cached read index (readIdxCached_) and if that fails retry after updating the cache:if(nextWriteIdx==readIdxCached_){readIdxCached_=readIdx_.load(std::memory_order_acquire);if(nextWriteIdx==readIdxCached_){returnfalse;}}The pop operation is updated in a similar way to first consult the cached write index (writeIdxCached_):if(readIdx==writeIdxCached_){writeIdxCached_=writeIdx_.load(std::memory_order_acquire);if(readIdx==writeIdxCached_){returnfalse;}}Re-running the same benchmark as before with the new ring buffer implementation:$ perf stat -e cache-misses,cache-references,l2_request_g1.change_to_x ./a.out 1 11 112287037 ops/s   Performance counter stats for './a.out 1 11':          15,010,392      cache-misses:u            #   32.553 % of all cache refs             46,110,663      cache-references:u                                                    6,781,273      l2_request_g1.change_to_x:u                                            0.892256380 seconds time elapsed         1.775185000 seconds user        0.000996000 seconds sysWow this is great! Throughput is now 112M items per second and the number of cache misses was significantly reduced. Checkoutringbuffer.cppif you want to verify this yourself.Further optimizationsSupporting batched push and pop operations can reduce the number of times the read and write indices needs to be updated to less than once per item.Using huge pages for the ring buffer backing memory can reduce TLB misses.Other postsOptimizing a ring buffer for throughputUsing huge pages on LinuxFuzzing floating point codeGenerating std::ostream &operator<< for C++ enums and structs using libClangTips for using the sockets APIUses of immediately invoked function expressions (IIFE) in C++Latency implications of virtual memoryAligned AVX loads and stores are atomicCorrectly implementing a spinlock in C++Low latency tuning guidePerformance impact of split locksC++ Best PracticesEstimating order queue positionDesigning a high performance market data feed handlerEfficient rolling statistics with NumPyErlang Latency Guide© 2022Erik Rigtorp<erik@rigtorp.se>GitHubLinkedIn\n",
      "---\n",
      "Text Blaze (YC W21) is hiring a growth engineer to pioneer LLM driven strategies\n",
      "Text Blaze (YC W21) is hiring a growth engineer to pioneer LLM driven strategies | Hacker NewsHacker Newsnew|past|comments|ask|show|jobs|submitloginText Blaze (YC W21) is hiring a growth engineer to pioneer LLM driven strategies1 hour ago|hideGreetings Hacker News community,We're excited to announce that Text Blaze (YC W21) is currently seeking a Growth Engineer who is passionate about leveraging large language models (LLMs) to transform the world of growth marketing. In this role, you'll have the unique opportunity to drive our user acquisition and activation journey end-to-end, exploring and experimenting with innovative ways to use LLMs to promote Text Blaze’s capabilities and grow existing users' usage of Text Blaze by generating personalized content tailored to each user.About Text BlazeAt Text Blaze, we're dedicated to freeing users from tedious work by providing them with simple yet powerful solutions. We're fast-paced, data-driven, and constantly iterating based on the needs of our users.Joining us means being part of a profitable, fast-growing company that already has an excellent product-market fit and a deeply loyal user base of over 300,000 users. As a member of our founding team, you'll have a substantial impact on our product, strategy, and culture.We're fully remote. You'll be part of a team that embraces ownership and impact, all while working comfortably from your own home.Skills and Qualifications- A passion for talking to users and understanding their problems. - A knack for identifying business needs and developing technical solutions to address them. - An eye for design and comfort with designing your own UI's and solutions. - Experience or strong interest working with large language models, prompt engineering and post-processing - Proficiency in SQL, Python and JavaScriptThis is an opportunity to be at the forefront of the LLM-driven growth revolution. If you're eager to rethink growth and transform how we interact with potential users, we'd love to hear from you.To apply please email us at hiring@blaze.todayFeel free to reach out to us directly if you have any questions!The Text Blaze TeamGuidelines|FAQ|Lists|API|Security|Legal|Apply to YC|ContactSearch:\n",
      "---\n",
      "It's weird that people get mocked for changing their minds\n",
      "JavaScript is not available.We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using twitter.com. You can see a list of supported browsers in our Help Center.Help CenterTerms of ServicePrivacy PolicyCookie PolicyImprintAds info© 2023 X Corp.Something went wrong, but don’t fret — let’s give it another shot.Try again\n",
      "---\n",
      "The best place to drink is the emptiest bar in the city\n",
      "nytimes.comPlease enable JS and disable any ad blocker\n",
      "---\n",
      "Build your own Docker with Linux namespaces, cgroups, and chroot\n",
      "Build Your Own Docker with Linux Namespaces, cgroups, and chroot: Hands-on Guide | Akash RajpurohitAboutProjectsBlogsSnippetsUsesSun IconMoon IconMobile Nav HamburgerAboutProjectsBlogsSnippetsUsesArrowLeft IconBuild Your Own Docker with Linux Namespaces, cgroups, and chroot: Hands-on Guide📆Jun 27, 2023·⏳ 4 min read·#️⃣ linux·                👀IntroductionContainerization has transformed the world of software development and deployment.Docker↗️, a leading containerization platform, leverages Linuxnamespaces,cgroups, andchrootto provide robust isolation, resource management, and security.In this hands-on guide, we’ll skip the theory (go through the attached links above if you want to learn more about the mentioned topics) and jump straight into the practical implementation.🙅🏻‍♂️Before we delve into building our own Docker-like environment using namespaces, cgroups, and chroot, it’s important to clarify that this hands-on guide is not intended to replace docker and its functionality.Docker have features such as layered images, networking, container orchestration, and extensive tooling that make it a powerful and versatile solution for deploying applications.The purpose of this guide is to offer an educational exploration of the foundational technologies that form the core of Docker. By building a basic container environment from scratch, we aim to gain a deeper understanding of how these underlying technologies work together to enable containerization.Let’s build DockerStep 1: Setting Up the NamespaceTo create an isolated environment, we start by setting up a new namespace. We use theunsharecommand, specifying different namespaces(--uts, --pid, --net, --mount, and --ipc), which provide separate instances of system identifiers and resources for our container.unshare--uts--pid--net--mount--ipc--forkStep 2: Configuring the cgroupsCgroups (control groups) help manage resource allocation and control the usage of system resources by our containerized processes.We create a new cgroup for our container and assign CPU quota limits to restrict its resource usage.mkdir/sys/fs/cgroup/cpu/container1echo100000>/sys/fs/cgroup/cpu/container1/cpu.cfs_quota_usecho0>/sys/fs/cgroup/cpu/container1/tasksecho$$>/sys/fs/cgroup/cpu/container1/tasksOn the third line we write the value0to the tasks file within the/sys/fs/cgroup/cpu/container1/directory. The tasks file is used to control which processes are assigned to a particular cgroup.By writing0to this file, we are removing any previously assigned processes from the cgroup. This ensures that no processes are initially assigned to the container1 cgroup.On the fourth line we write the value of$$to the tasks file within the/sys/fs/cgroup/cpu/container1/directory.$$is a special shell variable that represents the process ID (PID) of the current shell or script. By this, we are assigning the current process (the shell or script) to the container1 cgroup.This ensures that any subsequent child processes spawned by the shell or script will also be part of the container1 cgroup, and their resource usage will be subject to the specified CPU quota limits.Step 3: Building the Root File SystemTo create the file system for our container, we usedebootstrapto set up a minimal Ubuntu environment within a directory named\"ubuntu-rootfs\". This serves as the root file system for our container.debootstrapfocal./ubuntu-rootfshttp://archive.ubuntu.com/ubuntu/Step 4: Mounting and Chrooting into the ContainerWe mount essential file systems, such as/proc,/sys, and/dev, within our container’s root file system. Then, we use the chroot command to change the root directory to our container’s file system.mount-tprocnone./ubuntu-rootfs/procmount-tsysfsnone./ubuntu-rootfs/sysmount-obind/dev./ubuntu-rootfs/devchroot./ubuntu-rootfs/bin/bashThe first command mounts theprocfilesystem into the./ubuntu-rootfs/procdirectory. Theprocfilesystem provides information about processes and system resources in a virtual file format.Mounting theprocfilesystem in the specified directory allows processes within the./ubuntu-rootfs/environment to access and interact with the system’s process-related information.The next command mounts thesysfsfilesystem into the./ubuntu-rootfs/sysdirectory. The sysfs filesystem provides information about devices, drivers, and other kernel-related information in a hierarchical format.Mounting thesysfsfilesystem in the specified directory enables processes within the./ubuntu-rootfs/environment to access and interact with system-related information exposed through thesysfsinterface.Finally we bind the/devdirectory to the./ubuntu-rootfs/devdirectory. The/devdirectory contains device files that represent physical and virtual devices on the system.By binding the/devdirectory to the./ubuntu-rootfs/devdirectory, any device files accessed within the./ubuntu-rootfs/environment will be redirected to the corresponding devices on the host system.This ensures that the processes running within the./ubuntu-rootfs/environment can interact with the necessary devices as if they were directly accessing them on the host system.Step 5: Running Applications within the ContainerNow that our container environment is set up, we can install and run applications within it. In this example, we install Nginx web server to demonstrate how applications behave within the container.(container) $ apt update(container) $ apt install nginx(container) $ service nginx startConclusionBy taking a hands-on approach and exploring the code and command examples, we’ve gained a practical understanding of building our own Docker-like environment using Linux namespaces, cgroups, and chroot.Of course docker containerization is lot more than what we just explored above but these fundamentals empowers us to create isolated and efficient environments for our applications.EnvelopeOpen IconStay up to dateGet notified when I publish something new, and unsubscribe at any time.JoinHackerNewsDiscuss on HackerNewsHackerNewsRedditTwitterWhatsappLinkedInPrevious ArticleHow to Create a Restricted Environment with the Linux chroot CommandYou may also like#linuxHow to Create a Restricted Environment with the Linux chroot CommandThe Linux operating system is known for its flexibility and robustness. One of the many powerful tools available in Linux is the chroot command, which can be used to create a restricted environment within the existing file system. This can be useful in a variety of scenarios, such as testing new software or isolating sensitive data. In this article, we'll explore how to use the chroot command in Linux and provide practical examples to help you get started.Jun 26, 2023#linuxLinux Control Groups: Fine-Tuning Resource Allocation for Optimal System PerformanceExplore the power of Linux control groups (cgroups) and how they revolutionize resource management in your Linux environment. Uncover the secrets of cgroups to effectively allocate system resources, limit process usage, and optimize performance for your applications and services.Jun 25, 2023#linuxLinux Namespaces: Isolating Your System for Enhanced Security and PerformanceDiscover the power of Linux namespaces and how they enable you to create isolated environments within your system. Dive into this comprehensive guide to understand the concept of namespaces, their benefits, and how they enhance security and performance in your Linux environment.Jun 23, 2023GeneralHomeAboutBlogsProjectsSnippetsExtrasNewsletterUsesResumeTweetsTagsPrivacy PolicyEnvelopeOpen IconStay up to dateGet notified when I publish something new, and unsubscribe at any time.JoinGithub IconTwitterLinkedInInstagram IconMail Icon© 2023          Akash Rajpurohit\n",
      "---\n",
      "Unexpected Interaction of Features\n",
      "Unexpected Interaction Of FeaturesUnexpected Interaction Of FeaturesRecent changesTable of contentsLinks to this pageFRONT PAGE / INDEXSubscribe!My latest posts can be found here:Colins BlogPrevious blog posts:Archimedes Hat Box TheoremConsidering A SphereTo Link Or Not To LinkGeneric Advice For Writing A ThesisJust Teach My Child The MathsNot A Spectator SportLeft Truncatable PrimeThe Doctor And The LawyerFour Points Two Distances ProofMeeting Ron GrahamNapkin Ring Versus Spherical CapThe Four Points PuzzleRadius Of The Earth Part TwoGrep Timing AnomalyThe Radius Of The EarthThis Works To Cure My HiccoughsPerhaps We Saved OneThinking About MastodonDisappearing Trains On VirginThe Independence GameOne Of My Favourite PuzzlesThinking About RecursionMemorising The TubeSpikey SpheresSurprisingly QuickAn Unexpected FractionYou Have To Admire Their OptimismRepresentatives MatterPythagoras By IncircleA Puzzle About PuzzlesHow Not To Do TwitterCalculating 52 Factorial By HandSmall Things Might Not Be So SmallNot If You HurryFactoring Via Graph Three ColouringAnother Proof Of The Doodle TheoremWhen Obvious Is Not ObviousGraph Three ColouringThe Doodle TheoremBe Careful What You SayThe Mutilated Chessboard RevisitedA Mirror CopiedThe Other Other Rope Around The EarthPhotocopy A MirrorThe Point Of The Banach Tarski TheoremSieve Of Eratosthenes In PythonFast Perrin TestRussian Peasant MultiplicationFindingPerrinPseudoPrimes Part2FindingPerrinPseudoPrimes Part1The Unwise UpdateMiles Per GallonTracking An Item On Hacker NewsHacker News User AgesPoking The Dusty CornersThere Is No Time For ThisPublically Sharing LinksLearning Times TablesGraceful DegradationDiagramming Maths TopicsOn The RackSquare Root By Long DivisionBeyond The BoundaryFill In The GapsSoftware ChecklistNASA Space CrewsThe Birthday ParadoxThe Trapezium ConundrumRevisiting The AntThe Ant And The Rubber BandIrrationals ExistMultiple Choice Probability PuzzleRandom EratosthenesWrapping Up Square DissectionDissecting A Square Part 2Dissecting A CircleDissecting A SquareAn Oddity In TennisDecision Tree For TennisDecision Trees In GamesA Matter Of ConventionDo You Nourish Or TarnishBinary Search ReconsideredTwo Equals FourThe Lost Property OfficeThe Forgiving User InterfaceSetting Up RSSWithdrawing From Hacker NewsAdditionally, some earlier writings:Random Writings.Colins Blog 2010Colins Blog 2009Colins Blog 2008Colins Blog 2007Colins Blog Before 2007An Unexpected Interaction of FeaturesI've been dealing with some data, and using my usual technique of using command-line tools to play with it for a while before writing a program to do the full analysis.But something was wrong, and it took me a while to work it out.I was sorting a file:whichaerodynamicallyelectroencephalogramexoticallyaerodynamicallyadifferentiation->aaerodynamicallyaerodynamicallydifferentiationelectroencephalogramexoticallywhichBut my file has as the first field a count:5 which15 aerodynamically20 electroencephalogram10 exotically15 aerodynamically1 a15 differentiation->10 exotically15 aerodynamically15 aerodynamically15 differentiation1 a20 electroencephalogram5 whichThat's not what I wanted, but this was a game I'd played before. The utilitysortis working on the data as text, so it's alphabetical. I need to sort using-nto get it to sort numerically:5 which15 aerodynamically20 electroencephalogram10 exotically15 aerodynamically1 a15 differentiation->1 a5 which10 exotically15 aerodynamically15 aerodynamically15 differentiation20 electroencephalogramExcellent, but now I realise there are repeated lines, and I need to de-duplicate. So I usesort -uto do that:5 which15 aerodynamically20 electroencephalogram10 exotically15 aerodynamically1 a15 differentiation->10 exotically15 aerodynamically15 differentiation1 a20 electroencephalogram5 whichThe duplication is gone, but the screwy ordering is back, because I forgot the \"numerical\" flag, sosort -nuis what I need:5 which15 aerodynamically20 electroencephalogram10 exotically15 aerodynamically1 a15 differentiation->1 a5 which10 exotically15 aerodynamically20 electroencephalogramSpot the difference.Yes, the \"differentiation\" line has gone, and I can only assume that when both thenanduflags are set, it only takes the numbers into account when deciding if there are duplicates. I haven't explored whether, for a given number, it (a) sorts and keeps the first, (b) sorts and keeps the last, (c) keeps the first in the input then sorts, (d) keeps thelastin the input then sorts, or (e) something else.But it's certainly not what I expected.So now it's back to using \"sort -n | uniq\" rather than \"sort -nu\".For reference: \"sort --version\" returns \"sort (GNU coreutils) 8.21\"<<<< Prev <<<<Archimedes Hat Box Theorem:>>>> Next >>>>Why Top Posting Has Won...You can follow me on Mathstodon.Of course, you can alsofollow me on twitter:Send us a comment ...You can send us a message here. It doesn't get published, it just sends us an email, and is an easy way to ask any questions, or make any comments, without having to send a separate email. So just fill in the boxes and thenYour name:Email:Message:ContentsAn Unexpected Interaction of FeaturesSend us a comment ...Links on this pageAMatterOfConventionAMirrorCopiedAPuzzleAboutPuzzlesAnOddityInTennisAnUnexpectedFractionAnotherProofOfTheDoodleTheoremArchimedesHatBoxTheoremBeCarefulWhatYouSayBeyondTheBoundaryBinarySearchReconsideredCalculating52FactorialByHandColinsBlogColinsBlog2007ColinsBlog2008ColinsBlog2009ColinsBlog2010ColinsBlogBefore2007ConsideringASphereDecisionTreeForTennisDecisionTreesInGamesDiagrammingMathsTopicsDisappearingTrainsOnVirginDissectingACircleDissectingASquareDissectingASquarePart2DoYouNourishOrTarnishFactoringViaGraphThreeColouringFastPerrinTestFillInTheGapsFindingPerrinPseudoPrimes_Part1FindingPerrinPseudoPrimes_Part2FourPointsTwoDistancesProofGenericAdviceForWritingAThesisGracefulDegradationGraphThreeColouringGrepTimingAnomalyHackerNewsUserAgesHowNotToDoTwitterIrrationalsExistJustTeachMyChildTheMathsLearningTimesTablesLeftTruncatablePrimeMeetingRonGrahamMemorisingTheTubeMilesPerGallonMultipleChoiceProbabilityPuzzleNASASpaceCrewsNapkinRingVersusSphericalCapNotASpectatorSportNotIfYouHurryOnTheRackOneOfMyFavouritePuzzlesPerhapsWeSavedOnePhotocopyAMirrorPokingTheDustyCornersPublicallySharingLinksPythagorasByIncircleRadiusOfTheEarthPartTwoRandomEratosthenesRandomWritingsRepresentativesMatterRevisitingTheAntRussianPeasantMultiplicationSettingUpRSSSieveOfEratosthenesInPythonSmallThingsMightNotBeSoSmallSoftwareChecklistSpikeySpheresSquareRootByLongDivisionSurprisinglyQuickTheAntAndTheRubberBandTheBirthdayParadoxTheDoctorAndTheLawyerTheDoodleTheoremTheForgivingUserInterfaceTheFourPointsPuzzleTheIndependenceGameTheLostPropertyOfficeTheMutilatedChessboardRevisitedTheOtherOtherRopeAroundTheEarthThePointOfTheBanachTarskiTheoremTheRadiusOfTheEarthTheTrapeziumConundrumTheUnwiseUpdateThereIsNoTimeForThisThinkingAboutMastodonThinkingAboutRecursionThisWorksToCureMyHiccoughsToLinkOrNotToLinkTrackingAnItemOnHackerNewsTwoEqualsFourWhenObviousIsNotObviousWhyTopPostingHasWonWithdrawingFromHackerNewsWrappingUpSquareDissectionYouHaveToAdmireTheirOptimismSite hosted byColinandRachelWright:Maths, Design, Juggling, Computing,Embroidery, Proof-reading,and other clever stuff.Suggest a change( <--What does this mean?) /Send me emailFront Page/All pages by date/Site overview/Top of pageQuotation fromTim Berners-Lee\n",
      "---\n",
      "Show HN: Mofi – Content-aware fill for audio to change a song to any duration\n",
      "Mofi - Content-aware fill and trim for music!MofiNewAboutLeave feedbackWelcome to MofiContent-aware fill and trim for music! Free and no download needed.FeaturesPerfect length:Shorten and lengthen a song, making it the perfect length to match a video or performance. Keep the vibe of the song with seamless transitions and without cutting off the end too early!Remove seamlessly:Don't like part of a song? Choose parts to remove and have them filled seamlessly, it's basically content-aware fill for audio!On repeat:Make an extended version of your song's favorite part by choosing the catchy part and seamlessly repeating part of it!Get startedSelect a local file or paste a link to start editing. No file or just exploring? Check outthis example!Drop, paste, or click to upload a file......or paste a link to a song online:ImportMake sure you have the applicable rights to any audio you submit to Mofi.FAQHow can I shorten a song without cutting it?Submit a song to Mofi and enter the new duration of the song. You can then choose from multiple results that match your requested length. This is helpful if you need to shorten a song to match a video you already edited.How can I make a song longer seamlessly?After you choose a song to edit on Mofi, you can type in the new length and export a new, longer version.How can I make a perfectly looping version of a song for TikTok?After you upload the song to Mofi, you can drag to select the part you want to loop. Click \"prefer\" in the menu and type in how long you want your edit to be and download it.How can I remove a part of a song without it sounding weird?You can use Mofi to remove a part of a song seamlessly! After adding it, select the part or parts that you don't like and the algorithm will remove them and try to keep the edit sound natural and without cuts.How do I shorten a song online for free?Mofi allows you to shorten (or lengthen!) any song to whatever length you want for free. You can use the website without installing or downloading another app or program.How can I remix a song without paying for Adobe Audition?You don't need to pay for Adobe Audition to remix a song. Use Mofi and change the length of a song for free online without downloading anything or creating an account.Legal© 2023Florian\n",
      "---\n",
      "Show HN: An Interactive Guide to Teach Derivatives and Backpropagation\n",
      "Building Autograd Engine & Neural Network Library: An Interactive Guidex0axzGithubAboutBuilding Autograd Engine & Neural Network Library: An Interactive GuideIn this article, we will build an Autograd engine and a neural network library that handle an N-dimensional array. Autograd is a tool used for derivative calculation. It tracks operations on values with enabled gradients and builds a dynamic computational graph — a graph without cycles. Input values serve as the leaves of the graph, while output values act as its roots. Gradients are computed by traversing the graph from root to leaf, applying the chain rule to multiply gradients at each step.Neural networks are complex mathematical functions that are adjusted through a process called training to produce the desired output. Backpropagation is a key algorithm used in this training process. It computes gradients, which represent the change in loss for small adjustments in input weights and biases. These gradients are then utilised to update the weights and biases, with a learning rate applied to reduce the overall loss and train the neural network. This fine-tuning is also used to carefully adjust the parameters of a pre-trained model to adapt it to a specific task or dataset. The training process occurs iteratively, involving the calculation of multiple gradients. A computation graph is constructed to store these gradient functions.Andrej Karaphy'sMicrogradand hisvideo tutorialabout building Micrograd, from which I would take a few examples, served as inspiration for this article. But this Autograd engine will accept N-dimensional array, whereas Microgard accepts scalar values only.While assuming a basic understanding of Python programming, high school calculus, and neural networks, I'll provide various teaching methods for those who may not have that background. This includes line-by-line Python code explanations and visualizations of the output. The article includes an interactive area to explore derivatives, utilizing concepts from calculus. For a comprehensive understanding, I recommend watching 3Blue1Brown'svideo serieson neural networks and backpropagation. In thefinal video, he covers the Chain Rule, which is the mathematical foundation of backpropagation. Additionally, Jay Alammar'sarticleon neural network basics is highly recommended.Exploring the building blocks of neural networks and their training process, the journey begins with the basics of derivatives and covers various examples and methods. Delving into backpropagation, the focus is on understanding how to perform it manually and programmatically, including implementation techniques. Creating an autograd class from scratch and utilizing it to train a neural network on a dataset is the next step, leading to the development of a simple neural network library using our autograd class.Let's dive right in and begin with the fundamentals.What is Derivates?Derivatives help us understand how things are changing at a specific point. They are like speedometers that measure           the rate of change of a quantity or the slope of a curve. By calculating derivatives, we can gain insights into           motion, growth, and other dynamic processes.The derivative of a function is calculated using a specific mathematical formula. Let's denote the derivative of a function \\( f(x) \\) as \\( f'(x) \\) or \\( \\frac{dy}{dx} \\), where \\( y \\) represents the dependent variable and \\( x \\) represents the independent variable.The general formula for finding the derivative of a function \\(f(x)\\) is:\\( f'(x) = \\lim_{h \\to 0} \\frac{{f(x + h) - f(x)}}{h} \\)In simpler terms, the derivative is calculated by taking the difference between the function values at two nearby           points and dividing it by the difference in their corresponding x-values, as the difference approaches zero \\( (h \\to 0) \\).For example, if we have a function \\( f(x) = 2x^2 \\), we can find its derivative using the formula:\\( f'(x) = \\lim_{{h \\to 0}} \\frac{{2(x + h)^2 - 2x^2}}{{h}} \\)By expanding and simplifying the expression, we can find the derivative \\( f'(x) = 4x \\).This formula allows us to find the instantaneous rate of change or slope of the function at any specific point. It           provides valuable information about how the function is changing at different locations along the x-axis.Single-input derivativeFirst, we'll create a basic function to compute the derivative of a scalar value. Subsequently, we'll perform theoretical differentiations on these expressions using identical values and verify that their outputs match. Lastly, we'll include an interactive section where we can adjust variable values and determine the derivatives of the given function with the chosen values.Let's go through each line of the code and explain what it does:def f(x):: This line defines a function namedfthat takes a single input parameterx. The function calculates and returns the result of the equation \\( 3 * x^2 - 4 * x + 5 \\).return 3*x**2 - 4*x + 5: This line specifies the equation that the functionfevaluates. It calculates the result of the quadratic expression \\( 3 * x^2 - 4 * x + 5 \\) and returns that value.f(3.0): This line calls the functionfwith an input value of3.0. It calculates the result of the expression \\( 3 * x^2 - 4 * x + 5 \\) with \\( x \\) set to \\( 3.0 \\) and returns the result.h = 0.001: This line assigns a value of0.001to the variableh. In this context,hrepresents a small value used to approximate the derivative of the function.x = 3.0: This line assigns a value of3.0to the variablex. This represents the point at which we want to evaluate the derivative of the function.(f(x + h) - f(x))/h: This line calculates the approximate derivative of the functiondef f(x):at the point \\( x \\) using the finite difference method. It evaluates the expression \\( \\frac{{f(x + h) - f(x)}}{h} \\), where \\( f(x + h) \\) represents the value of the function at \\( x + h \\), \\( f(x) \\) represents the value of the function at \\( x \\), and \\( h \\) is a small increment. This expression calculates the slope between two nearby points on the function and then divides it by \\( h \\) to approximate the derivative.To summarize, the code defines a functionfthat represents a quadratic equation. It then sets the values ofhandx, representing the small increment and the point at which to evaluate the derivative, respectively. Finally, it calculates the approximate derivative of the function atxusing the finite difference method and returns the result.Theoretically differentiate the \\( f(x) = 3x^2 - 4x + 5 \\)To differentiate the function \\( f(x) = 3x^2 - 4x + 5 \\), we can apply the power rule and the constant rule of differentiation. The power rule states that the derivative of \\( x^n \\) (where \\( n \\) is a constant) is \\( n * x^{(n-1)} \\). The constant rule states that the derivative of a constant term is always zero.Let's find the derivative of \\( f(x) \\) step by step:\\( f(x) = 3x^2 - 4x + 5 \\)To find the derivative, we differentiate each term separately:The derivative of \\( 3x^2 \\) with respect to \\( x \\) is:\\( \\frac{{d}}{{dx}} (3x^2) = 2 * 3x^{(2-1)} = 6x \\)The derivative of \\( -4x \\) with respect to \\( x \\) is:\\( \\frac{{d}}{{dx}} (-4x) = -4 \\)The derivative of the constant term \\( 5 \\) with respect to \\( x \\) is:\\( \\frac{{d}}{{dx}} (5) = 0 \\)Rewrite the derivative as follows:\\( f'(x) = 6x - 4 \\)To find the value of the derivative at \\( x = 3 \\), we substitute \\( x = 3 \\) into the derivative expression:\\( f'(3) = 6 * 3 - 4 = 18 - 4 = 14 \\)Therefore, the derivative of \\( f(x) = 3x^2 - 4x + 5 \\) at \\( x = 3 \\) is \\( 14 \\).Theoretically differentiate the expression \\(\\frac{{f(x + h) - f(x)}}{h}\\) where \\( h = 0.001 \\) and \\( x = 3.0 \\), and \\( f(x) = 3x^2 - 4x + 5 \\)To differentiate the expression \\(\\frac{{f(x + h) - f(x)}}{h}\\) where \\( h = 0.001 \\) and \\( x = 3.0 \\), and \\( f(x) = 3x^2 - 4x + 5 \\), we can substitute these values into the expression and simplify it.Start by substituting the given values into the expression:\\(\\frac{{f(x + h) - f(x)}}{h}\\) \\( =  \\) \\(\\frac{{f(3.0 + 0.001) - f(3.0)}}{{0.001}}\\)Calculate the values of \\( f(3.0 + 0.001) \\) and \\( f(3.0) \\):\\( f(3.0 + 0.001) = 3 * (3.0 + 0.001)^2 - 4 * (3.0 + 0.001) + 5 \\)\\( = 3 * (3.001)^2 - 4 * (3.001) + 5 \\)\\( = 3 * 9.006001 - 12.004 + 5 \\)\\( = 27.018003 - 12.004 + 5 \\)\\( = 20.014003 \\)\\( f(3.0) = 3 * (3.0)^2 - 4 * (3.0) + 5 \\)\\( = 3 * 9 - 12 + 5 \\)\\( = 27 - 12 + 5 \\)\\( = 20 \\)Substituting these values back into the expression:\\( \\frac{{f(x + h) - f(x)}}{h} \\)\\( = \\frac{{20.014003 - 20}}{{0.001}} \\)\\( = \\frac{{0.014003}}{{0.001}} \\)\\( = 14.003 \\)Therefore, the value of the expression \\( \\frac{{f(x + h) - f(x)}}{h} \\) when \\( h = 0.001 \\) and \\( x = 3.0 \\) is \\( 14.003 \\).Play with single-input derivative!h:0.001x:3a:3.0b:-4.0c:5.0Derivative of3.0\\( x^2 \\)-4.0\\( x \\)+5.0at \\( x = \\)3isand with adding slope of \\( h = \\)0.001isDerivative of \\( \\frac{{f(x + h) - f(x)}}{h} \\) where \\( x = \\)3and \\( h = \\)0.001is\\( f(x + h) = \\)3.0\\( (x + h)^2 \\)-4.0\\( (x + h) \\)+5.0\\( = \\)\\( f(x) \\) =3.0\\( x^2 \\)-4.0\\( x \\)+5.0\\( = \\)Multi-input derivativeIn this section, we will create two functions. One function will involve incrementing one variable by a small amount proportional to the slope, allowing us to approximate the derivative of the expression with respect to that variable. We will then proceed to theoretically differentiate the given expression with respect to one of its variables using identical values, ensuring that the results match. Finally, an interactive section will be provided where variable values can be adjusted, and the variable for which the expression's derivative is computed can be changed.Let's go through each line of the code and explain what it does:h = 0.0001: This line assigns a value of0.0001to the variableh. In this code,his referred to as the \"slope,\" but it is actually a small increment used for approximating the derivative.a = 2.0,b = -3.0,c = 10.0: These lines assign specific values to the variablesa,bandc. These values represent the inputs for the function or expression we are working with.d1 = a * b + c: This line calculates the value of the expression \\( a * b + c \\) and assigns it to the variabled1.a += h: This line increments the value ofaby addinghto it. The purpose is to create a new value for a to be used in the next line.d2 = a * b + c: This line calculates the value of the expression \\( a * b + c \\) using the updated value ofaand assigns it to the variabled2.print('d1: ', d1),print('a: ', a),print('d2: ', d2),print('slope: ', (d2 - d1)/h): These lines print the values ofd1,a,d2and the slope (approximated derivative) calculated as \\(\\frac{{d2 - d1}}{h}\\).To summarize, the code sets up variables for the slope (h) and the inputs (a,bandc). It then performs calculations using these values to findd1andd2, representing the expressions \\( a * b + c \\) at different values ofa. Finally, it prints the values ofd1,a,d2, and the slope calculated using the finite difference method.Theoretically differentiate \\( a * b + c \\) with respect to \\( a \\)To differentiate the expression \\( a * b + c \\) with respect to \\( a \\), we need to find the derivative of the expression with respect to \\( a \\). Given that \\( a = 2.0 \\), \\( b = -3.0 \\), and \\(c = 10.0 \\), let's proceed with the differentiation.The expression \\( a * b + c \\) involves multiplication and addition. To find the derivative with respect to \\( a \\), we differentiate each term separately:The derivative of \\( a * b \\) with respect to \\( a \\) is:\\( \\frac{{d}}{{da}} (a * b) = b \\)The derivative of \\( c \\) with respect to \\( a \\) is:\\( \\frac{{d}}{{da}} (c) = 0 \\)Since \\( c \\) is a constant, its derivative with respect to \\( a \\) is always \\( 0 \\).Rewrite the derivative as follows:\\( \\frac{{d}}{{da}} (a * b + c) = b + 0 = b \\)Substituting the given values \\( a = 2.0 \\), \\( b = -3.0 \\), and \\(c = 10.0 \\) into the derivative expression, we get:\\( \\frac{{d}}{{da}} (2.0 * -3.0 + 10.0) = -3.0 \\)Therefore, the derivative of the expression \\( a * b + c \\) with respect to \\( a \\), when \\( a = 2.0 \\), \\( b = -3.0 \\), and \\(c = 10.0 \\), is \\( -3.0 \\).Play with multi-input derivatives!h:0.001a:2.0b:-3.0c:10.0Derivatives with respect to:abc\\( \\text{D1} = a * b + c = \\)+= \\( h = \\)\\( \\text{D2} = a * b + c = \\)\\( \\text{Slope} = \\frac{{d2 - d1}}{{h}} = \\)Differentiate \\( a * b + c \\) with respect toisand with adding slope of \\( h = \\)0.001isImplementing backpropagationNow that a basic understanding of the derivative has been established, let's move forward with building the neural networks. The first step involves creating a class capable of handling N-dimensional array. The values and gradients will be stored in this class, as neural networks entail complex mathematical expressions. The development of these data structures will commence promptly. However, prior to that, the process of backpropagation will be manually performed. Subsequently, the automation of backpropagation will be achieved using the example-based explanation provided below.Manual backpropagationIn this section, the exploration of the manual process of backpropagation will take place, which involves utilizing the chain rule to compute gradients. Backpropagation is a technique that leverages the chain rule to efficiently calculate gradients in a neural network with multiple layers. By propagating the error backwards through the layers, it becomes a crucial algorithm for training neural networks.The chain rule plays a vital role by allowing us to break down the intricate task of adjusting weights and biases in a neural network into smaller, manageable steps. By considering the influence of each layer on the subsequent layer, we can ascertain how modifications in the network's parameters impact its output. This knowledge is then utilized to enhance the network's performance during the training process.In order to comprehend the process, we will manually demonstrate the assignment and initialization of variables, followed by performing calculations on them to construct an expression. It is important to note that the subsequent section will illustrate how these tasks can be accomplished programmatically.\\( a = 2.0 \\)\\( b = -3.0 \\)\\( c = 10.0 \\)\\( e = a * b \\)\\( d = e + c \\)\\( f = -2.0 \\)\\( L = d * f \\)Substitute the expressions to obtain the expression for \\( L \\):\\( L = d * f \\)\\( L = (e + c) * f \\)\\( L = (a * b + c) * f \\)Expand the expression:\\( L = (2.0 * -3.0 + 10.0) * -2.0 \\)\\( L = (-6.0 + 10.0) * -2.0 \\)\\( L = 4.0 * -2.0 \\)\\( L = -8.0 \\)Next, we will visually represent the output and observe its appearance. It is not necessary to concern ourselves with the specifics of graph generation at this point, as the upcoming section will provide detailed instructions on how to generate such graphs.Manually assign the gradient value of the variable \\( L.grad \\) to \\( 1.0 \\).Upon updating the gradient value of the variable \\( L.grad \\) to \\( 1.0 \\), the resulting diagram will display the following visual representation.Differentiation process for product expressionsMoving forward with the backpropagation process, our focus will now shift towards examining the derivatives of \\( L \\) with respect to \\( d \\) and \\( f \\). Our first step will involve calculating the derivative of \\( d \\).To differentiate \\( L \\) with respect to \\( d \\), we treat all other variables (\\( a \\), \\( b \\), \\( c \\), and \\( f \\)) as constants since they don't depend on \\( d \\). The derivative of \\( a \\) constant multiplied by \\( a \\) variable is simply the constant itself. Therefore, the derivative of \\( d \\) with respect to \\( d \\) is \\( 1 \\):\\( \\frac{{dL}}{{dd}} = f * 1 \\)\\( \\frac{{dL}}{{dd}} = -2.0 * 1 \\)\\( \\frac{{dL}}{{dd}} = -2.0 \\)So, the derivative of \\( L \\) with respect to \\( d \\), denoted as \\( \\frac{{dL}}{{dd}} \\), is equal to \\( -2.0 \\).We can prove that the derivative of \\( L \\) with respect to \\( d \\), denoted as \\( \\frac{{dL}}{{dd}} \\), is equal to \\( -2.0 \\) using the definition of the derivative.Given:\\( L = d * f \\)The derivative of \\( L \\) with respect to \\( d \\), denoted as \\( \\frac{{dL}}{{dd}} \\), is defined as the limit of the difference quotient as \\( h \\) approaches \\( 0 \\):\\( \\frac{{dL}}{{dd}} = \\lim_{{h \\to 0}} \\frac{{L(d + h) - L(d)}}{{h}} \\)Substitute the expression for \\( L \\):\\( \\frac{{dL}}{{dd}} = \\lim_{{h \\to 0}} \\frac{{(d + h) * f - d * f}}{{h}} \\)Expand the expression:\\( \\frac{{dL}}{{dd}} = \\lim_{{h \\to 0}} \\frac{{d * f + h * f - d * f}}{{h}} \\)Simplify:\\( \\frac{{dL}}{{dd}} = \\lim_{{h \\to 0}} \\frac{{h \\cdot f}}{{h}} \\)Cancel out \\( h \\):\\( \\frac{{dL}}{{dd}} = \\lim_{{h \\to 0}} f \\)Substitute the value of \\( f \\):\\( \\frac{{dL}}{{dd}} = -2.0 \\)Therefore, the derivative of \\( L \\) with respect to \\( d \\), denoted as \\( \\frac{{dL}}{{dd}} \\), is indeed equal to \\( -2.0 \\).We can apply the same mathematical principles to solve the derivatives of the product expressions. For instance, the derivative of \\( L \\) with respect to \\( d \\) is equal to \\( f \\), and the derivative of \\( L \\) with respect to \\( f \\) is equal to \\( d \\), with a specific value of \\( 4.0 \\). By following this logic, you can solve similar examples without the need for repetitive differentiation.Update the gradient values of the variables \\( d \\) and \\( f \\). Specifically, \\( d.grad \\) will be assigned a value of \\( -2.0 \\), and \\( f.grad \\) will be assigned a value of \\( 4.0 \\). Once these updates are applied, the resulting diagram will display the following visual representation.Differentiation process for sum expressionsThe next step involves determining the gradient values of the variables \\( e \\) and \\( c \\).To find the derivative of the expression \\( d = c + e \\) with respect to \\( c \\), we differentiate the expression with respect to \\( c \\) while treating \\( e \\) as a constant. Since the derivative of a constant with respect to any variable is \\( 0 \\), the derivative of \\( e \\) with respect to \\( c \\) is \\( 0 \\).Therefore, the derivative of \\( d \\) with respect to \\( c \\), written as \\( \\frac{{dd}}{{dc}} \\), is simply \\( 1 \\).To prove the derivative of \\( d = c + e \\) with respect to \\( c \\) using the definition of the derivative, we need to compute the following limit:\\( \\frac{{dd}}{{dc}} = \\lim_{{h \\to 0}} \\frac{{d(c + h) - d(c)}}{{h}} \\)Start by evaluating \\( d(c + h) \\) and \\( d(c) \\):\\( d(c + h) = (c + h) + e = c + h + e \\)\\( d(c) = c + e \\)Substituting these values into the limit expression, we have:\\( \\frac{{dd}}{{dc}} = \\lim_{{h \\to 0}} \\frac{{c + h + e - (c + e)}}{{h}} \\)Simplifying the expression inside the limit:\\( \\frac{{dd}}{{dc}} = \\lim_{{h \\to 0}} \\frac{{c + h + e - c - e}}{{h}} \\)\\( \\lim_{{h \\to 0}} \\frac{{h}}{{h}} \\)\\( \\lim_{{h \\to 0}} 1 \\)\\( = 1 \\)Therefore, we have shown that the derivative of \\( d = c + e \\) with respect to \\( c \\) is \\( 1 \\), which confirms our initial result.We can apply the same mathematical principles to solve the derivatives of sum expressions. For instance, the derivative of \\( d \\) with respect to \\( c \\) is equal to \\( 1.0 \\), and the derivative of \\( d \\) with respect to \\( e \\) is equal to \\( 1.0 \\). By following this logic, you can solve similar examples without the need for repetitive differentiation.We have obtained the local derivatives of \\( \\frac{{dL}}{{dd}} \\), \\( \\frac{{dd}}{{dc}} \\), and \\( \\frac{{dd}}{{de}} \\). Now, let's determine the derivatives of \\( L \\) with respect to \\( c \\) and \\( e \\), represented as \\( \\frac{{dL}}{{dc}} \\) and \\( \\frac{{dL}}{{de}} \\), respectively.To find \\( \\frac{{dL}}{{dc}} \\), apply the Chain rule:\\( \\frac{{dL}}{{dc}} = \\frac{{dL}}{{dd}} * \\frac{{dd}}{{dc}} \\)\\( \\frac{{dL}}{{dc}} = -2.0 * 1.0 \\)\\( \\frac{{dL}}{{dc}} = -2.0 \\)Similarly, employing the Chain rule, we can find \\( \\frac{{dL}}{{de}} \\):\\( \\frac{{dL}}{{de}} = \\frac{{dL}}{{dd}} * \\frac{{dd}}{{de}} \\)\\( \\frac{{dL}}{{de}} = -2.0 * 1.0 \\)\\( \\frac{{dL}}{{de}} = -2.0 \\)Update the gradient values of the variables \\( c \\) and \\( e \\). Specifically, \\( c.grad \\) will be assigned a value of \\( -2.0 \\), and \\( e.grad \\) will be assigned a value of \\( -2.0 \\). Once these updates are applied, the resulting diagram will display the following visual representation.Finally, in order to determine the local derivative of \\( e \\) with respect to \\( a \\) and \\( b \\), we will employ thedifferentiation method for product expressions. According to this approach, the derivative of \\( e \\) with respect to \\( a \\) is equivalent to \\( b \\), whose value is \\( -3.0 \\), and the derivative of \\( e \\) with respect to \\( b \\) is equal to \\( a \\), whose value is \\( 2.0 \\). Therefore, we now possess the values of \\( \\frac{{dL}}{{de}} \\), \\( \\frac{{de}}{{da}} \\), and \\( \\frac{{de}}{{db}} \\). To find the values of \\( \\frac{{dL}}{{da}} \\) and \\( \\frac{{dL}}{{db}} \\), we will utilize the chain rule, as demonstrated above.To find \\( \\frac{{dL}}{{da}} \\), apply the Chain rule:\\( \\frac{{dL}}{{da}} = \\frac{{dL}}{{de}} * \\frac{{de}}{{db}} \\)\\( \\frac{{dL}}{{da}} = -2.0 * -3.0 \\)\\( \\frac{{dL}}{{da}} = 6.0 \\)Similarly, employing the Chain rule, we can find \\( \\frac{{dL}}{{db}} \\):\\( \\frac{{dL}}{{db}} = \\frac{{dL}}{{de}} * \\frac{{de}}{{da}} \\)\\( \\frac{{dL}}{{db}} = -2.0 * 2.0 \\)\\( \\frac{{dL}}{{db}} = -4.0 \\)Update the gradient values of the variables \\( a \\) and \\( b \\). Specifically, \\( a.grad \\) will be assigned a value of \\( 6.0 \\), and \\( b.grad \\) will be assigned a value of \\( -4.0 \\). Once these updates are applied, the resulting diagram will display the following visual representation.Now that we have gained an understanding of manual backpropagation, if you wish to verify the accuracy of the gradient values obtained through differentiation, you can explore the interactive sections forsingleandmultipleinput derivatives. Additionally, we will now proceed to automate the backpropagation process. By comparing the gradient values obtained through automation with the manually calculated values, we can ensure the accuracy of our process and calculations.Automate backpropagationThe functionality of theValueclass is to implement automatic differentiation, which allows for computing gradients of mathematical expressions with respect to their inputs. The class represents a value or variable in a computational graph, where each value can be connected to other values through mathematical operations.Let's proceed with creating one function at a time within theValueclass, and meticulously analyze each line of the code to provide an explanation of its purpose and functionality.The__init__method initializes an instance of theValueclass. It takes in adataparameter, which can be a NumPy array or any data that can be converted into a NumPy array. Ifdatais already a NumPy array, it is stored directly. Otherwise, it is converted into a NumPy array usingnp.array(data).Thegradattribute is initialized as an array of zeros with the same shape as thedataarray. This attribute is used to store the gradient (derivative) of the node with respect to some output.The_backwardattribute is a placeholder for the backward function, which is used for backpropagation in neural networks. It is initially set to a lambda function that does nothing.The_prevattribute is a set that keeps track of the previous nodes (parents) in the computation graph. This is used to determine the dependencies between nodes during backpropagation.The_opattribute stores the operation associated with the current node. This can be used to identify the type of operation performed on the node, such as addition, multiplication, etc.Thelabelattribute is an optional label for the node, which can be used for identification or debugging purposes.In summary, this code defines a class that represents a node in a computation graph, with functionality to store data, compute gradients, and manage dependencies.The__add__method is overridden in theValueclass to define the behavior of the addition operation (+) between twoValueobjects. This method allows adding twoValueinstances together.Inside the__add__method, theotherparameter is checked to see if it is already aValueobject. If not, it is converted into aValueobject usingValue(other).A newValueinstance calledoutis created to represent the result of the addition operation. The data ofoutis obtained by adding the data ofself(the current instance) and the data ofother. The parents ofoutare set asselfandother, and the operation associated withoutis set as '+'.A nested function_backwardis defined within the__add__method. This function is responsible for calculating the gradients using the chain rule and updating the gradients of the operands (selfandother). The gradient ofselfis updated by adding the element-wise multiplication of \\( 1.0 \\) and the gradient ofout. Similarly, the gradient ofotheris updated by adding the element-wise multiplication of \\( 1.0 \\) and the gradient ofout.The_backwardfunction is then assigned to the_backwardattribute of the out instance, effectively replacing the placeholder backward function with the actual backward function.Finally, theoutinstance representing the result of the addition operation is returned.In summary, the__add__method allows adding twoValueinstances together and defines the necessary computations for calculating gradients during backpropagation.The__mul__method is overridden in theValueclass to define the behavior of the multiplication operation (*) between twoValueobjects. This method allows multiplying twoValueinstances together.Similar to the__add__method, theotherparameter is checked to determine if it is already aValueobject. If not, it is converted into aValueobject usingValue(other).A newValue instance calledoutis created to represent the result of the multiplication operation. The data ofoutis obtained by element-wise multiplying the data ofself(the current instance) and the data ofother. The parents ofoutare set asselfandother, and the operation associated withoutis set as '*'.A nested function_backwardis defined within the__mul__method. This function calculates the gradients using the chain rule and updates the gradients of the operands (selfandother). The gradient of self is updated by adding the element-wise multiplication ofother.dataand the gradient of out. Similarly, the gradient ofotheris updated by adding the element-wise multiplication ofself.dataand the gradient ofout.The_backwardfunction is assigned to the_backwardattribute of theoutinstance, replacing the placeholder backward function.Finally, theoutinstance representing the result of the multiplication operation is returned.In summary, the__mul__method allows multiplying twoValueinstances together and defines the necessary computations for calculating gradients during backpropagation.The__pow__method is overridden in theValueclass to define the behavior of the power operation (**) between twoValueobjects. This method allows raising aValueinstance to a scalar exponent or element-wise raising aValueinstance to anotherValueinstance.If theotherparameter is a scalar (integer or float), an element-wise power operation is performed. Theself.datais raised to the power ofother, and the result is stored inout_data. A newValueinstance calledoutis created without_dataas the data,selfas the parent, andf'**{other}'as the operation label.The_backwardfunction is defined for the scalar exponent case. It calculates the gradients using the chain rule and updates the gradient ofself. The gradient update involves multiplyingotherwithnp.power(self.data, other - 1)and then multiplying the result with the gradient ofout. The computed gradient is added toself.grad.If theotherparameter is aValueinstance, an element-wise power operation is performed. Theself.datais raised to the power ofother.data, and the result is stored inout_data. A newValueinstance calledoutis created without_dataas the data,selfandotheras parents, and '**' as the operation label.The_backwardfunction is defined for theValueexponent case. It calculates the gradients using the chain rule and updates the gradients ofselfandother. The gradient update forselfinvolves multiplyingother.datawithnp.power(self.data, other.data - 1)and then multiplying the result with the gradient ofout. The computed gradient is added toself.grad. The gradient update forotherinvolves multiplyingnp.log(self.data)with the gradient ofoutand adding it toother.grad.In case theotherparameter is neither a scalar nor aValueinstance, aTypeErroris raised to indicate unsupported operand types.In summary, the__pow__method allows raising aValueinstance to a scalar exponent or element-wise raising aValueinstance to anotherValueinstance. It defines the necessary computations for calculating gradients during backpropagation in each case.The code provides additional method overrides in theValueclass:__radd__method allows performing right addition by theValueinstance. It returns the result of additionselfbyotherusing the+operator.__rmul__method allows performing right multiplication by theValueinstance. It returns the result of multiplyingselfbyotherusing the*operator.__truediv__method allows performing true division by theValueinstance. It returns the result of dividingselfbyotherusing the/operator. This is achieved by multiplyingselfbyotherraised to the power of \\( -1 \\).__neg__method allows performing negation of theValueinstance. It returns the negation ofselfby multiplying it with \\( -1 \\).__sub__method allows performing subtraction of aValueinstance. It returns the result of subtractingotherfromselfusing the-operator. This is achieved by addingselfto the negation ofother.These method overrides provide convenient shorthand notations for arithmetic operations involvingValueinstances and allow for a more expressive and intuitive usage of theValueclass.Theexpmethod is defined in theValueclass to compute the element-wise exponential of aValueinstance.The method begins by retrieving theself.dataarray and assigning it to the variablex.A newValueinstance calledoutis created with the exponential ofxas the data. The parents ofoutare set to(self,), indicating thatselfis the parent node. The operation label is set as'exp'to represent the exponential operation.A nested function_backwardis defined to calculate the gradients using the chain rule. In this case, the gradient ofselfis updated by adding the element-wise multiplication ofout.dataand the gradient ofout.The_backwardfunction is assigned to the_backwardattribute of theoutinstance, replacing the placeholder backward function.Finally, theoutinstance representing the result of the exponential operation is returned.In summary, theexpmethod computes the element-wise exponential of aValueinstance and defines the necessary computations for calculating gradients during backpropagation.Thetanhmethod is defined in theValueclass to compute the element-wise hyperbolic tangent of aValueinstance.The method begins by retrieving theself.dataarray and assigning it to the variablex.The hyperbolic tangent ofxis calculated usingnp.tanh(x)and assigned to the variablet.A newValueinstance calledoutis created withtas the data. The parent ofoutis set to(self,), indicating thatselfis the parent node. The operation label is set as'tanh'to represent the hyperbolic tangent operation.A nested function_backwardis defined to calculate the gradients using the chain rule. In this case, the gradient ofselfis updated by adding the element-wise multiplication of(1 - t**2)and the gradient ofout. The derivative(1 - t**2)corresponds to the derivative of the hyperbolic tangent function.The_backwardfunction is assigned to the_backwardattribute of theoutinstance, replacing the placeholder backward function.Finally, theoutinstance representing the result of the hyperbolic tangent operation is returned.In summary, thetanhmethod computes the element-wise hyperbolic tangent of aValueinstance and defines the necessary computations for calculating gradients during backpropagation.Thebackwardmethod is defined in theValueclass to perform backpropagation and compute gradients for the computational graph.The method begins by initializing an empty list calledtopoto store the topological order of nodes and a set calledvisitedto keep track of visited nodes.A nested function calledbuild_topois defined to recursively build the topological order of nodes starting from a given nodev. The function checks if the nodevhas been visited before. If not, it addsvto thevisitedset and recursively callsbuild_topofor each child node ofv. After visiting all child nodes, it appendsvto thetopolist. This ensures that nodes are added to thetopolist in a topological order, i.e., parents before children.Thebuild_topofunction is invoked withselfas the starting node to build the topological order of nodes.The gradient of the output node (assumed to be a scalar loss) is set to ones usingnp.ones_like(self.data). This initializes the gradient for backpropagation.The method then iterates through the nodes in reverse order using thereversedfunction on thetopolist. For each node, it calls the_backwardfunction associated with that node. The_backwardfunction was assigned in the respective arithmetic and mathematical operation methods, and it calculates and updates the gradients of the node's parents based on the chain rule.By traversing the nodes in reverse topological order, thebackwardmethod ensures that the gradients are calculated correctly and efficiently.In summary, thebackwardmethod performs backpropagation by traversing the computational graph in reverse topological order and calling the_backwardfunction for each node to compute the gradients.The__repr__method is overridden in theValueclass to provide a string representation of aValueinstance.The method returns a string that includes the value of thedataattribute of theValueinstance. It uses f-string formatting to construct the string representation in the formatValue(data=), whereis replaced with the actual value ofself.data.This allows for a concise and informative representation of aValueinstance when it is printed or converted to a string.In summary, the__repr__method provides a string representation of aValueinstance, making it easier to understand and debug the object when printed or converted to a string.Visualize the expressionsSince theValueclass performs computation on expressions that can potentially be large, depending on the inputs, it would be beneficial to have a visually appealing representation of these expressions. This visualization would allow us to better understand and gain a sense of how the results of these expressions look, facilitating comprehension and analysis.To visualize the computational graph, we will use theGraphvizlibrary.We will create a pair of functions. The initial function will trace the computational graph starting from a given node and provide a collection of nodes and edges that depict the graph. The second function will accept a root node as input and produce a visual representation of the computational graph rooted at that node. Furthermore, we will meticulously examine each line of the code to ensure precise explanations of its purpose and functionality.The code defines a function calledtracethat takes arootnode as input and returns a set of nodes and edges that represent a trace of the computational graph rooted at therootnode.The function first initializes empty sets callednodesandedgesto store the nodes and edges of the graph, respectively.A nested function calledbuildis defined to recursively build the set of nodes and edges starting from a given nodev. The function checks if the nodevis already in thenodesset. If not, it addsvto thenodesset and proceeds to iterate over the previous nodes (parents) ofv. For each previous node (child), it adds an edge fromchildtovin theedgesset and recursively callsbuildon the previous node (child).Thebuildfunction is invoked initially with therootnode to start building the set of nodes and edges.Finally, the function returns the set of nodes (nodes) and edges (edges).In summary, thetracefunction traces the computational graph rooted at a given node and returns the set of nodes and edges that represent the graph.The code defines a function calleddraw_dotthat takes arootnode as input and generates a visualization of the computational graph rooted at therootnode using the Graphviz library.The function begins by creating aDigraphobject nameddotwith the format set to SVG and the graph attributerankdirset to 'LR' to arrange the nodes from left to right.Thetracefunction is called to retrieve the set of nodes and edges that represent the computational graph rooted at therootnode.The function then iterates over the nodes in thenodesset. For each node n, it assigns a unique ID (uid) based on the node's ID usingstr(id(n)). It converts thedataandgradarrays of the node into string representations usingnp.array2stringwith specified precision, separator, and suppression of small values. It creates the label for the node by combining the node's label, data string, and gradient string. The node is added to the graph with the unique ID, label, and shape 'record' to visualize the node as a record-shaped box.If the node has an associated operation (n._op), it adds an additional node to the graph with a unique ID based on the node's ID and operation, and labels it with the operation. An edge is added from the operation node to the current node (n) in the graph.Next, the function iterates over theedgesin the edges set. For each edge (n1,n2), it adds an edge from the ID of the first node (n1) to the ID of the second node (n2) concatenated with the operation name (n2._op).Finally, the function returns the generated graph (dot).Overall, thedraw_dotfunction generates a visualization of the computational graph rooted at a given node by creating nodes and edges in aDigraphobject using Graphviz. The nodes represent theValueinstances in the graph, and the edges represent the dependencies between the nodes based on their parent-child relationships. The labels of the nodes display information such as the node's label, data, and gradient.Example 1: Compute a forward pass on 2D array and visualize the computation graphIn this first example, we will perform a forward pass on the tanh function and subsequently visualize it. The inputs, weights, and biases will all be 2D array with the same values to ensure accurate calculations. You can copy the code and modify these values to observe different results.Output:Here is a visual representation illustrating the forward pass of the tanh function.Example 1: Performing backward propagation and visualizing the updated computation graphCompute gradients for the variableothrough backward propagation to determine its impact on the hyperbolic tangent function (tanh).Output:Here is a visual representation illustrating the backward propagation process of the tanh function.Example 2: Compute a forward pass on scalar values, perform backward propagation, and visualize the computation graphIn this second example, we will execute a forward pass on the tanh function, followed by the computation of gradients through backward propagation, and then visualize the results. The inputs, weights, and biases will be scalar values, identical to those used in Example 1, to ensure precise calculations. Feel free to copy the code and modify these values to observe varying outcomes.Output:Here is a visual representation that illustrates both the forward pass and backward propagation processes of the tanh function. Please compare this graph with the one from Example 1 to ensure that the gradient values are the same.Example 3: Compute a forward pass and perform backward propagation on the tanh function using PyTorchIn this example, we will use the same values for the input, weight, and bias variables, along with the tanh function from the PyTorch library. The purpose is to validate the accuracy and consistency of the calculations carried out by our Autograd class. By comparing the results, we can confirm their similarity.Building a neural network libraryWe will now build a neural network library that consists of three classes: Neuron, Layer, and MLP. The Neuron class defines a single neuron in a multi-layer perceptron (MLP) with randomly assigned weights and bias. It performs computations and applies the hyperbolic tangent activation function. The Layer class represents a layer of neurons and computes outputs based on inputs. The MLP class constructs an MLP with a customizable architecture, allowing inputs to propagate through all layers to produce a final output. Both the Neuron and Layer classes have a parameters method to retrieve their specific parameters. Overall, the code offers the necessary functionality for defining and utilizing MLP models, enabling the propagation of inputs and the retrieval of parameters.Let's proceed with creating one class at a time and meticulously analyze each line of the code to provide an explanation of its purpose and functionality.The code imports therandommodule, which is used for generating random numbers.ANeuronclass is defined, representing a single neuron in a neural network.The__init__method initializes the neuron with random weights and a bias. The number of input connections (inputs) to the neuron is specified by nin. The weights are randomly initialized using therandom.uniformfunction between -1 and 1, and stored in a listself.w. The bias is also randomly initialized and stored inself.b.The__call__method implements the behavior of the neuron. Given an inputx, it calculates the weighted sum of inputs multiplied by weights, adds the bias, applies the hyperbolic tangent function to the result (activation), and returns the output of the neuron.Theparametersmethod returns the parameters of the neuron, which include the weights(self.w)and the bias(self.b).In summary, theNeuronclass represents a single neuron in a neural network. It has methods for initialization, computing the output of the neuron, and retrieving the neuron's parameters. The neuron's weights and bias are randomly initialized within a specified range. The neuron computes its output by calculating the weighted sum of inputs, adding the bias, and applying the hyperbolic tangent function to the result. The neuron's parameters include the weights and bias.ALayerclass is defined, representing a layer of neurons in a neural network.The__init__method initializes a layer with a specified number of input neurons (nin) and output neurons (nout). It creates a list ofnoutneurons by using a list comprehension. Each neuron in the list is created by calling theNeuronclass with nin as the number of input connections.The__call__method computes the output of each neuron in the layer given an inputx. It iterates over the neurons in the layer and calls each neuron withx, collecting the outputs in a list namedouts. If there is only one output neuron, it returns the output directly; otherwise, it returns the list of outputs.Theparametersmethod returns the parameters of all neurons in the layer. It achieves this by iterating over the neurons in the layer and calling theparametersmethod of each neuron. The parameters of each neuron are then flattened into a single list using a list comprehension and returned.In summary, theLayerclass represents a layer of neurons in a neural network. The layer is initialized with a specified number of input and output neurons. The layer contains a list of neurons, each created with the specified number of input connections. The layer's__call__method computes the output of each neuron in the layer given an input. The outputs are collected in a list, and if there is only one output neuron, it is returned directly; otherwise, the list of outputs is returned. The layer'sparametersmethod returns the parameters of all neurons in the layer by iterating over the neurons, calling theirparametersmethod, and flattening the parameters into a single list.AnMLP(Multi-Layer Perceptron) class is defined, representing a multi-layer neural network.The__init__method initializes an MLP with the specified number of input neurons (nin) and a list of output neurons for each layer (nouts). It creates a listszthat contains the sizes of all layers, starting with the input layer size (nin) followed by the output sizes of each layer (nouts). Each layer in the MLP is created by using a list comprehension and calling theLayerclass. The size of each layer is determined bysz[i]as the number of input neurons andsz[i+1]as the number of output neurons.The__call__method performs forward propagation through the MLP. It iterates over the layers in the MLP and sequentially applies each layer to the inputx. The output of each layer becomes the input for the next layer. Finally, it returns the final output of the MLP.Theparametersmethod returns the parameters of all layers in the MLP. It achieves this by iterating over the layers in the MLP and calling theparametersmethod of each layer. The parameters of each layer are then flattened into a single list using a list comprehension and returned.In summary, theMLPclass represents a multi-layer perceptron (MLP), which is a type of neural network. The MLP is initialized with the number of input neurons and a list of output neurons for each layer. The MLP consists of multiple layers, where each layer is represented by theLayerclass. The__call__method performs forward propagation through the MLP by sequentially applying each layer to the input. The final output of the MLP is returned. Theparametersmethod returns the parameters of all layers in the MLP by iterating over the layers, calling theirparametersmethod, and flattening the parameters into a single list.Perform forward propagationWe will now assign input values, build an MLP with a predetermined structure, and then perform forward propagation to calculate and obtain the output.The code sets the input valuesxto[2.0, 3.0, -1.0].AnMLPobject namednis created. It is initialized with 3 input neurons and a list[4, 4, 1]representing the number of neurons in each hidden layer and the output layer. Therefore, the MLP has 3 hidden layers, each with 4 neurons, and 1 output neuron.The__call__method of theMLPobjectnis called with the input valuesx. This triggers the forward propagation of the input through all layers of the MLP.The__call__method sequentially applies each layer in the MLP to the input. It iterates over the layers stored in theself.layersattribute of the MLP and applies each layer to the input. The output of each layer becomes the input for the next layer.The final output of the MLP is returned.In summary, this sets the input values for the MLP, creates an MLP object with a specific architecture (3 input neurons, 3 hidden layers with 4 neurons each, and 1 output neuron), and performs forward propagation by calling the MLP object with the input values. The output of the MLP is then returned.Training a neural networkMoving forward, our next steps involve initiating the training process of a neural network. We will commence by creating a small dataset and subsequently proceed to train the MLP model with the goal of minimizing the loss and improving its prediction capabilities. Lastly, we will present the list of predicted outputs.Create datasetNow, our next step is to create a small dataset.The code sets the input values for the training examples in a list namedxs. Each training example is represented as a list of input values. In this case, there are four training examples, each with three input values.The code sets the desired target values for the training examples in a list namedys. Each target value corresponds to a training example inxs. In this case, there are four target values.The code provides a comment indicating the correspondence between the training examples and their respective target values. For example,xs[0]corresponds toys[0],xs[1]corresponds toys[1], and so on.In summary, this sets the input values for a set of training examples in the listxsand the desired target values in the listys. The correspondence between the training examples and their target values is indicated through the comment. These data are typically used for training a machine learning model, where the model learns to map the input values inxsto the corresponding target values inys.Train the MLP modelNow start the training process of the MLP model with the objective of minimizing the loss and enhancing its predictive capabilities.Continue iterating until the loss is minimized and the predictions reach the desired level of improvement.The code initiates a loop that runs for 20 iterations using therange(20)function.Within each iteration:The forward pass is performed by applying the MLP objectnto each input in thexslist using a list comprehension. This generates a list of predicted outputsypredcorresponding to each input inxs.The loss is calculated by summing the squared differences between the predicted outputsyoutand the corresponding target valuesygtusing a generator expression and thesum()function.The backward pass is performed to compute the gradients of the loss with respect to the parameters of the MLP. First, the gradients of all parameters in the MLP are set to zero by iterating over the parameters using the n.parameters()method and settingp.grad = 0.0for each parameterp.The gradients are computed using thebackward()method of the loss. This method calculates the gradients using automatic differentiation and the chain rule.The weights of the MLP are updated by iterating over the parameters and performing a gradient descent update. Each weightp.datais updated by subtracting0.5 * p.gradfrom its current value.The iteration numberkand the value of the loss are printed using theprint()function.In summary, this trains the MLP model for 20 iterations using a training loop. In each iteration, a forward pass is performed to compute the predicted outputs, and the loss is calculated by comparing the predicted outputs to the target values. Then, a backward pass is performed to compute the gradients of the loss with respect to the model parameters. The weights of the model are updated using gradient descent. The iteration number and the value of the loss are printed after each iteration. This process aims to train the MLP model to minimize the loss and improve its predictions.Predicted outputsLastly, the list of predicted outputs will be displayed.The code generates a list comprehension where each inputxin thexslist is passed through the MLP objectn. This applies the MLP's forward propagation to each input and produces a list of predicted outputs.In summary, this calculates the predicted outputs for each input in thexslist using the MLP objectn. Theypredlist contains these predicted outputs.SummaryNeural networks are mathematical expressions, specifically multi-layer perceptrons, that process input data using weights and parameters. They employ a loss function to assess prediction accuracy and aim to minimize this loss through manipulation and backpropagation to obtain gradients. By iteratively adjusting parameters using gradient descent, the network's performance improves over time. Neural networks can tackle complex problems and scale up to billions or trillions of parameters. Training them on large datasets, like GPT for language modeling, unveils emergent properties. Despite slight variations, the fundamental principles of neural network training remain consistent, making the process broadly applicable.Project's codeHereis the project's repository, containing the necessary files. Inside the repository, you will discover anengine.pyfile where I implemented the code for theValueclass, and alibrary.pyfile that includes the code for the neural network library. The library.py file imports theValueclass from the engine.py file. Furthermore, I have included a Jupyternotebookfile, which you can export to an editor and experiment with.References and further reading3Blue1Brown'svideo serieson basics of neural networks and backpropagation.Alammar, J (2018). The Illustrated Transformer [Blog post]. Retrieved fromhttps://jalammar.github.io/illustrated-transformer/Vaibhav Kumar'sblog poston PyTorch Autograd.Andrej Karaphy'sMicrogradand hisvideo tutorialabout building Micrograd.\n",
      "---\n",
      "Ninth Dedekind number discovered: long-known problem in mathematics solved\n",
      "400 Bad requestYour browser sent an invalid request.We highly recommend setting a meaningful User-Agent header.\n",
      "---\n",
      "Working with Docker containers with the dexec bash script\n",
      "403 Forbidden403 Forbiddennginx\n",
      "---\n",
      "Detect Food Adulteration with Easy Home Tests\n",
      "Dart: Detect Adulteration with rapid testMilk & Milk ProductsOil and FatsSugar & ConfectioneryFood Grains & Its ProductsSalt, Spices & CondimentsFruits & VegetablesBeveragesSensory evaluation quick testsAboutGet In TouchDetect Adulteration With Rapid TestCommon quick tests for detection of some food adulterants at household.Milk & Milk Products4 TestsOil and Fats3 TestsSugar & Confectionery3 TestsFood Grains & Its Products9 TestsSalt, Spices & Condiments18 TestsFruits & Vegetables3 TestsBeverages4 TestsSensory evaluation quick testsDetect Adulteration With Rapid TestCommon quick tests for detection of some food adulterants at household.Milk & Milk Products4 TestsOil and Fats3 TestsSugar & Confectionery3 TestsFood Grains & Its Products9 TestsSalt, Spices & Condiments18 TestsFruits & Vegetables3 TestsBeverages4 TestsSensory evaluation quick testsAboutDARTFood is essential for sustenance of life. Adulteration of food deceive the consumer and can cause risk to their health. The purpose of this manual is to list out common methodologies available for food adulterants generally found in India.The scope of this manual is meant for household, which can induce awareness among the consumer about food safety.Milk & Milk ProductsTest 1 : Detection of water in milkTesting Method:Put a drop of milk on a polished slanting surface.Pure milk either stays or flows slowly leaving a white trail behind.Milk adulterated with water will flow immediately without leaving a mark.Pure milkPure milkAdulterated milkAdulterated milkTest 2 : Detection of detergent in milkTesting Method:Take 5 to 10ml of sample with an equal amount of water.Shake the contents thoroughly.If milk is adulterated with detergent, it forms dense lather.Pure milk will form very thin foam layer due to agitation.Pure milkPure milkAdulterated milkAdulterated milkTest 3 : Detection of starch in milk and milk products (khoya, chenna, paneer)Testing Method:Boil 2-3 ml of sample with 5ml of water.Cool and add 2-3 drops of tincture of iodine.Formation of blue colour indicates the presence of starch.(In the case of milk, addition of water and boiling is not required)Pure milkPure milkAdulterated milkAdulterated milkTest 4 : Detection of mashed potatoes, sweet potatoes and other starches in ghee/butterTesting Method:Take ½ teaspoon of ghee/butter in a transparent glass bowl.Add 2-3 drops of tincture of iodine.Formation of blue colour indicates the presence of mashed potatoes, sweet potatoes and other starches.PurePureAdulteratedAdulteratedOil and FatsTest 1 : Detection of other oils in coconut oilTesting Method:Take coconut oil in a transparent glass.Place this glass in refrigerator for 30 minutes.(Do not keep in the freezer)After refrigeration, coconut oil solidifies.If coconut oil is adulterated, then other oils remain as a separate layer.PurePureAdulteratedAdulteratedTest 2 : Detection of TOCP (Tri-Ortho-Cresyl-Phosphate) in oils and fatsTesting Method:Take 2ml of sample of oil.Add on a little amount of yellow butter (Solid).Immediate formation of red colour indicates the presence of TOCP.PurePureAdulteratedAdulteratedTest 3 : Proper winterization of refined winterized salad oilsTesting Method:Take 100ml sample oil in bottle, cork tightly and seal with paraffin.The bottle is completely submerged in bucket containing finely cracked ice and water is added until it rises to top of the bottle.The bucket is kept filled solidly with ice by removing any excess water and adding ice when necessary.After 5.5 hours remove the bottle and examine oil.If it is properly winterised, sample will be brilliant, clear and limpid.Refined winterized salad oilsRefined winterized salad oilsSugar & ConfectioneryTest 1 : Detection of sugar solution in honeyTest Method 1Test Method 2Take a transparent glass of water.Add a drop of honey to the glass.Pure honey will not disperse in water.If the drop of honey disperses in water, it indicates the presence of added sugarPurePureAdulteratedAdulteratedTake a cotton wick dipped in a pure honey and light with a match stick.Pure honey will burn.If adulterated, the presence of water will not allow the honey to burn if it does; it will produce a cracking sound.Test 2 : Detection of chalk powder in sugar/pithi sugar/jaggeryTesting Method:Take a transparent glass of water.Dissolve 10g of sample in water.If sugar/pithi sugar/jaggery is mixed with chalk, the adulterant will settle down at the bottom.PurePureAdulteratedAdulteratedTest 3 : Detection of aluminium leaves in silver leavesTesting Method:Take some portion of the leaf and crush it between two fingers.Pure silver leaves will be easily crushed and crumble to the powder form while aluminium leaves will only break into smaller shreds.Further take the suspected silver leaves and make it in the form of a ball and burn it with the help of a flame.Pure silver leaves burn away completely leaving glistening balls while aluminium leaves are reduced to grey ash.Silver leavesSilver leavesAluminium leavesAluminium leavesFood Grains & Its ProductsTest 1 : Detection of extraneous matter (dust, pebble, stone, straw, weed seeds, damaged grain, weeviled grain, insects, rodent hair and excreta) in food grainsTesting Method:Take small quantity of sample in a glass plate.Examine the impurities visually.Pure food grains will not have any such impurities.Impurities are observed visually in adulterated food grains.PurePureAdulteratedAdulteratedTest 2 : Detection of dhatura in food grainsTesting Method:Take small quantity of food grains in a glass plate.Examine the impurities visually.Dhatura seeds which are flat with edges and blackish brown in colour can be separated out by close examination.Impurities are observed visually in adulterated food grains.Dhatura seeds in food grainsDhatura seeds in food grainsDhatura seedsDhatura seedsTest 3 : Detection of excess bran in wheat flourTesting Method:Take a transparent glass of water.Sprinkle a spoon of wheat flour on the surface of water.Pure wheat flour will not show excess bran on water surface.Impurities are observed visually in adulterated food grains.Pure wheat flourPure wheat flourExcess bran in wheat flourExcess bran in wheat flourTest 4 : Detection of khesari dal in dal whole and splitTesting Method:Take small quantity of dal whole or split in a glass plate.Examine the impurities visually.Khesari dal which has edged type appearance showing a slant on one side and square in appearance can be separated out by close examination.Pure dal will not have any such impurities.Pure dalPure dalKhesari dalKhesari dalTest 5 : Detection of added colour in food grainsTesting Method:Take a transparent glass of water.Add 2 teaspoons of food grains and mix thoroughly.Pure food grains will not leave any colour.Adulterated food grains leaves colour immediately in water.PurePureAdulteratedAdulteratedTest 6 : Detection of turmeric in sella riceTesting Method:Take a tea spoon of rice in a glass plate.Sprinkle a small amount of soaked lime (commonly known as chuna which is used in pan) on the rice grains.Pure grains will not form red colour.Adulterated grains will form red colour.PurePureAdulteratedAdulteratedTest 7 : Detection of rhodamine B in ragiTesting Method:Take cotton ball soaked in water or vegetable oil. (conduct the test separately).Rub the outer surface of the ragi.If cotton absorbs colour, then it indicates the adulteration of rhodamine B for colouring the outer surface of ragi.PurePureAdulteratedAdulteratedTest 8 : Detection of chakunda beans in pulsesTesting Method:Take small quantity of pulses in a transparent glass plate.Examine the impurities visually.Chakunda beans can be separated out by close examination.Chakunda beansChakunda beansTest 9 : Detection of sand soil, insects, webs, lumps, rodent hair and excreta in Atta, Maida, Suji (Rawa)Testing Method:These can be identified by visual examination.Atta, Maida, Suji (Rawa)Atta, Maida, Suji (Rawa)Sand, Soil, insects, webs, lumps, rodent hair & excretaSand, Soil, insects, webs, lumps, rodent hair & excretaSalt, Spices & CondimentsTest 1 : Detection of foreign resin in asafoetida (hing)Test Method 1Test Method 2Burn small quantity of asafoetida in a stainless steel spoon.Pure asafoetida will burn like camphor.Adulterated asafoetida will not produce bright flame like camphor.PurePureAdulteratedAdulteratedPowder a gram of asafoetida and take it in a glass container.Add one tea spoon of water. Mix thoroughly by shaking.Milky white solution with no sediments represents pure asafoetida.AsafetidaAsafetidaNon-Edible Gum/ResinNon-Edible Gum/ResinTest 2 : Detection of papaya seeds in black pepperTest Method 1Test Method 2Add some amount of black pepper to a glass of water.Pure black pepper settles at the bottom.In the adulterated black pepper, papaya seeds float on the surface of water.PurePureAdulteratedAdulteratedSpread spice on a white paper.Observe the appearance of the sample using the magnifying glass.Black pepper is brown in colour. It has a wrinkled surface and has a characteristic smell and pungent taste.The papaya seeds have shrunken smooth surface and oval shape. It is greenish brown or blackish brown in colour and has a repulsive flavour.Black PapperBlack PapperPapaya seedsPapaya seedsTest 3 : Detection of light black berries in black pepperTesting Method:Press the berries with the help of fingers.Light berries will break easily while black berries of pepper will not break.Black pepperBlack pepperLight black berriesLight black berriesTest 4 : Detection of soap stone or other earthy matter in asafoetida (hing)Testing Method:Shake little portion of the sample with water and allow to settle.Pure asafoetida will not leave any soap stone or other earthy matter at the bottom.If asafoetida is adulterated, soap stone or other earthy matter will settle down at the bottom.PurePureAdulteratedAdulteratedTest 5 : Detection of artificial/water soluble synthetic colours in chilli powderTesting Method:Sprinkle chilli powder on the surface of water taken in a glass tumbler.The artificial colourants will immediately start descending in colour streaks.PurePureAdulteratedAdulteratedTest 6 : Detection of light black berries in black pepperTesting Method:Float the sample of black pepper in alcohol (rectified spirit).The mature black pepper berries sink while the light black pepper floats.PurePureAdulteratedAdulteratedTest 7 : Detection of saw dast in chilli powderTesting Method:Add the sample to water.The saw dust will float at the surface of water while Chilli powder will settle down in bottom.Chilli powderChilli powderSaw dustSaw dustTest 8 : Detection of starch in asafoetiaTesting Method:Add the sample to water.The artificial colourants will immediately start descending in colour streaks.AsafoetiaAsafoetiaStarchStarchTest 9 : Detection of chalk in common saltTesting Method:Stir a spoonful of sample of salt in a glass of water.The presence of chalk will make solution white and other insoluble impurities will settle down.Common saltCommon saltChalkChalkTest 10 : Detection of exhausted cloves in cloveTesting Method:Take some water in a glass and put cloves.Genuine cloves will settle down at the bottom while exhausted cloves will float on surface.ClovesClovesVolatile oil extracted clovesVolatile oil extracted clovesTest 11 : Detection of cassia bark in cinnamonTesting Method:Take small quantity of cinnamon in a glass plate.If adulterated, on close visual examination, cassia bark that comprises of several layers in between the rough outer and inner most smooth layers can be differentiated from cinnamon.Cinnamon barks are very thin that can be rolled around a pencil or pen. It has a distinct smell.CinnmonCinnmonCassiaCassiaTest 12 : Detection of grass seeds coloured with charcoal dust in cumin seedsTesting Method:Rub small amount of cumin seeds on palms.If palms turn black, adulteration is indicated.PurePureAdulteratedAdulteratedTest 13 : Detection of argemone seeds in mustard seedsTesting Method:Take small quantity of mustard seeds in a glass plate.Examine visually for the argemone seeds.Mustard seeds have a smooth surface and when pressed, inside it is yellow in colour.Argemone seeds have grainy, rough surface and are black in colour. When pressed, inside it is white in colour.Mustard seedsMustard seedsArgemone seedsArgemone seedsTest 14 : Detection of lead chromate in turmeric wholeTesting Method:Add small quantity of turmeric whole in a transparent glass of water.Pure turmeric will not leave any colour.Adulterated turmeric appears to be bright in colour and leaves colour immediately in water.PurePureAdulteratedAdulteratedTest 15 : Detection of artificial colour in turmeric powderTesting Method:Add a teaspoon of turmeric powder in a glass of water.Natural turmeric powder leaves light yellow colour while settling down.Adulterated turmeric powder will leave a strong yellow colour in water while settling down.PurePureAdulteratedAdulteratedTest 16 : Detection of sawdust and powdered bran in powdered spicesTesting Method:Sprinkle powdered spices on the water surface.Pure spices will not leave any saw dust/powdered bran on the surface of water.If spices are adulterated, saw dust/powdered bran will float on the surface.PurePureAdulteratedAdulteratedTest 17 : Differentiation of common salt and iodised saltTesting Method:Cut a piece of potato, add salt and wait for a minute.Add two drops of lemon juice.If it is iodised salt, blue colour will develop.In the case of common salt, there will be no blue colour.Iodised saltIodised saltCommon saltCommon saltTest 18 : Detection of coloured dried tendrils of maize cob in saffronTesting Method:Genuine saffron will not break easily like artificial. Artificial saffron is prepared by soaking maize cob in sugar and colouring it with coal tar.Take a transparent glass of water and add small quantity of saffron.If saffron is adulterated, the artificial colour dissolves in water rapidly. A bit of pure saffron when allowed to dissolve in water will continue to give its saffron colour so long as it lasts.SaffronSaffronColoured tendrilsColoured tendrilsFruits & VegetablesTest 1 : Detection of malachite green in green vegetables like bitter gound, green chilli and others.Test Method 1Test Method 2Take a cotton piece soaked in water or vegetable oil. (conduct the test separately).Rub the outer green surface of a small part of green vegetable/chilli.If the cotton turns green, then it is adulterated with malachite green.PurePureAdulteratedAdulteratedTake a small part of the sample and place on a piece of moistened white blotting paper.The impression of colour on the paper indicates the use of malachite green, or any other low priced artificial colour.Green VegetablesGreen VegetablesMalachite GreenMalachite GreenTest 2 : Detection of artificial colour on green peas.Testing Method:Take little amount of green peas in a transparent glass.Add water to it and mix well.Let it stand for half an hour.Clear separation of colour in water indicates adulteration.PurePureAdulteratedAdulteratedTest 3 : Detection of rhodamine B in sweet potato.Testing Method:Take a cotton ball soaked in water or vegetable oil. (conduct the test separately).Rub the outer red surface of the sweet potato.If cotton absorbs colour, then it indicates the usage of rhodamine B for colouring the outer surface of sweet potato.PurePureAdulteratedAdulteratedBeveragesTest 1 : Detection of clay in coffee powderTesting Method:Add ½ teaspoon of coffee powder in a transparent glass of water.Stir for a minute and keep it aside for 5 minutes. Observe the glass at the bottom.Pure coffee powder will not leave any clay particles at the bottom.If coffee powder is adulterated, clay particles will settle at the bottom.PurePureAdulteratedAdulteratedTest 2 : Detection of chicory powder in coffee powderTesting Method:Take a transparent glass of water.Add a teaspoon of coffee powder.Coffee powder floats over the water but chicory begins to sink.PurePureAdulteratedAdulteratedTest 3 : Detection of exhausted tea in tea leavesTest Method 1Test Method 2Test Method 3Take a filter paper and spread few tea leaves.Sprinkle with water to wet the filter paper.Wash the filter paper under tap water and observe the stains against light.Pure tea leaves will not stain the filter paper.If coal tar is present, it will immediately stain the filter paper.Take small amount of tea leaves/ dust and place it in the centre of a filter paper.Add water drop by drop at the heap of the tea leaves/ dust.If the tea is adulterated with a coloured tea, water will dissolve the added colour and leave streak of colour in the filter paper.PurePureAdulteratedAdulteratedSpread a little slaked lime on white porcelain tile or glass plate.Sprinkle a little tea dust on the lime.Red, orange or other shades of colour spreading on the lime will show the presence of coal tar colour.In case of genuine tea, there will be only a slight greenish yellow colour due to chlorophyll, which will appear after some time.Test 4 : Detection of iron filings in tea leavesTesting Method:Take small quantity of tea leaves in a glass plate.Move the magnet through the tea leaves.Pure tea leaves will not show any iron filings on the magnet.If adulterated, then iron filings will be seen on the magnet..PurePureAdulteratedAdulteratedSensory evaluation quick testsFood product: MilkAdulterant : Synthetic MilkMethods:Synthetic milk gives bitter after taste.If adulterated, it gives a soapy feeling on rubbing between the fingers.Food product: Black pepper/ ClovesAdulterant : Coated with mineral oilMethods:Black pepper coated with mineral oil gives kerosene like smell.Food product: Chilli powderAdulterant : Brick powder, salt powder or talc. powderMethods:Take teaspoon of chilli powder in a glass of water and examine the residue.When the residue is rubbed & if any grittiness is felt it indicates the presence of brick powder/sand.When the white residue is rubbed, soapy and smooth feel indicates the presence of soap stone.Food product: ClovesAdulterant : Volatile oil extracted cloves (exhausted cloves)Methods:Exhausted cloves can be identified by its small size and shrunken appearance.The characteristic pungency of genuine cloves is less pronounced in exhausted cloves.Food product: SugarAdulterant : UreaMethods:Rub little sugar on palm and smell. If adulterated with urea, it will smell of ammonia.Dissolve a small amount of sugar in water.If adulterated, urea in sugar gives a smell of ammonia.Food product: Wheat, Rice, Maize, Jowar, Bajra, Channa, Barley etcAdulterant : Kernel BuntMethods:Separate out the non-characteristic grains and examine.Kernel bunt has a dull appearance, blackish in colour and rotten fish smell.Food product: AttaAdulterant : Resultant atta/ MaidaMethods:When dough is prepared from resultant atta, less water is needed.The normal taste of chapati prepared out of atta is somewhat sweetish whereas those prepared out of adulterated will taste insipid (tasteless).Food product: SagoAdulterant : Sand or talcumMethods:Put a little quantity of sago in mouth.If adulterated, it will have a gritty feel.Food product: Powdered spicesAdulterant : Common saltMethods:Taste for addition of common salt.If present, it will taste salty.Food product: Sweet meatsAdulterant : Artificial SweetenerMethods:Taste small quantity of sample.Artificial sweetener leaves a lingering sweetness on tongue for a considerable time and leaves a bitter after taste.(Note: This method is applicable if artificial sweetener is used in addition to sugar)Get in touchPhone011-232-37417Emaillabs@fssai.gov.inAddressFDA Bhawan near Bal Bhavan,Kotla Road, New Delhi - 110002 India.only 400 charecters allow3 + 8 =Put sum of both numbers in box.Send messageThank you for contacting us!You are very important to us, all information received will always remain confidential.We will contact you as soon as we review your message.FSSAI© 2023 All Right Reserved\n",
      "---\n",
      "4D Toys Update 8: Rotating the 3D Slice, 2D Faces Projections, Marble Scenes\n",
      "Not Acceptable!Not Acceptable!An appropriate representation of the requested resource could not be found on this server. This error was generated by Mod_Security.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Modern TLS/SSL on 16-bit Windows\n",
      "Modern TLS/SSL on 16-bit WindowsDialup.netWindleWinGPTModern TLS/SSL on 16-bit WindowsLately, there's been an resurgence of new programs written for retro computers—everything     from a Slack client to many Wordle clones, to a Mastodon client. But most of these programs, if they     connect to the Internet, require a proxy running on a modern computer to handle     the SSL/TLS connection, which almost all APIs nowadays require. For my Gateway 4DX2-66 running     Windows 3.11 for Workgroups, making it reliant on a modern machine for any kind of real Internet     use is a sad state of affairs—so I decided to change the status quo.It wasn't that Windows 3.1 didn't support secure connections; Internet Explorer 2, for instance,     supported SSL. But over time, both clients and servers have upgraded to newer versions of the SSL     (now called TLS) protocol and algorithms, and have dropped support for older versions as     vulnerabilities likePOODLEare found with them.Normally, programs can upgrade to using a newer TLS library (e.g. OpenSSL) to get support for     modern TLS, but one of the biggest barriers to this for Windows 3.1 is that it's a 16-bit OS;     TLS libraries today tend to support 32-bit OS's, and sometimes 16-bit OS's for embedded hardware,     but never Windows 3.1 itself.[1]I was inspired byYeo Kheng Meng's notesas he discovered the same challenges for his aforementioned Slack client—it seemed possible     to somehow modify a decent TLS library and convince it to compile and work in the Windows 3.1     environment, and I wanted to give it a shot to give my Gateway, and other Windows 3.1 computers     around the world, the ability to connect to most of the Internet again.What does success look like?To connect to most servers today, we need to be able to speak TLS 1.2.     Older versions of TLS have widely been deprecated by servers in the last few years.     TLS 1.3 is the newest version of TLS, standardized in 2018, so it'll be a bonus to support it as well,     but not all servers support it yet.From Wikipedia:Transport Layer SecurityProtocolPublishedStatusSSL 1.0UnpublishedUnpublishedSSL 2.01995Deprecated in 2011 (RFC 6176)SSL 3.01996Deprecated in 2015 (RFC 7568)TLS 1.01999Deprecated in 2021 (RFC 8996)TLS 1.12006Deprecated in 2021 (RFC 8996)TLS 1.22008In use since 2008TLS 1.32018In use since 2018We also need to support a set of popularcipher suites,     or the algorithms that the TLS protocol uses under the hood to actually exchange keys and encrypt data.     Upon connection, the TLS client tells the server which cipher suites it supports in the \"Client Hello\"     message; if the server doesn't     support any of them, it will reject the connection with a \"No common ciphers\" error. There are 37 cipher     suites for TLS 1.2, so we need to at least support the most common (read: less vulnerable) ones for our client.One non-goal of this effort was actually creating asecureimplementation. Given that I'm already     throwing security out of the window by using 30-year old software on the Internet, I decided it was     okay to make some tradeoffs to get a working implementation. The biggest limitations are that I am     using a fake random number generator, and I am not verifying certificates.Finding the right TLS libraryGiven the success criteria above, I looked into a few different TLS libraries that might work: OpenSSL,     BearSSL, Mbed TLS, and WolfSSL. WolfSSL stood out among the pack as it had explicit 16-bit compiler support     while being fully-featured and well-supported.     It also had a wide range of support code for all sorts of hardware with different constraints—including     limited memory—giving me a plethora of examples I could learn from.I also needed a working TCP/IP stack on Windows. It's hard to believe now, but Windows 3.x didn't come with     TCP/IP built in. There were many options users could choose from, including Trumpet Winsock, a popular     shareware TCP/IP stack. For my testing purposes, I decided to go with Microsoft's own TCP/IP implementation,     TCP/IP-32, which came as a separate download from Microsoft. This provides a TCP/IP implementation which     you interface through Winsock (the Windows Sockets API)—an older version of the same API you can use even     today on Windows 11, but it should work with any other implementation.Development environmentMy plan was to compile WolfSSL into a DLL that could then be used from any program. Because WolfSSL is     written in C, I needed a C environment that could create 16-bit Windows DLLs. I decided to useOpen Watcom v2, which provides phenomenal     support for 16-bit Windows programs and DLLs, and cross-compilation including from 64-bit Windows 11.Unlike withWindle, to make things a bit easier for myself, I did the main development     on Windows 11,     with a folder shared to a VirtualBox VM running Windows 2000 (which can run 16-bit programs, unlike Windows 11)     for most of the iteration and testing; then     verified at intervals that it still worked on Windows 3.11 for Workgroups.DLL HellMy first challenge was figuring out how to build and use DLLs on Windows 3.x. To do so, I needed to     understand the difference betweenfarandnearpointers.Nowadays we tend to conceptually think of pointers to memory as absolute addresses; however,     when programming for 16-bit Windows, thex86 memory segmentationarchitecture dating back to the Intel 8088 and 8086 CPUs has to be taken into account.Disclaimer:This is my understanding after reading up on this subject. I've tried to provide a     simple explanation on this without going into too much of the details, e.g. the differences between Real     and Protected modes. Please reach out if anything here is fundamentally incorrect.With segmentation, memory is split in tosegmentseach up to 64KB in size. A segment might represent     the code (the instructions) for the program, the data (the global and static local variables), or the     stack for a program. Addresses in memory consist of two parts: the segment the memory lives in, and the     offset within that segment. A pointer with this full, two-part address is called afarpointer.Segment:xxxx xxxx xxxx xxxx0000+Offset:0000yyyy yyyy yyyy yyyy=Far pointer:zzzz zzzz zzzz zzzz zzzzExample of a far pointer[2]The system has a set of registers, including the Code Segment (CS), Data Segment (DS), and Stack Segment (SS),     which keep track of the segments that are applicable to the currently running program. When passing a pointer     to a function inside the same program, you typically pass just the offset of the variable you're referencing,     and the segment is implied. This kind of pointer is called anearpointer, and is used most of the     time to save on memory.When calling into a DLL from a program, a few things are different. First, the instructions for a DLL are     in a different segment from the program's instructions, so the CS register must be changed to the DLL's in     the function call. The C compiler takes care of this for us if we use the non-standard__farkeyword in     front of the function name, meaning that the compiler will generate a \"far call\".Second, when passing pointers into DLL functions, we have to use far pointers; DLLs are tricky in that     when running code in them, the Code and Data segments are those of the DLL, but the Stack segment is     that of the calling program's. Using far pointers ensures that the wrong assumptions aren't made about     which segments pointers point to.Another non-standard C keyword that is often used for DLL functions is__pascal. This specifies     that this function uses the Pascalcalling convention.     A calling convention specifies how parameters are passed to a function in memory and how the stack is     cleaned up after a function returns. (With pascal, parameters are pushed on the stack left-to-right and the     callee removes them from the stack on return). Windows 3.x adopted the     calling convention used by Borland Pascal (and Delphi 1.0),     hence the name, but later Windows versions dropped it in favor ofstdcall.This means all the functions in WolfSSL that will be called from an external program need to be defined as__far __pascal. For example, the function to initialize WolfSSL is defined as follows:int __far __pascal wolfSSL_Init(void);Everything I've said above generally applies to calling the Windows API as well; after all, the Windows API     is implemented as calls into the DLLs that are part of Windows.Segment too largeThe biggest limitation I ran into with porting WolfSSL to 16-bit Windows was the 64KB maximum size of     segments—each Code and Data segment can only be a maximum of 64KB. This is a challenge when you're     compiling a TLS library with support for dozens of cipher suites, and various protocols both commonly and     rarely used.Thankfully, we're not limited to 64KB in total code or data for our DLL. 16-bit compilers have a concept of     \"memory models\", which were defined as Small, Medium, Compact, Large, and Huge. All compilers for the platform,     whether from Microsoft, Borland, or Open Watcom, support these models as a compile flag; models change how the     compiler uses far/near pointers and which libraries are used in the generated instructions. I decided to use     the \"Large\" memory model, which allows for multiple Code segments and Data segments in your program or DLL.FromProgramming Windows 3.1, Third Editionby Charles PetzoldModelCode SegmentsData SegmentsSmall11MediumMultiple1Compact1MultipleLargeMultipleMultipleHugeMultipleMultipleTo save on memory in general, I started by turning off as many compile-time feature flags in WolfSSL as     I could without jeopardizing     its ability to connect to most modern TLS servers. This includes features used by insecure cipher suites     (e.g. MD5, DES, RC4) as well as other features like DTLS and server support I wouldn't be using for a     simple TLS client.I quickly found that even that wasn't enough, as I'm limited to 64KB of code in each object file.     Every time an object file hit that limit, the compilation would fail with \"Segment too large\".     In particular, WolfSSL'sinternal.cfile is a whopping 1.25MB     (too largefor even GitHub to render),     and would fail the build every time I enabled a feature I needed.I was able to get that file down to a size that would fit intotwosegments by moving code around     into two files,internal.candinternal2.c—elegant, I know!     This was the most agonizing and time-consuming part of this whole process; I was in a loop of testing     the code to see if I had enough features to connect to a server, enabling a feature, seeing \"Segment too large\",     and moving more code while trying not to break the intricate dependencies between functions, or inadvertently     changing the meaning of the nestedifdefmacros in the code. Eventually, it compiled.Even with WOLFSSL.DLL compiled, I was running into a strange \"Access Denied\" error while loading the DLL with theLoadLibraryWindows API call. Eventually, after much agony, I figured out I needed to turn off debugging     information in the generated code, and change the target processor from the default (Intel 8086) to 80286 in the     compiler options.It works!Once I got everything compiling, I whipped together a quick test program to hit Qualys SSL Lab'sbrowser capability testerand download the results to a file.I could debug what was going on (especially with missing features) by using Wireshark to decode the     \"Client Hello\" message, which is the message that a TLS client sends to the server upon connection     advertising its capabilities.In my initial builds I was missing the Server Name Indication (SNI) extension, which is generally required     nowadays to allow servers to host multiple TLS websites on one IP address with different certificates. With     that added, and after some more code moving tointernal2.c, I was in business.After downloading the Qualys results on Windows 3.11 for Workgroups and opening the resulting file in     Internet Explorer 3, voilà:You can see our build of WolfSSL supports a healthy number (2) of the finest cipher suites, in addition to a     bunch of less secure ones—which is more than enough for most web sites to talk to us!Bonus: TLS 1.3Supporting TLS 1.2 was enough for most use cases, but WolfSSL has TLS 1.3 built in and it would be     awesome if our Windows 3.1 apps could take advantage of it too. TLS 1.3 has some significant changes     in the protocol compared to TLS 1.2, and also dispenses with the 37 cipher suites in lieu of 5 secure ones.After playing around with the compiler flags, and moving even more code around to avoid \"segment too large\" errors,     I was finally able to get my build of WolfSSL to compile with TLS 1.3 enabled. However, I did run into an issue     where the code thinks the received encrypted data is \"too large\" because it's 1 byte. For now, I've commented     the check out, and it seems to work in real-world situations, but I would love to understand why this is happening.Here's a screenshot of the Qualys page showing TLS 1.3 working, with theTLS_AES_128_GCM_SHA256cipher suite:WinGPTWhat's the use of a library if you can't use it? Check outWinGPT, an AI Assistant for     Windows 3.1, which makes use of the WolfSSL port to connect directly to the OpenAI API servers.DownloadI am providing the modified source code for WolfSSL here, under the GNU General Public License (GPL) v2 license     that WolfSSL is licensed under.     As noted above, this code with the modifications I have made isnot secure,not reliable, and there isno warranty. You should definitely not use it for     any purposes other than testing for your own entertainment. You can find thefull GPL v2 license here.You will also find that I have not figured out a way to integrate with the build tools (like CMake) that the     rest of WolfSSL uses, or made changes in a way that will be easy to integrate back into the main source tree.     If someone wants to make 16-bit Windows a supported architecture for WolfSSL, that would be     great—I haven't got there yet.WolfSSL for Windows 16-bit + WinGPT 1.0 source code (14M)Footnotes[1]The closest is Didiet Noor's prior work in gettingmbed TLS working on Windows NT 3.x and 95but WindowsNT3.x, like Windows 95, is a 32-bit OS.[2]This model applies to Real Mode, but Protected Mode uses a descriptor table and different sizes for addresses. Readthe Wikipedia articlefor more details.Contact:@DialupDotNet\n",
      "---\n",
      "Discovering that a Bluetooth car battery monitor is siphoning location data\n",
      "Part 1 - Discovering that your Bluetooth car battery monitor is siphoning up your location data - doubleagent.netSkip to primary navigationSkip to contentSkip to footerdoubleagent.netAboutToggle menuhaxrobJust another hackerFollowAustraliaDouble AgentTwitterGitHubPart 1 - Discovering that your Bluetooth car battery monitor is siphoning up your location data13 minute readOn this pageTLDRProduct informationData privacyLocation and Android permissionsThe hardwareThe test setupDynamic analysisIntercepting network trafficMemory analysisStatic analysisDecompilationHelloHacker News, thanks for visiting!Follow@haxrobon Twitter for further developments in this series.TLDRA Bluetooth enabled battery monitor that records car battery voltages. The hardware requires a smartphone for pairingThe product collects GPS co-ordinates, cell phone tower data and nearby Wifi beaconsLocation data is sent over the Internet to servers in Hong Kong and mainland ChinaApp store misleads consumers by stating that no personal data is collected or shared. Since the Android app requires location permissions to use the hardware device, users are effectively forced to continuously broadcast their physical location to 3rd parties in order to use the product.There are no legitimate reason for a car battery monitor application to track it’s user’s location. With over 100,000 downloads on Android alone, this raises significant privacy concernsIn this three part series:Part 1- This pagePart 2- Reverse engineering the AMap SDK location tracking featuresPart 3- Reimplementing BLE functionality and obtaining the firmwareWithin this series of posts, we explore the discovery of an Bluetooth enabled battery voltage product, acquired from a popular electronics retailer in Australia. What started as an initial hunch lead me down rabbit a rabbit hole to discover that the app covertly tracks the users physical location. It collects GPS co-ordinates, neighbouring cell phone tower location data and Wifi access points, sending this data to cloud servers in Hong Kong and mainland China.At the time of writing, location data is sent to servers related to two seperate corporate entities:The product / app developer,Leagend, hosted in Alibaba Cloud, Hong Kongbm2.quicklynks.com/47.244.125.231The location services SDK developer,AMap, hosted in Alibaba Cloud, Beijingdualstack-cgicol.amap.com/106.11.130.194Partly responsible for the extensive data collection is an embedded library used, calledAMap, which is a “leading provider of digital map in China”.Acquiredby Alibaba, it is stated that “In 2018, Amap became the first Chinese maps service to navigate a path to 100 million daily users”. Inpart 2we look under the hood at how AMap is not only collecting the GPS co-ordinates, but also every other possible location data the phone can collect - surveying Wifi and telecommunication cell phone tower data.The Android application which connects to the battery monitor device,BM2100K+ downloads, with 1.55K reviews.As@XenoKovahhighlights, you can map out the coverage of these devices by searching the various BLE advertised device names (battery monitory,ZX-1689,Li Battery Monitor) inWiGLE.net. You can gain an appreciation to just how much coverage these devices have across the whole globe.I haven’t personally seen these in my data yet, buthttps://t.co/eCSD8oVDJeimplies there are 16 or so floating around in my area. Example distribution in the US below:https://t.co/JVue6ciIqGpic.twitter.com/DCRel7GMPf— Xeno Kovah (@XenoKovah)June 27, 2023The iPhone iOS versioncan be found here. While I have not peformed any static analysis on the iOS decompilations to date, inspection of the network traffic from the phone reveals that that the Apple iPhone version is also sending location data to remote servers.Feel free to reach out to meon twitterfor partially reverse engineered decompilation of the sources referenced. The subsequent posts should provide enough detail for others to independently verify what is being reported.In the following Wireshark trace we see along with the battery voltage readings, the latitude and longitude being sent unencrypted, via a HTTP POST tobm2.quicklynks.com:A wireshark trace of mobile trafficProduct informationI acquired the  vehicle battery monitoring Bluetooth device sold under the brand PowerTech from a popular Australian electronics retailer,Jaycar Electronics.This appears to be a re-brandedBluetooth 4.0 Battery Monitorby a company calledLeagendwhich is available onAmazonfor purchase.It’s resold under local brands, for example another popular auto retailer, Repco,sells it under the Century brand.Other device names are “ZX-1689” and “Li Battery Monitor” which the application looks for in the device name of the advertising BLE beacon which are indentified inpart3.The device is quite simple - you connect it to the terminals of a battery and pair it with your phone. It shows the battery voltage/percentage and allows you to run some crank tests. That’s what’s advertised.Jaycar (Powertech) and Repco (Century) branded BM devicesAdditionally, the required application runs in the background, effectively turning a smart phone into location scanning device. Having your phone become a continuous Wifi scanner drains the battery - and this isn’t something legitimate application developers want. People do complain about issues caused. Patrick’s review of the BM2 app would agree:While we can’t explain the legitimate reason a battery voltage monitor would need to know your GPS location, a charitable explanation of the AMap SDK collecting GPS, Wifi and cell tower data is they are attempting to do what Google and Apple already do - build a relational database, mapping phone cell towers and wifi access points to GPS co-ordinates. When a phone has bad GPS signal, knowing the adjacent Wifi access points or phone towers within reception can help increase accuracy.Some terminologyAMap collects the telecomunication provider’s adjacent cell phone tower location data - Specifically thecell global identity. This is an ID that uniquely identifies a cell, unique across the whole world.The CGI is made up of:MCC= Mobile Country CodeMNC= Mobile Network CodeTheMCC+MNCmake up thePLMN(Public Land Mobile Network) - Identifies the mobile operator (e.g. Telstra, Australia)LAC= Location Area Code. Set of base stations grouped together in a geographical regionCI= Cell ID. Identifies base station transceiver within a region. Think of this as an ‘antenna’ that your phone is talking toIn 4G, technicallyTAC(tracking area code) is used.Wifi data collection includes:BSSIDMAC address of Wifi access points.SSID- Access point nameThe AMap developers go to lengths to conceal the behaviour, encrypting any data before it touches disk or sent over the Internet. Location data is encrypted with ephemeral AES keys which is then encrypted with a public RSA key. This removes the dependency for certificate pinning and ensures man-in-the-middle inspection of the network traffic is not possible without modifications to the application or obtaining the corresponding private RSA key.Data privacyNote:As of 27th of June 2023, the BM2 app developer have updated the privacy statements on both the Google Play and Apple App stores - now mentioning that precise location data is being collected.The following is stated on the BM2 appAndroid Play store:One by one, let’s review the statements claimed:1. No data shared with third partiesIn addition to your battery statistics (e.g. voltage), the latitude and longitude co-ordinates of your location is sent to theBM2application cloud servers,quicklynks.comCrash analytics are sent to a 3rd party Chinese company,umeng.comWifi, cell phone tower and GPS co-ordinates are sent to a Chinese company,AMap2. No data collectedSelf explanatory3. Data is encrypted in transitData sent to theBM2cloud servers isunencryptedHow about on the Apple store?take a lookTheprivacy policy fine printdoes mention “Hong Kong” and “location information”. We all read the fine print right?Location and Android permissionsFor the application to work, you must give the Android application permissions that let it obtain location information otherwise it won’t work: For Bluetooth scanning, Android requires this permission. At least with the iOS version, you can hit “deny” when it asks for location permissions and the battery monitor device will still work.To expand on the reason cited, it’s best explained from Android’s developerdocumentation:To provide users with greater data protection, starting in this release, Android removes programmatic access to the device’s local hardware identifier for apps using the Wi-Fi and Bluetooth APIs.  To access the hardware identifiers of nearby external devices via Bluetooth and Wi-Fi scans, your app must now have the[ACCESS_FINE_LOCATION]or[ACCESS_COARSE_LOCATION]permissions.I would argue that such a broad permission that covers both Bluetooth, GPS and Cell data offers lower data protections - as it opens up app developers to abuse this permission as we see with theBM2application that really just requires BLE scanning. BLE scanning can be achieved with justBLUETOOTH_SCAN, available on Android 12+.Update 2023-06-27Google provide further guidancehere. It is possible to specifyACCESS_FINE_LOCATIONwithandroid:usesPermissionFlagsset toneverForLocation. This is only for when Bluetooth scan results are used to derive physical location. That does not seem to be the case here though.The hardwareOur interest lies mostly in the phone applications that interface with the hardware, although it’s customary to at least take a peek inside and explore what the possibilities are for pulling off the firmware.Not much too it; some voltage regulators and a single SoC - a Texas InstrumentsCC2541) all in one Bluetooth Low Energy MCU. Datasheethere. Some possible debug ports are spotted:Click to enlargeThe CPU is based on an 8 bitIntel 8051. Later revisions of the CC series use ARM cortex architecture.According to the specifications, theCCseries SoCs support on chip debugging via a proprietary interface - No JTAG or SWD to be seen here. This means we will need theCC Debuggeror try some customArduino implementation, although this specific IC is not supported. As the device supports over-the-air updates, there is a REST endpoint which will return the firmware over HTTP, documented inpart 3It appears there is noshuntor other current sensing circuity. Hardware wise, this really is as simple as it gets.The test setupFor testing I’m using a small led acid 12v battery with theBM2battery monitor and a rooted Android handset which will be used for dynamic instrumentation.Notably, the setup sat on my desk. As we discover inpart 2of this blog post series, the AMap location data is only written to it’s database from memory when it detects you are physically moving. To overcome this and other hurdles,FridaandObjectionused extensively to instrument the running software in run time.Dynamic analysisIntercepting network trafficMitmproxyis a defacto “in the middle” proxy software and it now supports a new mode usingwireguard. What this means is it’s extremely trivial (and quick) to peek inside mobile application traffic with minimal configuration. Once theWireguardapplication is installed on the handset, simplymitmweb --mode=wireguardand take a scan the QR code on screen by taking an image from the handset. Immediately all traffic from the handset will be sent over a Wireguard tunnel to mitmproxy. Browsing to http://mitm.it then allows you to download a certificate to add to the trust store. With iOS the process is trivial. Android has now made it harder to do, and in this case I had to use a rooted handset.Note: Since theBM2does not use HTTPS, there is no need to even install a certificate. What this means is that anyone can independently identify that their latitude and longitude co-ordinates are being sent on either iOS or Android with no modifications to their phone.After the application connects to the battery monitor device,  we see aPOSTrequest is sent tohttp://bm2.quicklynks.com:8080/api/bm2/userDevice/upload?.Latitude and longitude fields are highlighted in green.At the time of writing, this server resolves to a host in Alibaba cloud, HK:$host bm2.quicklynks.com bm2.quicklynks.com has address 47.244.125.231$curlhttps://ipinfo.io/47.244.125.231{\"ip\":\"47.244.125.231\",\"city\":\"Sham Shui Po\",\"region\":\"Sham Shui Po\",\"country\":\"HK\",\"loc\":\"22.3302,114.1595\",\"org\":\"AS45102 Alibaba (US) Technology Co., Ltd.\",\"timezone\":\"Asia/Hong_Kong\",}In this specific request we also see a sample of the battery voltages, the hardware MAC address of the device (nicknameandserialNo).Spoofing GPS co-ordinatesGPS co-ordinates can be spoofed by using the followingFridato dynamically hook intoandroid.location.Location.{getLatitude|getLongitude}methods. Frida will be used extensively in our testing. More on this later.location.jsconstlat=39.1090;constlng=-76.7700;Java.perform(function(){varhookedClass=\"android.location.Location\"varLocation=Java.use(hookedClass);Location.getLatitude.implementation=function(){console.log(\"[+]\"+hookedClass+\"new lat:\"+lat);returnlat;}Location.getLongitude.implementation=function(){console.log(\"[+]\"+hookedClass+\"new lng:\"+lng);returnlng;}})To invoke:$ frida -U -l location.js -f com.dc.battery.monitor2Memory analysisAs stated earlier, GPS, Wifi and cell data is gathered by the embedded AMap library. The code is obsfucated to make reverse engineering more time consuming. Anything that touches disk or the network is encrypted serialized binary blobs. This calls for some quick wins with dynamic instrumentation as the code runs on a handset while paired to the hardware battery monitor.For example, we can peek inside the application’s heap memory. For this we will use a plugin forObjectioncalledWallbreaker. After some quick analysis of the AMap library we know what class names to find instances in memory (click pictures to expand):GPS data:Telecommuncation provider cell data:Wifi data (toString() enumerated):Static analysisDecompilationFirst let’s grab the APK straight off the handset. We could of course get a copy from APK pure too fromhereFirst identify the application name identifier which iscom.dc.battery.monitor2:Obtain the path of the APK and pull it from the device withadb shell pm paththen pull it off the phone.JADXis our choice for the de-compiler, and it’s just great. Opening the.apkand it handles everything in one shot, from decompression to de-compiling the java bytecode into Java.The very first thing is to check the permissions inAndroidManifest.xmlafter opening the APK in APK injadx-guiThe hightlights in green raises a few questions. We have explained whyFINE_LOCATIONis required, but why would a battery monitor application needsCAMERA,IMAGE_CAPTURE,ACTION_VIDEO_CAPTURE,MODIFY_AUDIO_SETTINGSandRECORD_AUDIO?At this point it’s possible that this functionality is unused. More investigation is needed here.Very quickly we see that the decompilation of the java bytecode directly from the APK is going to be problematic. The entrypoint iscom.stub.StubAppwhich has methods names obsfucated with xor encryption which indicates there is more work to do.<application android:theme=\"@style/AppTheme\" android:label=\"@string/apk_release_name\" android:icon=\"@mipmap/ic_launcher\" android:name=\"com.stub.StubApp\"Fortunantly it’s obvious that a commercial software packer calledqihoo.utilhas been used. Zimperium has agood writeupon this packer as it’s often found employeed in Chinese based mobile malware. It’s somewhat advanced in the sense that the unpacked software is encrypted and packed into native, compiled library. People have written unpacking tools that claim to handle this packer such asandroid-unpacker. Given that developers often update and change their packing techniques, the unpacker tools in the public domain can quickly become outdated.As such we will take much easier approach - by usingfrida-dexdumpit’s possible to dump the original (unpacked) mobile application Dalvik executable bytecode from memory after opening the application on the handset.Qihoo 360 is not without their owncontraversy, being “placed on theBureau of Industry and Security’sEntity Listdue to U.S. national security concerns”.After installing dexdump (e.g.pip3 install frida-dexdump), run it after opening the application:frida-dexdump -U -f com.dc.battery.monitor2 -dUsedex2jarto covertclasses.dexto java bytecode:./d2j-dex2jar.sh ./com.sec.android.app.samsungapps/classes.dexWe can the use jadx to then decompile into readable java and now have the original application code, method names, variable names forcom.dc.battery.monitor2, as no further obfuscation was done outside of the initial packing/encrypting.The exception here is theamaplocation services SDK library which was originally obsfucated which will make our time a little harder to reverse these parts. Fortunately class names are recoverable for the AMap related classes by selectingtools -> deobsfucationin JADX.While the variable or method names are random(ish) strings, the recovered class names are descriptive enough that with some effort the function of the classes and methods is identified with method and variables renamed appropriately by hand.Next up, inpart 2we will investigate how the embedded AMap SDK is not only sending the GPS co-ordinates, but Wifi and telecommunication cell tower data.Updated:May 21, 2023PreviousNextFeed© 2023 doubleagent.net. Powered byJekyll&Minimal Mistakes.\n",
      "---\n",
      "How Network Processors Work\n",
      "How Network Processors WorkSkip to main content+1 (866) 653-6233Search formSearchSoftware Expert Witness TeamABOUT USCONTACT USExpert WitnessEngineering ServicesDirectoryExpert ServicesExpert Reports by Testifying Software ExpertsSoftware Source Code Review and AnalysisReverse Engineering and Forensic AnalysisConsulting Experts in Software and ElectronicsStayAreas of ExpertiseAutomotive SystemsCloud ComputingComputer SecurityConsumer ElectronicsElectronic CircuitsEnterprise SoftwareIndustrial ControlsInternet of Things (IoT)Medical DevicesMilitary & AerospaceMobile Devices & AppsSignal ProcessingTelecommunicationsStayMatters & VenuesPatent Infringement and Invalidity ExpertsSoftware Copyright and Trade Secrets ExpertsProduct Liability and Failure Analysis ExpertsContract Disputes and Software Project FailuresVenues and ClientsStayCase StudiesDirecTV Anti-PiracySamsung Software CopyrightToyota Runaway CarsStayResourcesExpert Witness BlogSource Code Review in LitigationSoftware Source Code DiscoveryStayFirmware TrainingProduct DevelopmentArchitecture ConsultingProcess ImprovementCase StudiesAonixBTE TechnologiesChamberlainDatalightJetHeadNiproOmnicellPole/ZeroRockwell CollinsStayResourcesHow-to ArticlesEmbedded C Coding StandardEmbedded Systems GlossaryOnline BooksFree Source CodeTech TalksRecorded WebinarsIndustry SurveysEmail NewslettersStayHow Network Processors WorkHomeBlogsHow Network Processors WorkPosted: Wed, 2000-11-01 00:00 - Mark KohlerMajor semiconductor manufacturers are starting to sell a new type of integrated circuit, the network processor. Network processors are programmable chips like general purpose microprocessors, but are optimized for the packet processing required in network devices. But what are they good for and how do they work?Network devices are a growing class of embedded system and include traditional Internet equipment like routers, switches, and firewalls; newer devices like Voice over IP (VoIP) bridges, virtual private network (VPN) gateways, and quality of service (QOS) enforcers; and web-specific devices like caching engines, load balancers, and SSL accelerators.In this article, I will describe the processing requirements of network devices, how traditional designs meet those requirements, how network processors aim to meet those requirements, and the architecture of a few network processors in detail.Network processing requirementsPart 1Not all network devices have the same processing requirements. However, a lot of similarities exist. As an example, I will roughly describe the packet processing duties of a router and a web switch. These core, time-critical duties are also called data plane tasks.Routers are the workhorses of the Internet. A router accepts packets from one of several network interfaces, and either drops them or sends them out through one or more of its other interfaces. Packets may traverse a dozen or more routers as they make their way across the Internet. Here is a simplified version of the IP routing algorithm:Remove the link layer headerFind the destination IP address in the IP headerDo a table lookup to determine the IP address of the next hopDetermine link layer address of the next hopAdd link layer header to packetQueue packet for sendingSend or drop packet (if link is congested)Web switches, by contrast, are a new type of network device. They address the problem of trying to increase the responsiveness of a popular Web site by using more than one web server. A web switch can direct incoming HTTP requests to different servers based on a variety of networking parameters, including the URL itself. For instance, all secure HTTP requests could be forwarded to a special web server with cryptographic hardware to accelerate those requests. Here is a simplified web switch algorithm:Accept incoming TCP connection (three-way handshake)Buffer incoming TCP data stream (TCP/IP protocol)Parse the stream to find the URL being requestedDo a table lookup to determine where to forward the requestOpen TCP connection with web server (three-way handshake)Send buffered request (TCP/IP protocol)Note that, for a given bandwidth, the web switch processing requirements are much higher, and require much more state than the router processing requirements. The difference arises because a router processes packets, but a web switch processes connections.Part 2The previous description of the core operations of a router and a web switch were not complete. A major piece was missing. What was it? Device management. How do you configure and control this device?A variety of less time-critical tasks fall outside the core processing or forwarding requirements of a network device. These are called control plane tasks. For a router, these tasks include routing protocols like OSPF and BGP, and management interfaces like serial ports, telnet, and SNMP. For a web switch, these tasks include receiving updates about the status of web servers and providing a web interface for configuration and management. For both devices, error handling and logging are important control plane tasks.Another way to distinguish data plane tasks from control plane tasks is to look at each packet's path. Packets handled by data plane tasks usually travel through the device, while packets handled by control plane tasks usually originate or terminate at the device.Data plane vs. control planeNetwork engineers have noticed an interesting relationship between data plane tasks and control plane tasks. Data plane tasks require a small amount of code, but a large amount of processing power. In contrast, control plane tasks require little processing power, but a large amount of code.Using a router as an example, this phenomenon can be considered from two vantages, code size or processing requirements. The data plane tasks of a router were described briefly in the previous section, and a detailed description would not be much longer. It seems apparent that one could handle the data plane tasks without a lot of code.The control plane tasks were also described, but the description was not nearly as precise. Even in a traditional network device like a router, control task implementations vary. All routers will have code to handle routing protocols like OSPF and BGP, and they will almost certainly have a serial port for configuration. But they may be managed via a web browser, Java application, SNMP, or all three. This can add up to a lot of code. If you're still not convinced, look at the size of Cisco's books on how to configure its routers.Now, let's consider the packets entering the router. Nearly all of them are addressed to somewhere else, and need to be examined and forwarded there very quickly. For example, for a router to run wire-speed with a 155Mbps OC-3 link, it needs to forward a 64-byte packet in three microseconds. These packets may not need to have much done with them, but it needs to be done in a timely manner.This requires tight code and a lot of processing power. By contrast, the occasional OSPF packet that causes the routing tables to be updated, or an HTTP request to make a configuration change might require a fair bit of code to be handled properly, but will have little impact on overall processing requirements.Fast path, slow pathThe different requirements of data plane and control plane tasks are often addressed by what is called afast path-slow path design. In this type of design, as packets enter the networking device, their destination address and port are examined, and based on that examination, they are sent on either the \"slow path\" or the \"fast path\" internally. Packets that need minimal or normal processing take the fast path, and packets that need unusual or complex processing take the slow path. Fast path packets correspond to data plane tasks, while slow path packets correspond to control plane tasks. Once they have been processed, packets from both the slow and fast path may leave via the same network interface. See Figure 1.Dividing up the processing in this way provides substantial implementation flexibility. While the slow path processing will almost certainly be implemented with a CPU, fast path processing can be implemented with an FPGA, ASIC, co-processor, or maybe just another CPU. This architecture is particularly strong because it allows you to implement simple time-critical algorithms in hardware and complex algorithms in software.Now that we have a handle on network processing requirements, let's start looking at network processors.ASICsOver the last 10 years, demand for higher bandwidth networks has driven the evolution of network equipment design. The first designs used CPUs exclusively. However, general purpose CPUs are not ideal for network programming. While their programmability is important, their floating-point units go unused, they have too much data cache, and too little memory bandwidth. Further, demand for bandwidth is increasing faster than CPU speeds. Network equipment designers cannot afford to wait for the next generation of CPUs to increase the speed of their devices. Even with fast path-slow path designs, problems still arise. For example, how do you make the fast path fast enough?The conventional answer is to design an ASIC. Well-designed ASICs can be much faster than CPUs, but they are difficult and expensive to develop; the cost of the tools alone make them unaffordable for many companies. Moreover, ASICs usually have limited programmability and must be redesigned as protocols and interfaces change. Network processor companies hope to bridge the divide between ASICs and CPUs by providing a device that is as programmable as a CPU but as fast as an ASIC.Network processor architecturesNetwork processor architectures make CPU architectures look staid and boring. Network processor designers from different companies have made vastly different decisions about I/O interfaces, memory interfaces, and programming models, not to mention system architecture and what flavors of hardware acceleration to include.Figure 2 is a block diagram of a generic network processor. It does not represent a specific network processor, but includes traits common to most. These traits are:Multiple RISC coresDedicated hardware for common networking operationsHigh-speed memory interface(s)High-speed I/O interfacesInterface to general purpose CPUProgramming a network processorSince network processors are very different from general purpose processors, the most important question for programmers is, how do you program it? How do you make effective use of multiple RISC cores and hardware acceleration units? Every network processor vendor insists that their design is the easiest to program, so it is good to think critically about this question.In many ways, network processor architectures look like the parallel processing architectures of a decade ago. Programmers have tried to harness the power of parallel processing architectures for a long time, but with little luck. Vector-processing supercomputers are used for special purpose applications like weather simulation, but programmers have not been successful in using them for general purpose applications.Is there any reason to think network processors will fare better? Yes, there is. Network processors are not trying to speed up general purpose processing. Network processing has certain characteristics that are very different from general purpose processing. Network processing involves less code but more data than general purpose processing. There is less interdependency between the data. Consider a router again. If a router receives n packets, for a small number n, it can process those packets independently. Another way of saying this is that processing these packets doesn't change the router's state. The exception to this would be configuration packets, or routing protocol packets. However, even these interdependencies are rather loose. If a router receives a packet that indicates it should update its routing tables, there is no reason it can't finish processing a few more packets before it does the update.Interpacket dependenciesOn the other hand, for the web switch there are substantial interpacket dependencies. A large class of packets must be processed in the order they are received. The web switch must maintain the semantics of a TCP connection, which means it must buffer packets it has received until it has received enough to parse out the URL. When forwarding the request to a web server, the web switch must save packets that it has sent but have not yet been acknowledged, in case they need to be resent. Despite these interdependencies, a web switch can still benefit from parallelism. How? If the packets are sorted so that packets for a particular connection always go to the same RISC core, then packets for that connection will be processed in order, and interpacket dependencies will have been observed.If you are evaluating a network processor, you should carefully consider what kind of interpacket dependencies you have, and how each network processor handles them. Network processors designed for very high speed traffic often have no provision for interpacket dependencies and thus would not be appropriate for network devices doing application-level processing.Speeds and feedsAs indicated above, a wide variety of network processor designs exist. One reason for this is that the interface speeds for network devices range over several orders of magnitude. Table 1 lists the maximum processing time a network device may use if it wants to perform at wire-speed for various interfaces. The rightmost column can be considered a per-packet time budget.WAN linkData rate (Mbps)Maximum processing time (ns)for a 64-byte packetT-11.5340,000T-34511,000OC-31553,000OC-12622820OC-482,500200OC-1929,50051Table 1. Maximum processing timeFrom reading the marketing literature of network processor vendors, you might believe that all network processors are designed for gigabit speeds, and the faster the better. However, depending on your application, a slower network processor might be a better choice. Network processors designed for the fastest speeds are much more I/O driven, and have less capabilities for pattern matching, sorting out interpacket dependencies, and other features desirable for application-level processing.Multiprocessing and multithreadingMany network processors include multiple processor cores that run in parallel. Some of the cores, notably those in Intel's IXP1200 and Sitera's Prism network processors, include hardware support for multiple contexts, which essentially results in zero context-switch time between threads on the same core.For multi-core network processors and multi-threaded cores, an important question is: who handles scheduling? Consider Figure 3, where six packets are destined for our four-core network processors.Which packet will be processed by which core? In some network processors, this is determined by the hardware. In others, the software determines the answer. Depending on your application and algorithms, the ability to control which packets go to which cores may be an important requirement. For others, the speed of hardware scheduling may be essential.Market developmentsThe hot news in the network processor market has been acquisitions and standards. Between September 1999 and June 2000, major semiconductor manufacturers went on a buying spree, each acquiring a network processor or acceleration company. During that time, Intel acquired NetBoost, Conexant acquired Maker, Lucent acquired Agere, Motorola acquired C-Port, and Vitesse acquired Sitera.On the standards front, companies in the switch fabric and network processor business have formed two standards bodies. The Common Switch Interface Consortium (CSIX) was formed to standardize a hardware interface between switch fabric chips and processing chips.The Common Programming Interface Forum (CPIX) was formed to standardize software interfaces for network processors. These two groups include in their membership almost every company that has anything to do with network processing, except Intel.In particular, the aims of CPIX are interesting: develop software standards for network processors, so that network processor software is portable to different network processors. While this would be beneficial to many network equipment manufacturers, vastly different network processor architectures make that prospect unlikely, at least without large performance sacrifices. Until CPIX releases its standard, it looks more like an anti-Intel coalition than a standards body.Network processor descriptionsC-5 Digital Communications ProcessorThe C-5 Digital Communications Processor (DCP), shown in Figure 4, may be the most powerful network processor of the bunch. It consists of 16 channel processors (CPs) and five co-processors, all connected through a 50Gbps bus. The channel processors, each of which consist of a 32-bit RISC core and two serial data processors (SDPs), are the heart of the unit. The SDPs are microcode-programmable to implement link layer interfaces including Ethernet, SONET, and serial data streams. Since each RISC core can run a different program, and the channel processors share a common bus, you have a lot of flexibility in distributing your processing across this chip. You could have a parallel processing arrangement where you ran identical programs on several CPs, or a pipelined arrangement where each processor was dedicated to a particular task and passed its output to the input of the next processor. The five co-processors are an executive processor, a fabric processor, a table lookup unit, a queue management unit, and a buffer management unit.The C-5 DCP has enough processing power to implement both data and control plane operations itself, or it can communicate with a host CPU across a PCI bus interface.Programming the C-5 DCP is not a small task. With the possibility of writing up to 16 different C/C++ programs for 16 processors, as well as writing microcode for the serial data processors(s), and system level code to tie everything together, a lot of effort goes into harnessing the C-5's power. C-Port's core development tools are based on the popular GNU gcc compiler and gdb debugger, modified by C-Port to work with their RISC cores. To program the RISC cores, you write from one to 16 different programs in C or C++. Then you can debug all of your programs at once using the included C-5 DCP simulator, or you can load your programs on to the C-5 DCP itself, and use gdb to debug them one CPU at a time. C-Port rounds out their development toolset with a traffic generator and performance analyzer.C-Port provides library routines, named C-Ware, to maintain software compatibility for future generations of DCPs. These routines cover features of both the RISC cores and the co-processors, including tables, queues, buffers, protocols, switch fabrics, kernel services, and diagnostics. The C-Ware reference library includes C-5 implementations of a gigabit ethernet switch, packet over SONET (POS) switch, and ATM switch.Intel IXP1200Intel has become a leader in marketing network processors as part of their Internet Exchange Architecture. Currently, most network processor companies are extremely secretive about their products. Intel is the exception. Of the four network processors described in this article, Intel's IXP1200 is the only one for which you can directly download a datasheet from the Web.The IXP1200, shown in Figure 5, consists of a StrongARM processor, six RISC micro-engines, and interfaces to SRAM/SDRAM memory, PCI bus, and Intel's proprietary IX Bus. The IXP1200 has been designed to do fast path and slow path processing in one chip. The StrongARM portion of the processor can be programmed for the slow path with conventional C/C++ tools. The six micro-engines are designed for fast path processing. Each micro-engine has four hardware contexts and can context switch in a single instruction. The micro-engines are limited to 4KB of program space, which is actually quite a bit, since they are programmed in microcode.Intel provides assembly tools for the microcode as well as a simulator for debugging the non-StrongARM parts of the IXP1200. Intel ships the IXP1200 development environment with example code for Layer 2 and Layer 3 bridging and routing.LucentLucent's network processor design is very different from the other three network processors described in this article. It is a three-chip solution for the fast path. System designers need to add a general-purpose microprocessor for slow path processing. Lucent's network processor has three parts: the functional pattern processor (FPP), the routing switch processor (RSP) and the Agere system interface (ASI). Both the FPP and RSP are programmed with 4GLs (fourth-generation languages). See Figure 6.The idea behind the FPP is that there is a large class of network processing functions that require some sort of pattern matching. This includes parsing packets and searching through routing tables. The RSP handles all actions for a particular packet, including packet modifications like routing, and traffic management functions like queueing. The ASI is for sending and receiving slow path packets from a general purpose CPU.Development kits are available that implement the Lucent network processor using five Xilinx Virtex FPGAs. Clocked at 33MHz, they support full duplex OC-12 interfaces. The tools are not the standard C/C++ development environment that is common with other network processors. The development kit contains:Functional programming language compiler-for programming the FPPAgere Scripting Language (ASL) Compiler-for programming RSP and ASIJava-based simulation environmentCommand-line simulators for the FPP and RSPTraffic generatorThe Application Code Library includes IP switching and routing over ATM AAL5, over Ethernet, and over Frame Relay.SiteraSitera's network processor family, the Prism IQ2000 (shown in Figure 7), consists of four RISC cores, co-processors for lookup, order management, multi-cast support, DMA management, context management, and interfaces to both SRAM/RDRAM and a general-purpose CPU. Sitera expects the Prism to handle fast path processing and for a CPU to be designed in for slow path processing.The Prism's RISC cores have a modified version of the MIPS instruction set with four hardware contexts. Packet scheduling is handled in hardware, with the order management co-processor responsible for resolving packet interdependencies. Sitera offers three variations of the Prism IQ2000, each with the same core but different network interfaces. Sitera's Developer's Workbench is based on the GNU C/C++ compiler, but also includes a simulator and traffic generator. Their reference application code supports Layer 2 and Layer 3 bridging and routing.ConclusionsThe network processor industry is at an early stage. Most network processors have only recently started shipping production quantities, and only a few shipping products use network processors. Nevertheless, for developers of networking devices, network processors might be the fastest platform for the next-generation product.This article was published in the November 2000 issue ofEmbedded Systems Programming. If you wish to cite the article in your own work, you may find the following MLA-style information helpful:Kohler, Mark. \"NP Complete,\" Embedded Systems Programming, November 2000, pp. 45-60.Related Barr Group Courses:Embedded Software Boot CampFor a full list of Barr Group courses, go to ourCourse Catalog.Back to Main BlogShareArticle CategoriesassemblyCcoding standardscommunicationsdebuggingelectronicsJavareal-timeRTOSsafetysecuritytoolsuser interfacesCall us:+1 (866) 653-6233QUICK LINKSSource Code Review ServicesExpert Witness DirectoryReverse Engineering ServicesExpert Reports & TestimonyHow-To Technical ArticlesSOURCE CODE REVIEWBarr Group providessource code comparison and review in programming languages such as C, C++, Java, Python, C#, Objective-C, Perl, PHP, Ruby, JavaScriptand for platforms including Windows, Linux, Android, iOS, Azure, and AWS.LATEST BLOG POSTSU.S. District Court Source Code Review RulesOracle v. Google Java API Copyright Dispute N...What is Expert Witness Testimony?Differences Between U.S. and Canadian CourtsWebsite contents copyright © 2012-2023 by Barr Group.Barr Group's logo is a U.S.-registered ® trademark.SITEMAP|PRIVACY\n",
      "---\n",
      "Launch HN: Argonaut (YC S21) – Easily Deploy Apps and Infra to AWS and GCP\n",
      "Launch HN: Argonaut (YC S21) – Easily Deploy Apps and Infra to AWS and GCP | Hacker NewsHacker Newsnew|past|comments|ask|show|jobs|submitloginLaunch HN: Argonaut (YC S21) – Easily Deploy Apps and Infra to AWS and GCP134 pointsbysuryao22 hours ago|hide|past|favorite|67 commentsHello HN, I'm Surya, the founder of Argonaut (https://www.argonaut.dev/), a unified platform that tries to make software ops painless, so teams can focus on building features instead of building and managing infrastructure. Argonaut combines Kubernetes PaaS, a CI pipeline builder, and a Terraform state manager with prebuilt AWS and GCP modules. Here’s a demo:https://www.youtube.com/watch?v=8DZsYXxA2tQ.I’ve helped build infrastructure tooling from scratch at multiple companies and realized two things: that the shape of the solution with the advent of containerization, Kubernetes, and hyperscalers is quite similar across orgs, and that highly knowledgeable engineers are needed to build and manage this system.Internal infrastructure teams juggle a multitude of tasks—provisioning cloud infrastructure, configuring runtimes, building code, securing artifacts, running tests, and deploying at scale. Post-deployment, they're also tasked with monitoring app performance, errors, uptime, and cost visibility. It's a lot of work, and having to build this tooling in-house is a deep inefficiency in engineering teams. The root of the problem is that AWS and GCP provide a lower level of abstraction than the entities, such as environments and applications, that developers have to deal with, and a ton of work is getting duplicated, often by underfunded teams, across many orgs. Argonaut’s objective is to be the developer platform and control center that you would otherwise have to build internally.Argonaut provides an intuitive developer experience that simplifies working with Kubernetes and enables developer self-service, reducing the burden on devops and platform teams. We've productized this workflow orchestration, incorporating best practices to provide a push-to-deploy experience with flexible pipelines and scalable infrastructure, all within minutes.Our users are startups across various domains like healthcare, IoT, fintech, AI, and SaaS products. Over the last two years, we’ve enabled customers to scale their engineering teams 10x and manage 10+ environments in parallel without needing a dedicated infra/DevOps team, saving them precious time and resources.Argonaut lets you set up production-ready infrastructure and customize as you scale. We then let you set up automated deployments of your application in minutes. We offer configurable build-and-deploy pipelines, powered by Dagger and ArgoCD, and deep integration with GitHub Actions and GitLab CI.  In addition, we support container registries, multiple cloud accounts, observability stacks, cost visibility providers, CDNs, and the entire helm chart ecosystem of Kubernetes, with more integrations on the way.Key features include: (1) easily create environments encapsulating cloud infrastructure, applications, and deployment pipelines (2) autoscaling deployments for apps and cronjobs to GCP and AWS with a progression across environments (3) compose deployments across multiple environments with our visual pipeline builder (4) get cost estimates before making infra changes, giving you a clear understanding of your expenses; (5) managed Terraform state and pre-built modules that just work, fostering team collaboration on infrastructure.Argonaut is self-serve, so you can sign up and start using the product right away:https://ship.argonaut.dev. There is a free tier that doesn't require a credit card to get started. We'd be delighted to have you try it, and are happy to help with onboarding.If your teams work with AWS, GCP, or Kubernetes, I’d love to hear about your experiences, pain points, and what you think a product like Argonaut should be able to do. Looking forward to your comments!quickthrower220 hours ago|next[–]> If your teams work with AWS, GCP, or Kubernetes, I’d love to hear about your experiences, pain points, and what you think a product like Argonaut should be able to do.Using Kubernetes in Azure (and this might be Azure specific), there isn't enough easy diagnostics via point/click for production issues. It is a nightmare trying to figure out why something happened and feels like you need to gain more expertise (at time sensitive times!) each time it does. Azure has improved over the years in this regard. But it might be a Kubernetes thing.A cool feature would be \"This pod stopped, and didn't restart for 10 minutes\" and the reason is \"{the reason in plain English}\".Kubernetes feels like a leaky thing to throw abstractions over, so the pain with using it is you need to become an expert in it, more so than the serverless offerings that are more genuinely abstracted, like the various app platforms that run the containers directly, or functions.I guess even when managed by the cloud host, it is more serverful (e.g. the need to SSH into VMs to do security hardening checks), but then there is this beast running on those servers you need to understand too.And at that point you need a lot of engineer time anyway and probably a platform separation to deal with it all.So I think if your product could remove some of those kinds of issues it would be good - but then I am still trying to work out \"why choose Kubernetes and not some sort of app service\" for the majority of users (I am keeping an open mind!)replysuryao20 hours ago|parent|next[–]> A cool feature would be \"This pod stopped, and didn't restart for 10 minutes\" and the reason is \"{the reason in plain English}\".There is a little \"bulb\" icon on the top. That enables a \"highlight mode\" where you can select some text, usually kubernetes error messages. That is sent to an OpenAI LLM to (1) convert the error into plain english (2) show potential fixes.This is limited by what GPT4 can provide but it is still helpful in some cases. Maybe we should highlight this feature more :)> Kubernetes feels like a leaky thing to throw abstractions over, so the pain with using it is you need to become an expert in it, [..]We believe two things: (1) k8s features exist because they are genuine user needs and we don't want to hide them (2) things get very complex very quickly because the \"beast\" is complex.Argonaut's approach is what I call \"Progressive Discovery\". There is a good happy path that works for 80% of use cases. When you need to deviate, we make it easy to work with the underlying primitives to enable your use case. This enables users to move fast without hitting an abstraction ceiling and it keeps the complexity in check.That said - Argonaut is not for everyone. If you have just a service or two, you're better off running it on a hosted runner instead of an aws or gcp or azure. It is going to be cheaper at small scale too.replyquickthrower220 hours ago|root|parent|next[–]Thanks. I think using AI to help with translating error messages, and perhaps finding the logs that matter, and even being an \"expert system\" of sorts to give an opinion on what went wrong is useful. Sort of how Windows diagnosis of why something isn't working (like wifi) has got better over the years, probably by adding more and more edge cases!replysuryao20 hours ago|root|parent|next[–]Yeah, I think there is a long way to go before the AI gets good enough to be trustworthy for infra type tasks but I am super excited for that future.replyfrakkingcylons13 hours ago|root|parent|prev|next[–]I hope your AI helper is named Jason :)replysuryao10 hours ago|root|parent|next[–]Hahareplybjornsing21 hours ago|prev|next[–]Very cool! I’ve been fiddling with terraform, ec2 + microk8s, eks, rancher fleet and crossplane over the weekend, trying to set up infra for a novel key-value store I’m working on. But there sure are a lot of ways to screw this up and get bogged down in devops work, instead of building product.My only concerns would be: 1) do I have a realistic “exit strategy” or am I de facto locked into your platform and 2) as an old school engineer I don’t feel fully comfortable with a click-ops platform, unless it can generate terraform or similar.replysuryao20 hours ago|parent|next[–]This is a concern we hear often. We have taken some steps to ensure that we do right by users in case users want an exit. Firstly, we use broadly adopted projects like ArgoCD for GitOps for apps and terraform for infra under the hood, though the tf is not exposed right now. All your config is in standard formats and can be transferred over. We are working on exposing these natively (and securely). You would be losing \"push to deploy\" CI pipelines though, since that requires hosted infra and workflow management that is actively done by Argonaut. Hope that answers your question.replytaurusismysign7 hours ago|prev|next[–]Congratulations on the launch. To ship something like this, it must have taken several months of hardwork.We are in security space and see proliferation of cloud providers (multi-cloud), accounts, services, tech-stacks a thing and it's getting insanely painful day by day.Argonaut is much needed esp for folks who want that ease of ops.replyalexjv8919 hours ago|prev|next[–]We at cashflowy.io has been using argonaut for a while now. As a single person dev team, I did not have the time luxury to deal with kubernetees and also handle customer support/business development etc. Wanted the flexibility of kubernetees but did not want the full kubernetees overhead being a small startup. Argonaut has worked out really well for us.replynailer16 hours ago|parent|next[–]If you need containers on demand, why not just use a simpler service like ECS? There’s a reason k8s is a meme for wasted engineering resources.replysuryao15 hours ago|root|parent|next[–]Responding on behalf of alex at cashflowy since I have some context. The team was originally on Elastic Beanstalk but chose to move to using kubernetes to leverage the rich ecosystem of helm charts. That enabled setup of tools like metabsse etc. very easily. Overall, it was lesser hassle for more functionality since CI/CD was also out of the box, and self-hosting these tools was a breeze with helm charts.replyg_delgado1416 hours ago|root|parent|prev|next[–]Same question here - what about something like AppEngine (or Elastic Beanstalk)?replymwcampbell17 hours ago|prev|next[–]Congratulations on your launch.Did you ever consider using Amazon ECS instead of Kubernetes? I made the move from EKS to ECS a couple of years ago, because ECS doesn't require you to pay for your own cluster control plane, and I feel that ECS integrates more seamlessly with the rest of AWS. I suppose that also means more AWS lock-in, but the Linux-based container images themselves are still portable. And overall, I've found that ECS is just less complicated and lower-maintenance than Kubernetes.But AFAIK, neither GCP nor Azure has an ECS-style shared container orchestration service. I wonder why that is.replysuryao15 hours ago|parent|next[–]Google CloudRun (equivalent to ECS) and AWS ECS are great but they have some limitations in the type of workloads you can run. The choice of EKS (and GKE) was done for a few forward looking reasons including the ability to run any kind of workloads and more complex scenarios including enabling cloud portability for example. Else, it would lead to potential lock-in as companies diversify in their requirements.With Argonaut, we try to make EKS easier to use than ECS to bring the best of both worlds. We handle the kubernetes version upgrades as well.replyzoomzoom12 hours ago|parent|prev|next[–]Google cloud also has Cloud Run and GKE autopilot.It’s great to see all the amazing tooling being built into this space. Other companies to check out include flightcontrol, architect, quovery, Coherence (withcoherence.com - disclosure that I’m a founder), stacktape, and zeet.replynightpool17 hours ago|parent|prev|next[–]> But AFAIK, neither GCP nor Azure has an ECS-style shared container orchestration service. I wonder why that is.Isn't this what Cloud Run on GCP is supposed to be? Or am I misunderstanding?replyHikikomori5 hours ago|parent|prev|next[–]We use ECS, but find ourselves implementing k8s features on top of it.replymaccard15 hours ago|parent|prev|next[–]Azure has Azure Container Apps.replynarenkmano21 hours ago|prev|next[–]Congrats on the launch! I've had to deploy python/java services on AWS ECS services (for blue-green deploys) multiple times over the last six months and it's always been a pain to setup it up. Especially in a startup where I want to move as fast as possible it's been a pain to set up manually.Is that something that is easy to setup with Argonaut?replysuryao20 hours ago|parent|next[–]This is central to what we do. I'd be happy to give you a demo. How it is done: (1) kubernetes and some essential tools for certificate and ingress management are setup. (2) connect github or gitlab repos and you get a push to deploy experience as the CI gets setupI assume you are already containerized, so there is not much to be done. There is a one time setup of a kubernetes cluster (EKS) that aws takes about 25mins for.This will give you a rolling zero down-time deploy out of the box along with a few other goodies. You can checkout a quick demo here (~4m) -https://www.youtube.com/watch?v=8DZsYXxA2tQreplyleoh21 hours ago|parent|prev|next[–]Are you using terraform?replynarenkmano20 hours ago|root|parent|next[–]No, doing everything by hand in the console, which has been super annoying. But don't want to spend time setting up terraform right now.replysuryao20 hours ago|root|parent|next[–]As an aside: argonaut sets everything up using terraform (everything is autogenerated from templates), though the tf code itself is not yet exposed to users. We're working on that functionality soon.replyicedchai15 hours ago|root|parent|prev|next[–]You're going to waste more time setting things up by hand. It's also error prone, and when you have to replicate things across environments (dev, test, prod, at a minimum), you'll spend a ton of time figuring out what you missed.The console is really only meant for prototyping. AWS should really emphasize this more.replyVincentEvans14 hours ago|root|parent|next[–]How does one convert a prototype generated by clicking around in the console - into terraform code? Is there a best practice approach?replyHikikomori5 hours ago|root|parent|next[–]Terraform 1.5 got a new import feature.https://www.hashicorp.com/blog/terraform-1-5-brings-config-d...replyvgeek13 hours ago|root|parent|prev|next[–]Check out Former2.replyearthling811820 hours ago|root|parent|prev|next[–]Well, that's likely the issue. You're spending more time avoiding doing it the way that will make everything go more smoothlyreplyryanSrich17 hours ago|prev|next[–]I think this is on topic.Does there exist a tool that gives me a fully abstracted layer like Heroku, but on my own AWS account? When I say fully, I mean fully. Where the tool will do maintenance, alert me a few days before it does it, autoremediation if something goes wrong, etc.?I essentially want the exact same functionality as Heroku, but with the cost savings of running it on my own infrastructure.replysuryao17 hours ago|parent|next[–]We handle things like maintenance. For example, kubernetes cluster upgrades are automated transparently for our users. We do not have auto remediation. That is a hard problem when we do not control the full runtime and hosting.replyksajadi15 hours ago|parent|prev|next[–]Yes. That’s exactly what Cloud 66 is.replybitlad15 hours ago|prev|next[–]It looks like yet another selfhostable Platform-as-a-service.This product (and all the PaaS abstractions for kubernetes) introduce something called '200% problem' where you have to not only issues in kubernetes now but also fix platform issues.Platforms like these existed since the dawn of cloud. I think the space is super crowded but no one has actually cracked this market. I think the total addressable market is fairly small for selfhostable PaaS.replyjamescmartinez17 hours ago|prev|next[–]Ok, I'll bite. We (mergent.co) have looked at similar tools before but ended up managing our own infra. This is primarily because the tools we've found focus on recreating Heroku/similar on our AWS, which doesn't suit our needs.For example, in addition to traditional applications, we run: - Kubernetes + Knative - Apache Pulsar - ScyllaDB - Elastic - Clickhouse (soon)How would Argonaut help us with our (frankly, painful) infra? We're living in YAML hell over here.replysuryao14 hours ago|parent|next[–]This type of use case leverages Argonaut's flexibility maximally. For traditional apps, the push-to-deploy CI/CD can be setup. For Pulsar and ScyllaDB, and Elastic there are helm charts that can be used very easily as a part of our AddOns which we are expanding continuously. For Knative and clickhouse, the best way to run them would be through Kubernetes operators. While this can be setup using Argonaut today, the experience feels janky and we're working on making this a first class entity in the product.The way Argonaut would help is by managing the configs and deployments in one place for easy collaboration and deployment, across environments and having GitOps with secret management for all the configs.replyzicon3521 hours ago|prev|next[–]This is a solid problem to be solved! Small engineering teams ought to solve business problems and not manage AWS/GCP hell.As someone who saw the earliest version of the product, the product has come a such a long way! Congrats!replyosigurdson12 hours ago|prev|next[–]I trust you but what exactly does it mean to provide you with GCP or AWS account information? What guarantees do your customers have that you won't be minting bitcoin using their account for example?replyosigurdson12 hours ago|parent|next[–]... and congrats on your launch!replyFBISurveillance20 hours ago|prev|next[–]Congrats on the launch. There was another YC-backed company that provided a ArgoCD as a service -https://www.koncrete.dev/It'd be interesting to know why they failed. I have to admit I got burnt a bit because we started to integrate with Koncrete and then they were out (and we've had to move away).replysuryao20 hours ago|parent|next[–]I don't have insider info about koncrete but there is akuity which does managed ArgoCD, built by the creators of ArgoCD, and that seems to be going well. Also, managed ArgoCD is one of ~4-5 things that we do - managed tf state and autogenerated tf, drag-drop CI builder, kubernetes management etc.replycollinc77711 hours ago|prev|next[–]Does this make it easy to switch cloud providers? One of the huge benefits I see here for startups is being able to continuously use free cloud creditsreplygautambt20 hours ago|prev|next[–]We've been using Argonaut for a while and have been a happy customer :) We deploy and manage our software on customers cloud accounts and Argonaut has been super useful for helping us manage all our deployments! Also a shoutout to Surya and his team for always being available in supporting us.replysuryao19 hours ago|parent|next[–]It's been a pleasure working with you and the bytebeam team.replynraf17 hours ago|prev|next[–]This looks very interesting. Been maintaining terraform scripts for a while that are frankly a nightmare to deal with at this stage.Are there any plans to support private clouds in future?replysuryao15 hours ago|parent|next[–]We are currently on AWS and GCP, with plans to expand to Azure later this year. Private clouds have not come up much in discussions so far, but we are open to it. How do you foresee a solution that works with private clouds to look like?replybovermyer22 hours ago|prev|next[–]How would this integrate (if at all) with other CI/CD tools, like Jenkins?replysuryao22 hours ago|parent|next[–]The CI runner logic is built on top of a CI agnostic abstraction layer called Dagger.io. This makes it super easy for the CI logic and integration portability. We are working on adding more CI providers.replyjagtstronaut21 hours ago|prev|next[–]Nice! Good luck to y’all.I’m in the middle of a particularly annoying ops ticket so this hits home today haha.replysuryao18 hours ago|parent|next[–]Every day is HugOps day in this land :)replyjuiiiced20 hours ago|prev|next[–]Is there any planned support for Azure? If not what is the reasoning (out of curiosity)?replysuryao20 hours ago|parent|next[–]We work with small-mid startups and not many of those use Azure :) IME, azure has higher adoption once there is a CIO in the company.However, in the Argonaut context, that only limits the overall infra management piece where we don't have a seamless integration using IAM roles and can't provision infra like dbs and queues. The app deployments to Azure kubernetes (or any k8s cluster) work seamlessly though, and some of our customers deploy to AKS in this manner.replyWaitWaitWha18 hours ago|prev|next[–]Does this work in Azure?Does this work in AWS Gov, Azure Gov, Google Cloud Gov?replysuryao17 hours ago|parent|next[–]Reg Azure, pasting my response from elsewhere in the thread:[...] in the Argonaut context, that only limits the overall infra management piece where we don't have a seamless integration using IAM roles and can't provision infra like dbs and queues. The app deployments to Azure kubernetes (or any k8s cluster) work seamlessly though, and some of our customers deploy to AKS in this manner.We do not support gov cloud yet.replyallanhahaha21 hours ago|prev|next[–]Congrats on the launch! I'm wondering how Argonaut compares to Porter (porter.run)  when it comes to DevOps as a service. Thank you!replysuryao19 hours ago|parent|next[–]They are building a very cool product. The difference is the following: (1) we focus on the entire infra and env management apart from being a kubernetes PaaS. This means you can setup cloud infra like managed kafka (MSK), docdb, SQS, CloudSQL, etc. as a part of your env without resorting to a different tool. Our customers love that single-pane experience. (2) We have no on-cluster agents and all code that runs on your cluster is yours alone (3) there is a slight difference in transparency vs ux tradeoff. We have a few more knobs you can control and that leads to more user involvement during setup.From a value perspective, we have a simple per-seat pricing.replythrow0317201918 hours ago|prev|next[–]Congrats on the launch. How does this compare to Convox?replyivanvas17 hours ago|parent|next[–]Both have SSO tax, it seems. Not nice.replysidcool19 hours ago|prev|next[–]I like the name.  Is it based on ArgoCD?replysuryao19 hours ago|parent|next[–]Thank you! The continuous delivery is powered by ArgoCD, but the name was chosen because we have some great folks on the team :)replyavg-devops-guy21 hours ago|prev|next[–]This would be dope if there was a self service options.replysuryao18 hours ago|parent|next[–]Do you mean a self-hosted option, since the product is self-service with support from our team? If so, I'd love to understand your constraints that require self-hosting. Email is surya@companyname.devreplyTjedjjd817 hours ago|prev|next[–]You have 5k RUBLOX and you must just/: Give email thanks/welcome(good game)..replycandiddevmike21 hours ago|prev[–]I really don't understand how companies just give AWS and GCP access (along with infrastructure and release management) to fly by night SaaS companies like yourself.  No security docs, no compliance audits, nothing.  To me, I'd use your customer list as companies to avoid interacting with, because there's a serious lack of due diligence on their part.replysuryao20 hours ago|parent|next[–]If I parse through and get to the concern being voiced, I'd rephrase it as \"how can I trust you with access to my cloud\".There is no easy answer but here is my response: 1. We take precautions to enable connections through oauth/app mechanisms for VCS integrations and IAM roles for cloud accounts like aws and gcp 2. Our incentives are aligned - we make money only if we earn and keep the trust of our customers 3. We have gone to extra lengths to enable easy exits in case companies want to move out.These, broadly speaking, are true for any other provider that you would use and maynowtrust for app hosting or CDNs or version control or payments - some of which are SmallCos and some were SmallCos until just a couple of years ago.At some level, it all boils down to \"trust us\" but hope this provides context.replyalex_suzuki19 hours ago|root|parent|next[–]The calm and professional way you respond to a needlessly aggressive comment does you credit.replybovermyer20 hours ago|parent|prev|next[–]The ad hominem attack and the hostility in your comment are unnecessary.replyalex_lav21 hours ago|parent|prev[–]Because GCP and AWS give access to \"fly by night\" devs, companies, products etc. as part of their business? Anyone can create a company, create some dev infrastructure and then _also_ ignore security and \"compliance\" best practices? What do you think a cloud vendor's role in this process is?replyGuidelines|FAQ|Lists|API|Security|Legal|Apply to YC|ContactSearch:\n",
      "---\n",
      "Why a browser and mail combination is worth it\n",
      "5 reasons why a browser and mail combination is great.BrowserMailNewsCommunityAboutDownloadVivaldi BlogAllNewsDesktopiOSAndroid5 reasons why a browser and mail combination is worth it.A browser with a built-in email client is a unique combination. Here are five reasons this combination helps improve your time spent online.ByDaniel AleksandersenJune 26, 20236900 viewsYour woes with email might be with your current email client but there’s nothing to stop you from getting a new one. If you’re looking for ways to be way more productive, we have the perfect combination for you — Vivaldi Mail built into the Vivaldi browser. It takes two to tango!The best email clients are focused on getting things done quickly, have customizable keyboard shortcuts, and give you features like search, filter, and more.Vivaldi Maildoes all of the above and more! We’ve always believed in the power of an email client integrated with the browser. Needless to say, this makes the whole experience powerful and productive.Unlike most email clients, Vivaldi Mail does all the heavy lifting for you – automatically detecting mailing lists and mail threads, as well as offering a powerful search feature. Vivaldi Mail is one of the most powerful email clients on the market, and it achieves its magic all on your local device.You can use multiple email accounts in Vivaldi Mail, so you don’t have to toggle back and forth between different apps. You get the tools to organize multiple inboxes and identities in one place.But there’s simply more to the advantages of this Mail+Browser combo. Here are five quick tips to make the most out of the combined browsing and email experience:#1 –Reply with tilingBy hitting “Reply” your message will open in a new browser tab. You can useTab Tilingto put your email reply and whatever web tabs you need to compose your answer side-by-side.In addition, if you’d like to view multiple messages at once you can open each message in a new tab by double clicking on them. Now you can tile all the emails, replies, forwarded, or new messages you’d like. All at once.Another benefit is that you can scroll up and down in a long message, and write a reply simultaneously without losing your place. Worth a try!#2 – Add links to the Reading ListRight-click on a link in a message and add it to the reading list. Voilà!Skim-read your newsletters, pick out what looks most interesting to you, and put them in the Reading List for later. This way you can quickly extract the best out of a pile of newsletters and move on to your next task.We built theReading Listinto the browser to save pages you want to read later. You can use it instantly – no service signup is required. You’ll discover it in the browser’s sidePanel.#3 –Open links in tabs and WorkspacesAs part of our design philosophy, we give different ways to use a feature or an action in the browser. This helps us adapt to the unique workflows of users.Therefore point no. 2 (above) has variations too! You can right-click on the link in an email to open it in the background tab.This, like the Reading List, allows you to process/skim through incoming emails with links, and open the important and valuable ones in the background. The downside of using an external client is that you have to open links in the foreground and change back and forth between different apps.Open links in Background Tabs.But we can do better! Let’s try using Workspaces. For example, perhaps you are working on a sales newsletter with a new game or some nice shoes, and you also have a Workspace named ‘Shopping’. You can simply open the link in the shopping workspace.Similarly, you can go through links that are work-related or private, or represent your hobbies, and open them into their respective Workspaces. This is not possible in external mail clients as they would always open links in the currently open workspace.Open links in WorkspacesPro-tip: We recommend usingWorkspacesin Vivaldi because it will help you tame your tab jungle beautifully and efficiently.#4–Translate messagesOpen a message in a foreign language, select the text, right-click the selection, and choose “Translate” from the menu.This may not be unique but what makes it special is that ourtranslation toolis privacy-friendly. The translation engine is hosted on Vivaldi servers in Iceland. This means there are no third-party servers involved. And it also means you don’t have to share what you read with ‘prying eyes’.Pro-tip: You can get extra perks by trying “Copy To Note” and “Add as Calendar Event” when right-clicking on the text that you highlighted.Translate a selection of text quickly.#5 –Quickly quote any text on a website in an emailSimply select a text on a website and right-click to ‘send by Mail’.For example, when you find an interesting piece of content on a website that you can’t wait to share, you can simply highlight the text, right-click, and pick “Send by email”. The highlighted text and link to the website will then be copied into a new email for you ready to edit and send once you’ve added some recipients.Share a text on a website through an email easily.Now that you have learned a thing or two about Vivaldi Mail and its ease to work with the browser’s functionality, you may ask yourself, “Great, but how do I set it up in the browser?”It is an easy process: start by downloading the Vivaldi browser. New users are asked to set up their email on the first run.v Already enjoying Vivaldi? Enable Mail from “Settings → Mail → Enable Mail, Calendar and Feeds”. From here, you can also add your email accounts.Setting it up comes with the added benefit of an integrated Vivaldi Calendar, which makes it a snap to manage schedules and coordinate meetings, and a built-in Feed Reader where you can subscribe to feeds on websites straight from the Address Bar.Finally, this might just come across as a relief to you — it does not lock you in the ecosystems of Big Tech. So if you are one of those who want to take control of your email situation, Vivaldi Mail will leave things in your control.Get Vivaldi Mail and Calander when getting started with the Vivaldi browser.Every story looks forward to its reactions from its readers. And rightly so, we are also looking forward to knowing which Mail+Browser combo you use or have used earlier. Or, is there a unique way in which you use Vivaldi Mail with the browser?Let’s get the discussion going in the comments below!Share articleFacebookMastodonTwitterRedditWritten byDaniel AleksandersencommentsPlease enable JavaScript to view commentsGet away from Big Tech and have fun doing itDownload VivaldiRelated articles12 ways to make Vivaldi your custom browserBe part of Vivaldi on iOS: Get the preview and give us feedback.*Freeze frame*, Vivaldi at Google I/O.Vivaldi HelpHelp articlesTutorialsAsk the communityReport a bugSubscribe to our newsletterBrowserDesktopAndroidiOSAutomotiveDownload VivaldiFeaturesCompare browsersMailMailCalendarFeed ReaderCompare email clientsNewsVivaldi BlogDesktop SnapshotsMobile SnapshotsHelpVivaldi Help PagesTutorialsReport a BugContactCommunityVivaldi CommunityBlogsForumThemesSocialContributeMerchandiseBannersAboutWhat We BelieveWe Don't Track YouPrivacy & TermsSecurityOur TeamJobsPress & MediaLinux DistributionsStatusAfrikaansAzərbaycancaбългарскиCatalàČeštinaDanskDeutschEnglishEspañolفارسیSuomiFrançaisGalegoMagyarՀայերենIndonesiaÍslenskaItaliano日本語関西弁TaqbaylitKurdishNederlandsNorsk bokmålpolskiPortuguês BrasileiroPortuguês EuropeuРусскийSlovenčinaSlovenščinaСрпскиSrpskiSvenskaTürkçeUkrainian简体中文繁體中文© Vivaldi Technologies™— All rights reserved.\n",
      "---\n",
      "Google has a secret browser hidden inside the settings\n",
      "403 - Forbidden | Access to this page is forbidden.\n",
      "---\n",
      "Hunter-gatherer lifestyle fosters thriving gut microbiome\n",
      "Hunter-gatherer lifestyle fosters thriving gut microbiomeSkip to main contentThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain             the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in             Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles             and JavaScript.AdvertisementView all journalsSearchLog inExplorecontentAboutthe journalPublishwith usSubscribeSign up for alertsRSS feednaturenewsarticleNEWS22 June 2023Hunter-gatherer lifestyle fosters thriving gut microbiomeSamples from the Tanzanian Hadza group included species previously unknown to science.Gemma ConroyGemma ConroyView author publicationsYou can also search for this author inPubMedGoogle ScholarTwitterFacebookEmailYou have full access to this article via your institution.Download PDFThe Hadza people of Tanzania are among the last hunter-gatherer societies in Africa.Credit: Boyd E. Norton/Science Source/Science Photo LibraryThe human gut is teeming with trillions of microbes, but most studies of this vast community have focused on people living in urban regions. Now, a team of researchers has sequenced gut microbiomes from Hadza people — members of a hunter-gatherer society in northern Tanzania — and compared them with those from people in Nepal and California1. The study has found not only that the Hadza tend to have more gut microorganisms than people in the other groups, but that a Western lifestyle seems to diminish the diversity of gut populations.The Hadza had an average of 730 species of gut microbe per person. The average Californian gut microbiome contained just 277 species, and the Nepali microbiomes fell in between. People with a farming-based lifestyle had an average of 436 microbe species, whereas those who live by foraging had an average of 317.The team also found species in the Hadza microbiomes that were not present in the Californian samples, such as the corkscrew-shaped bacteriumTreponema succinifaciens. Only some of the Nepali microbiomes contained this microbe, suggesting that the bacterium is dying out as societies become more industrialized.Redressing the balancePrevious research has found that human gut microbiomes vary across regions and lifestyles, but there is a lack of data from non-industrialized populations, says study co-author Justin Sonnenburg, a microbiologist at Stanford University in California. “Part of the sequencing effort was to help fill that gap and provide more data for regions of the world that are under-represented,” he says.Although it is well known that the microbiomes of people living non-industrial lifestyles are more diverse than those of people in industrialized societies, the findings show that the difference is more pronounced than previously thought, says study co-author Matthew Carter, also a microbiologist at Stanford.“The data greatly expand our picture of the human microbiome,” says Andrew Moeller, an evolutionary biologist at Cornell University in Ithaca, New York. “I am sure there are untold stories that remain hidden in the sequences.”The researchers sequenced microbiomes from fecal samples collected from 167 Hadza people — including infants and mothers — between 2013 and 2014. For comparison, the team also generated sequences from stool samples collected from four groups of people in Nepal in 2016, and samples from Californian participants in a 2021 study2that explored how diet affects the microbiome.Diversity dwindlesFrom these samples, Sonnenburg and his team sequenced more than 90,000 genomes from microbes found in the human gut, including bacteria, viruses that infect bacteria, and single-celled organisms from groups called archaea and eukaryotes. Some 44% of these microbial genomes had not yet been recorded in large catalogues such as the Unified Human Gastrointestinal Genome database. Among the genome sequences recovered from the Hadza samples, more than 1,000 were from bacterial or archaeal species that are new to science.Furthermore, gut-microbe species commonly found in industrialized populations often contained genes associated with responding to oxidative damage. The team suspects chronic inflammation in the gut could trigger such damage, creating a selective pressure for those genes, says study co-author Matthew Olm, a microbiologist at Stanford. “If you have a state of chronic inflammation, it would make sense that your gut microbiome has to adapt,” he says. These genes were not detected in the Hadza microbiomes.Samuel Forster, a microbiologist at the Hudson Institute of Medical Research in Melbourne, Australia, says that studying non-Western populations will help to build a more complete picture of the human gut microbiome and how it differs across lifestyles and regions. This could help researchers to track which species are disappearing in industrialized populations and how that affects human health, says Forster. “We have an opportunity to understand the full complement of microbes we carry,” he says. “It’s effectively avoiding an extinction event by understanding them now, before they’re lost.”doi: https://doi.org/10.1038/d41586-023-02065-yReferencesCarter, M. M.et al.Cellhttps://doi.org/10.1016/j.cell.2023.05.046 (2023).ArticleGoogle ScholarWastyk, H. C.et al.Cell184, 4137–4153 (2021).ArticlePubMedGoogle ScholarDownload referencesRelated ArticlesHow gut bacteria could boost cancer treatmentsSubjectsGenomicsMicrobiomeAnthropologyLatest on:GenomicsA pangenome reference of 36 Chinese populationsArticle14 JUN 23Have a high-pitched voice? It might be in your genesNews09 JUN 23‘Science was heard’: woman who was convicted of killing her children pardoned after inquiryNews06 JUN 23MicrobiomeHow I mixed microbiome research with public-health advocacyCareer Q&A15 JUN 23Mum’s microbes might boost brain development of c-section babiesNews15 JUN 23Mapping the Chinese microbiome: it’s time for a united effortSpotlight14 JUN 23AnthropologyLaos cave fossils prompt rethink of human migration mapNews13 JUN 23Ancient DNA reveals how farming spread into northwest AfricaNews & Views07 JUN 23Northwest African Neolithic initiated by migrants from Iberia and LevantArticle07 JUN 23JobsNeuroscience Postdoctoral ProgrammeThe Centre for Systems Neurobiology is now seeking Postdoctoral Fellows within several neuroscience research areasLinköping (Kommun), Östergötland (SE)Linköping University (LiU)Teaching Faculty and Lab Manager PositionsWestlake University is a new type of non-profit research-oriented university in Hangzhou, Zhejiang, the People's Republic of China, supported by pu...Hangzhou, Zhejiang, ChinaWestlake UniversityResearch positions of Lushan Botanical Garden of Chinese Academy of SciencesLushan Botanical Garden of Chinese Academy of Sciences is worldwide seeking applications for its research positions of the garden.Jiujiang, Jiangxi, ChinaLushan Botanical Garden of Chinese Academy of SciencesFaculty Positions in Westlake UniversityFounded in 2018, Westlake University is a new type of non-profit research-oriented university in Hangzhou, China, supported by public a...HangzhouWestlake UniversityMultiple Positions Open in Stomatology Hospital, Zhejiang University School of MedicineFounded in 1897, Zhejiang University (ZJU) ranks among the top 3 universities on Chinese mainland and within the top 100 in the Times Higher Educat...Hangzhou, Zhejiang (CN)Stomatology Hospital, School of Stomatology, Zhejiang University School of Medicine(ZJUSS)You have full access to this article via your institution.Download PDFRelated ArticlesHow gut bacteria could boost cancer treatmentsSubjectsGenomicsMicrobiomeAnthropologySign up to Nature BriefingAn essential round-up of science news, opinion and analysis, delivered to your inbox every weekday.Email addressYes! Sign me up to receive the dailyNature Briefingemail. I agree my information will be processed in accordance with theNatureand Springer Nature LimitedPrivacy Policy.Sign upClose bannerCloseSign up for theNature Briefingnewsletter — what matters in science, free to your inbox daily.Email addressSign upI agree my information will be processed in accordance with theNatureand Springer Nature LimitedPrivacy Policy.Close bannerCloseGet the most important science stories of the day, free in your inbox.Sign up for Nature BriefingExplore contentResearch articlesNewsOpinionResearch AnalysisCareersBooks & CulturePodcastsVideosCurrent issueBrowse issuesCollectionsSubjectsFollow us on FacebookFollow us on TwitterSubscribeSign up for alertsRSS feedAbout the journalJournal StaffAbout the EditorsJournal InformationOur publishing modelsEditorial Values StatementJournal MetricsAwardsContactEditorial policiesHistory of NatureSend a news tipPublish with usFor AuthorsFor RefereesLanguage editing servicesSubmit manuscriptSearchSearch articles by subject, keyword or authorShow results fromAll journalsSearchAdvanced searchQuick linksExplore articles by subjectFind a jobGuide to authorsEditorial policiesNature (Nature)ISSN1476-4687(online)ISSN0028-0836(print)nature.com sitemapAbout Nature PortfolioAbout usPress releasesPress officeContact usDiscover contentJournals A-ZArticles by subjectNanoProtocol ExchangeNature IndexPublishing policiesNature portfolio policiesOpen accessAuthor & Researcher servicesReprints & permissionsResearch dataLanguage editingScientific editingNature MasterclassesLive Expert Trainer-led workshopsResearch SolutionsLibraries & institutionsLibrarian service & toolsLibrarian portalOpen researchRecommend to libraryAdvertising & partnershipsAdvertisingPartnerships & ServicesMedia kitsBranded                         contentCareer developmentNature CareersNatureConferencesNatureeventsRegional websitesNature AfricaNature ChinaNature IndiaNature ItalyNature JapanNature KoreaNature Middle EastPrivacy                 PolicyUse                 of cookiesYour privacy choices/Manage cookiesLegal                 noticeAccessibility                 statementTerms & ConditionsYour US state privacy rights© 2023 Springer Nature Limited\n",
      "---\n",
      "Things That Count\n",
      "Things that Count -  - Things that CountThings that CountIntroductionPart 1 OriginsPart 2 Modern EraPart 3 Late ModernCollection CalculantPhoto galleryList of objectse-LibraryAn explanation?Contact the authorConditions of useDownload ebookNotesNew on the siteNew in the worldOther work by authorSome other objectsE.M.G. GramophonesListVideoedit SideBarGeminiSkinpowered byPmWikiEdit PagePage HistoryRecent ChangesThings that Count«  ||Part 1 Origins»IntroductionOn this page…(hide)1.Initial observations.2.Did increases in the power of  mathematics lead the development of calculators?  Was it the other way round?3.What is a calculator?4.A discussion in three parts.(Pascaline “1652” - working exemplar-collection Calculant)Welcome tothings-that-count.net.This website describes a collection of antique calculators (“collection Calculant”1)   and uses it to help develop a historical account of the way humans developed the need and capacity  to calculate, the things they used to help them, and how human societies (and even human brains) evolved with those developments.The account given here is of  a 37,000 year story, one in which humans came to count, record their counting and do simple arithmetic sums. Over time these capabilities became essential ingredients in what became increasingly complex societies. More citizens needed to be able to manipulate numbers in their daily lives and, over time, a range of aides of various sorts were developed to assist. At the beginning, the aides were very simple - for example, marks scribed on bones and patterns arranged with pebbles. Later, primitive devices and tables were developed and sold. Over time, much more elaborate mechanical devices were developed to help in this task. Many of these devices, where they survive, now represent little more than mechanical fossils.  Unused and largely forgotten their remains are scattered across history from earliest human pre-history to our present moment.The need for calculation, however has prospered. As  societies have become more complex, transactions in them depending on arithmetic (the familiar tasks of counting, adding, subtracting, multiplying and dividing), as well as more complex mathematics, have intensified. Yet over much of this period, for many people in these societies, doing even the simplest arithmetic tasks has been neither easy nor, for some, comprehensible.  For this reason finding ways to do these tasks faster and more accurately, and to spread the ability across more people, has been a preoccupation in many societies.  It is the approaches that have been taken to aid achieving these simple goals (rather than the development of complex mathematics) which is the primary focus of this website.Early “calculators” were not things. Rather they were people who were employed to calculate. Over time these people were first aided, but later replaced by calculating devices.  These devices became very widely used across many countries.  There is evidence we may now be passing the heyday of such stand-alone calculators. This is because, increasingly since the advent of electronic computing, the aides to calculation have begun to appear in virtual form as apps in phones, tablets and laptops. The end of calculators, seen as devices, in this sense is looming.One might imagine that a history of calculators would consist simply of the progressive discovery and invention of ever more effective and sophisticated calculating devices.  Indeed many such accounts do focus on this with loving details of the minutae of mechanical invention. But to focus simply on that is to oversimplify and lose much of what is potentially interesting.   Across human history many weird things were indeed devised for doing simple calculations.  But the development of these begs a series of questions:  When and why were they made, how were they used, and why at times were they forgotten for centuries or even millennia?The objects in“collection Calculant”described here, which are used to help illustrate answers to these sort of questions, are drawn from across some 4,000 years of history.  Each of them was created with a belief that it could assist people in thinking about (and with) numbers. They range from little metal coin-like disks to the earliest electronic pocket calculators - representing a sort of ‘vanishing point’ for all that had come before.     The collection and the history it illustrates in a sense form a duet - the two voices each telling part of the story. The history has shaped what has been collected, and the collection has helped shape how the story is told.1.  Initial observations.As most people know, the spread of electronic personal calculators of the 1970s was followed quickly by the first personal computers. Before long, computer chips began to be embodied in an ever expanding array of converging devices. In turn, ever greater computing power spread across the planet.  However sophisticated these modern computers appeared on the outside, and whatever the diversity of functions they performed, at heart they achieved most of this by doing a few things extremely fast. (Central to the things they did were logic operations such as “if”, “and”, “or” and “not”, and the arithmetic operations of addition and subtraction - from which multiplication and division can also be derived).  On top of this were layers of sophisticated programming, memory and input and output.Prior calculating technologies had to rely on slower mechanical processes.  This meant they were much more limited in speed, flexibility and adaptability.  Nevertheless they too were designed to facilitate the same fundamental arithmetic and logical operations.   The technologies of mathematics are in this sense much simpler than the elaborate analytic structures which make up mathematical analysis.   And for this reason, it is not necessary to consider all of mathematics in order to follow much of the history of how the technologies to aid mathematical reasoning developed.  Just considering the history of the development of aids to calculation can tell a great deal.  As already noted, it is that which is dealt with here.The calculational devices that were developed show an unmistakeable progression in complexity, sophistication and style from the earliest to the latest.   Corresponding to this it is possible to construct histories of calculational aids as some sort of evolution based on solving technical problems with consequent improvements in design building one upon the other.  But, as already noted, it is also important to understandwhythey were invented and used.Fortunately in order to understand what has shaped the development of these calculational aids we can largely avoid talking much about mathematics.  This is lucky because mathematics is by now a huge field of knowledge. So you are entitled to relief that in this site we will avoid much of mathematics.  We need not touch, for example, on calculus, set and group theory, the mathematics of infinite dimensional vector spaces that make the modern formulation of quantum mechanics possible, and tensors which Einstein used to express his wonderfully neat equations for the shape of space-time.2It will be sufficient to note that many modern challenges - from the prediction of climate under the stress of global warming, to the simulation of a nuclear reactor accident, to the deconstruction of DNA - could not occur without enormous numbers of calculations which in the end are constituted out of additions and subtractions (and multiplications and divisions) and can only be carried out in workable times with the use of ever faster calculating devices.Even keeping our attention restricted to the basic arithmetic operations,  it turns out we will still encounter some of the curly issues that we would have to think about if we were focussing on the whole evolving field of mathematical thought. Of course history of mathematics is itself a field of scholastic study which can be developed from many perspectives. These include those from the mainstream of history and philosophy of science3through to the sociology of science.4Even though this discussion here focuses on only a tiny “arithmetic core” of mathematics it will still be useful to take some account of this literature and its insights.  In particular, whether concerning ourselves with the evolution of the simple areas of mathematics or the more obstruse areas, one question is always raised: what led to this particular development happening as and when it did?2.  Did increases in the power of  mathematics lead the development of calculators?  Was it the other way round?It might be assumed that arithmetic, and more broadly, mathematics, developed through a process that was entirely internal to itself.  For example, this development might have been propelled forward because people could ask questions which arise within mathematics, but require the invention of new mathematics to answer them.Suppose we know about addition and that 2+2 =4. Then it is possible to ask what number added to 4 would give 2.  Answering that involves inventing the idea of a negative number. This leads to progress through ‘completing mathematics’ (i.e. seeking to answer all the questions that arise in mathematics which cannot yet be answered.) That must be part of the story of how mathematics develops. Yet the literature on the history of mathematics tells us this cannot be all.The idea of ‘mathematics’, and doing it, are themselves inventions. The question of when mathematics might be useful will have different answers in different cultures. Different societies may identify different sorts of issues as interesting or important (and only some of these will be usefully tackled with mathematics). Also different groups of people in those societies will be educated in what is known in mathematics.   Finally, different groups of people, or organisations, may have influence in framing the questions that mathematicians are encouraged (and resourced) to explore.But the same is true of invention.  At different times and in different cultures there have been quite different views taken on the value of change, and thus invention.  At some points in history the mainstream view has been that the crucial task is to preserve the known truth (for example, as discovered by some earlier civilisation - notably the ancient Greeks, or as stated in a holy book).   At other times or places much greater value has been placed on inventing new knowledge. Even when invention is in good standing there can be a big question of  who is to be permitted to do it.  And even if invention is applauded it may be still true that this may only be in certain areas considered appropriate or important.  This is as true in mathematics as in other areas of human activity.In short, a lot of factors can shape what is seen as “mathematics”, what it is to be used for, and by whom. As an illustration it is worth remembering that astrology has until relatively recently been considered both a legitimate area of human knowledge and a key impetus for mathematical development.  Thus E. G. Taylor writes of the understandings in England in the late sixteenth  century:  “The dictum that mathematics was evil for long cut at the very roots of the mathematical arts and practices. How were those to be answered for whom mathematics meant astronomy, astronomy meant astrology, astrology meant demonology, and demonology was demonstrably evil?”5Indeed, it was noted that when the first mathematical Chairs were established at Oxford University, parents kept their sons from attending let they be ‘smutted with the Black Art’.6However, despite these negative connotations, practioners of “the dark arts” played a strong role in developing and refining instruments and methodologies for recording and predicting the movement of “star signs” as they moved across the celestial sphere.One of the key features of the contemporary world is its high level of interconnection.  In such a world it is easy to imagine that developments in “mathematics” which happen in one place will be known and built on almost simultaneously in another. Yet that is a very modern concept.  In most of history the movement of information across space and time has been slow and very imperfect.  So what at what one time has been discovered in one place may well have been forgotten a generation or two later, and unheard of in many other places.  For this reason, amongst others already mentioned, talk of the evolution of mathematics as if it had a definite timetable, and a single direction is likely to be very misleading.History of course relies on evidence.  We can only know where and when innovations have occurred when evidence of them can be uncovered. Even the partial picture thus uncovered reveals a patchwork of developments in different directions. That is certainly a shadow of the whole complex pattern  of discovery, invention, forgetting, and re-discovery which will have been shaped at different times by particular needs and constraints of different cultures, values, political structures, religions, and practices.   In short, understanding the evolution of calculating machines is assisted by investigating it in the context of the evolution of mathematical thinking.  But that is no simple picture.  The history of developments in calculators and mathematics has been embroidered and shaped by the  the social, political and economic circumstances in which they emerged.  At times, mathematical developments have shaped developments in calculators, and and other times, the opposite has been true.3.  What is a calculator?“Calculator” could be taken to mean a variety of things.  It could be calculation ‘app.’ on a smart phone, a stand alone elctronic calculator from the 1970s, or the motorised and before that hand-cranked mechanical devices that preceded the electronic machines.  In earlier times it could simply mean someone who calculates. It is difficult to see where the line should be drawn in this regress all the way back to the abstract manipulation of ‘numbers’.In this discussion, “calculator” is used as shorthand for “calculating technology”. In particular it is taken to mean any physically embodied methodology, however basic, used to assist the performance of arithmetic operations (including counting).Thus a set of stones laid out to show what the result is if two are added to three (to give five), or if in three identical rows of five what the outcome is of multiplying five by three (to give fifteen) will be regarded as a simple calculator. So too, will the fingers of the hand, when used for similar purpose, and even the marking of marks on a medium (such as sand, clay or papyrus) to achieve a similar result.This approach is certainly not that taken in all the literature. Ernest Martin in his widely cited bookThe Calculating Machines (Die Rechenmaschinen)is at pains to argue of the abacus (as well as slide rules, and similar devices), that “it is erroneous to term this instrument a machine because it lacks the characteristics of a machine”.7In deference to this what is referred to here is “calculators” (and sometimes “calculating technologies or “calculating devices”).  Where the phrase “calculating machine” is used it will be in the sense used by Martin, referring to something with more than just a basic mechanism which would widely be understood to be  a machine. But with that caveat, the term “calculator” will be used here very broadly.The decision to apparently stretch the concept of calculator so far reflects a well known observation within the History and Philsophy of Science and Technology that in the end, technique and technology, or science and technology, are not completely distinct categories.  Technologies embody knowledge, the development of technologies can press forward the boundaries of knowledge, and technological development is central to discovery in science. As Mayr says in one of many essays on the subject, “If we can make out boundaries at all between what we call science and technology, they are usually arbitrary.”8Indeed, as will be described later, the mental image that mathematics is the work of mathematicians (‘thinkers’) whilst calculators are the work of artisans (‘practical working people’) is an attempt at a distinction that falls over historically, sociologically, and philosophically.4.  A discussion in three parts.This is a work in progress, which in part is why it is formed as a website.  So please regard it as a first draft (for which there may never be a final version).  For this reason, corrections, additional insights, or  links to other resources I should know about will be much appreciated.A word also about the way I have constructed the historical account.  In keeping with the analysis I have contributed to elsewhere (in a book by Joseph Camilleri and myself9), human development, will roughly be divided into a set of semi-distinct (but overlapping) epochs, preceded by a “pre-Modern Era” spanning the enormous time period from the birth of the first modern homo-sapiens to the beginning of the “Modern Period”. This beginning is set as beginning (somewhat earlier than is conventional) in themiddle of the sixteenth century, with the “Early Modern Period” continuing from themid-sixteenth to late eighteenth century, and the “Late Modern Period” stretching forward into the twentieth century, andterminating around the two world wars.  From thereon the world is regarded by Joseph Camilleri and myself as entering aperiod of transition10(but there is not much need to focus on that here).Thus the historical account is broken into three parts. The first part looks at the relationship between the evolution of calculating and calculators in the pre-Modern period. That forms a backdrop but only one object in the collection is of an appropriate age. Apart from that object (which is some 4,000 years old) the objects in this “collection Calculant” are drawn from the Modern Period (the earliest of these objects being from the early sixteenth century), and the Late Modern Period (from 1800) when mechanical calculation began to gain greater use in the broader society.«  ||Part 1 Origins»1“Calculant” in Latin means literally “they calculate”. (More precisely it is the third-person plural present active indicative of the Latin verb calculo ( calculare, calculavi) meaning “they calculate, they compute”).(↑)2See for examplehttp://mathworld.wolfram.com/EinsteinFieldEquations.htmlor for more explanationhttp://physics.gmu.edu/~joe/PHYS428/Topic9.pdf(both viewed 26 Dec 2011)(↑)3See for example, Eleanor Robson, Jacqueline A. Stedall,The Oxford handbook of the history of mathematics, Oxford University Press, UK, 2009(↑)4See for example, Sal Restivo,Mathematics in Society and History: Sociological Inquiries, Kluwer Academic Publishers, Netherlands, 1992(↑)5E.G.R. Taylor,The Mathematical Practitioners of Tudor & Stuart England 1485–1714, Cambridge University Press for the Institute of Navigation, 1970, p. 4.(↑)6John Aubrey quoted in Taylor, ibid, p. 8.(↑)7Ernest Martin,The Calculating Machines (Die Rechenmaschinen), 1925,  Translated and reprinted by Peggy Aldrich Kidwell and Michael R. Williams for the Charles Babbage Institute, Reprint Series for the History of Computing, Vol 16, MIT Press, Cambridge, Mass, 1992, p. 1.(↑)8Otto Mayr, “The science-technology relationship”, in Barry Barnes and David Edge (eds),Science in Context, The MIT Press, Cambridge USA, 1982, p.157.(↑)9Joseph Camilleri and Jim Falk,Worlds in Transition: Evolving Governance Across a Stressed Planet, Edward Elgar, UK, 2009(↑)10ibid, pp. 132–45.(↑)«  ||Part 1 Origins»Pages linked to this pageThis work by Jim Falkis licensed under aCreative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported LicenseClick on the logo to the left to see the terms on which you can use it.EditHistorySourceAttach FileBacklinksList GroupPage last modified on 08 May 2023skin configpmwiki-2.2.63\n",
      "---\n",
      "How to steal a masterpiece: Advice from the world’s greatest art thief\n",
      "How to Steal a Masterpiece | TimeTIME logoConnect WalletWallet SettingsDisconnect WalletMetaMaskWalletConnectSign InMy AccountMy AccountDigital                             MagazinesTIME StorefrontHelp CenterSign OutSubscribeSubscribeSpotlightWe've Gotten 'Custer's Last Stand' Wrong for Nearly 150 YearsCloseMy AccountMy AccountDigital                         MagazinesTIME StorefrontHelp CenterSign OutSign InSubscribeSectionsHomeU.S.PoliticsWorldHealthClimateFuture of Work by CharterBusinessTechEntertainmentIdeasScienceHistorySportsMagazineTIME 2030Next Generation LeadersTIME100 Leadership SeriesTIME StudiosVideoTIME100 TalksTIMEPiecesThe TIME VaultTIME for HealthTIME for KidsTIME EdgeTIME CO2Red Border: Branded Content by TIMEPersonal Finance by TIME StampedShopping by TIME StampedJoin UsNewslettersSubscribeGive a GiftShop the TIME StoreTIME Cover StoreCustomer CareUS & CanadaGlobal Help CenterReach OutCareersPress RoomContact the EditorsMedia KitReprints and PermissionsMoreAbout UsPrivacy PolicyYour California Privacy RightsTerms of UseSite MapConnect with UsPresented ByIdeasCultureHow to Steal a Masterpiece: Advice from the World’s Greatest Art ThiefHow to Steal a Masterpiece: Advice from the World’s Greatest Art ThiefPortrait of Madeleine de France (1443-1495), eldest daughter of Francois I, Queen of Scots, first wife of Jacques V. Painting by Corneille de Lyon (Corneille de La Haye) (1500/1510-1574). Oil on wood. 0,22 x 0,31. Castle Museum, Versailles, FranceLeemage-CorbisIdeasByMichael FinkelJune 14, 2023 7:05 AM EDTFinkel is the author ofThe Art Thief: A True Story of Love, Crime, and a Dangerous PassionFirst, says the art thief, forget about the movies.Skylight entries, smoke bombs, and shootouts may be cinematic, but unless you want to go to jail, these are terrible tactics for stealing art. Violence and destruction in a museum only minimize your odds of success. Art crime, according toStéphane Breitwieser, is best accomplished when no one knows that it’s happening.Breitwieser, a 52-year-old Frenchman, is one of the greatest art thieves of all time. He stole over 300 works from museums and cathedrals across Europe, worth an estimated two billion dollars. While I was preparing to write a book about him, Breitwieser granted me dozens of hours of interviews, during which he revealed in great detail his criminal mind.There’s never a need, he said, to force open a museum door, or crawl through a window, or rappel through a skylight. Don’t even come when the museum is closed. Ideally, arrive during lunch, when the crowds are thinner and the security staff rotates shorthanded to eat. Do not stress about parking the car – anywhere near the museum is fine.More from TIMEDon’t come alone. You’ll need a trustworthy accomplice as lookout. Breitwieser’s partner was his long-time girlfriend, Anne-Catherine Kleinklaus. To blend in with the tourists, they always dressed sharply. Cooler weather, Breitwieser emphasized, is preferable for stealing. This way, you can wear an overcoat – just make sure that your stealing coat is at least one size too big, and that your pants are a little loose at the waist.The only tool necessary is a Swiss Army knife. Stash it in a pocket of your coat. The best way to gain access to a museum is through the main entrance. Purchase a ticket for you and your partner in cash. Walk in.Once inside, note the flow of visitors and check for surveillance cameras. Are the guards sitting or patrolling? Select a side room that’s out of the main river of tourists, preferably a gallery with a single entryway and no security camera or permanent guard. It’s not hard to find such a spot in many museums, especially smaller ones.As for the artwork to target, the piece should be small – for a sculpture, about the size of a brick; for a painting, no larger than a pizza box. More importantly, the work must be aesthetically attractive to you. Taking on all this risk for an object you don’t like, Breitwieser said, is the mark of a fool.Station your partner at the entrance to the room. Agree on a warning signal. For Breitwieser and Kleinklaus, theirs was a brief cough. If visitors are in the room, wait for them to exit. Then move swiftly to your targeted item. If the piece is in a display case, the access panel will probably be bolted shut. It doesn’t matter; you’re not going to pick it – that’s difficult and time-consuming. Instead, leave the lock fastened and use what Breitwieser called the “silicone slice.”Museum display cases are made of tempered glass or a clear acrylic like Plexiglas or Lucite, usually fused at the edges with silicone glue. A fine surgeon’s cut will release this seal, and by operating on a corner with the sharpest blade of your Swiss Army knife, hairline incisions both vertical and horizontal, the panels will loosen.If your partner coughs, stop cutting and push the panels together. They should revert to their original position. Whether it’s a guard or a tourist that enters, abandon your posts and gaze contemplatively at various works in the room. Allow the gallery to empty again, then return to the mission.Sometimes there will be two or three such disturbances. Don’t spend a suspiciously long time in one room – 15 minutes or so is the maximum. If there’s too much traffic, abandon the attempt. Try another room, or another day, or another museum.The beauty of a completed silicone slice is that it permits the panels to flex open just enough to snake a hand through. Grasp your desired piece and wriggle it out through the gap. Now, brush aside your overcoat and tuck the object snugly into the waist of your pants at the small of your back. Readjust your coat so the artwork is covered. There will be a slight lump, but Breitwieser promises that no one will notice.If you’re after a painting, the easy part is removing the work from the wall. Often all you have to do is lift it. The challenge is the frame; even on small paintings, most frames are too bulky to hide beneath an overcoat, no matter how roomy.Breitwieser’s solution: turn the painting over and place it face-down on a display case or the floor. He used his Swiss Army knife to manipulate the clips or nails on the back until the frame was detached. If there was no time for such diligence, he put the work back on the wall and left empty-handed. When he removed a frame, Breitwieser liked to stash it in the gallery behind a window curtain or under a piece of furniture. Empty frames, he said, were his calling card.To master frame removal, Breitwieser became an expert at putting frames on by apprenticing in a high-quality frame shop. To comprehend the degree to which museum guards actually pay attention, he worked as a guard one summer. Any good thief, he said, should prepare as thoroughly.A painting that’s free of its frame, Breitwieser warned, is as vulnerable as a newborn. With extreme care, place the painting at your back, cushioned between your shirt and overcoat.Now leave the museum with your partner. No matter how covert your actions, the theft will likely be noticed quickly, triggering an emergency response. The police will be called. The museum could be locked down, and all visitors searched.Hustle to the museum’s main exit, but never run, inside the museum or out, even if you hear police sirens approaching – especially then. Walk to your car, place the stolen work gently in the trunk, and drive off.Do not speed! The last thing you need now is to be stopped by a cop. Once at home, put the work in a place where no one might accidentally see it. Breitwieser and Kleinklaus stashed their loot in the bedroom they shared, which they always kept locked.Admire your stolen work to your heart’s content, but one thing you absolutely can not do, Breitwieser said, is sell it. Trying to sell a stolen piece for money is how most art thieves get caught. Police detectives who specialize in art theft are trained to uncover these transactions. If you need cash, said Breitwieser, get a job. Money can be made with far less danger than art crime.Steal all the art you want. Starting in 1995, Breitwieser and Kleinklaus committed an average of one theft every two weeks for seven years. But it’s probably best to rid yourself of any social or moral conscience you might have. Or, you can do as Breitwieser did, find a reason to justify your actions. Rather than an art thief, Breitwieser considered himself an art liberator, freeing masterpieces from uncomfortable and crowded confines. This way, stealing from a museum – one of the miracles of modern society, offering public access to priceless works of communal heritage – won’t bother you at all.Also, it would be best if you did not have any friends or relatives, or need a repair person, because you can never invite anyone into your home.Finally, do not make any mistakes, either while stealing or hiding art. Being human, you may find this impossible. In which case, be prepared to spend time in jail. Breitwieser was imprisoned for years. Accept that you may have a criminal record for life.Or, instead, you can just leave the work in a museum and visit it whenever you like.More Must-Reads From TIMEHow'Barbie' Came to LifeAmerica's Second Year Post-RoeWill Be BusyMiss Benny IsGlamorous—And TransgenderEssay:I Fell for a Famed Artist. Then He Got ViolentHow theWomen’s World Cup Evolved Into What It Is TodayTheDangers of Unregulated Deep-Sea TourismPodcast:Elliott Page Steps Into His TruthThe TrueHistory of 'Custer's Land Stand'These Are the100 Most Influential Companies of 2023Contact usatletters@time.com.TIME Ideashosts the world's leading voices, providing commentary on events in news, society, and culture. We welcome outside contributions. Opinions expressed do not necessarily reflect the views of TIME editors.You May Also LikeRead NextReligion Is an Ex I’m Still Trying to Leave BehindNext Up: Editor's PickHow Black Filmmakers Are Reclaiming Their History OnscreenEDIT POSTHomeU.S.PoliticsWorldHealthBusinessTechPersonal Finance by TIME StampedShopping by TIME StampedFuture of Work by CharterEntertainmentIdeasScienceHistoryNewsfeedSportsMagazineThe TIME VaultTIME For KidsTIME CO2TIME EdgeVideoMastheadNewslettersSubscribeSubscriber BenefitsGive a GiftShop the TIME StoreCareersPress RoomTIME StudiosU.S. & Canada Customer CareGlobal Help CenterContact the EditorsReprints and PermissionsSite MapMedia KitSupplied Partner ContentAbout Us© 2023 TIME USA, LLC. All Rights Reserved. Use of this site constitutes acceptance of ourTerms of Service,Privacy Policy(Your California Privacy Rights) andDo Not Sell or Share My Personal Information.TIME may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.  |EU Data Subject Requests\n",
      "---\n",
      "OPNsense: Open-source security platform\n",
      "OPNsense® a true open source security platform and more - OPNsense® is a true open source firewall and moreAboutAbout OPNsenseMarkets & FeaturesRoadmap & FutureLegal GuidelinesContactUsersGet StartedDevelopersDevelopersRoadmap & FuturePartnersPartner benefitsOPNsense® PartnersSupportForumDocumentation/wikiCommercial SupportProfessional servicesBlogDownloadOfficial ShopDonateSecure Your Network with easeFrom Virtual Private Networking to Intrusion Detection, Best in class, FREE Open Source Project.Download OPNsense®Sign-up for ETPRO TelemetryVersion 23.1 - \"Quintessential Quail\"From Virtual Private Networking to Intrusion Detection, Best in class, FREE Open Source Project.Checkout the OPNsense® Business EditionCommercial firmware repository, OVA image, Central Management, integrated GeoIP database, 20% discount on business support package and an easy way to support the project!SUBSCRIBEAvailable Now! - 4th Edition!The complete 4th Edition of Practical OPNsense® byMarkus StubbigSimple packet filters are becoming a thing of the past. Even the open-source domain is moving towards Next-Generation Firewalls. And OPNsense is a top player when it comes to intrusion detection, application control, web filtering, and anti-virus. No network is too insignificant to be spared by an attacker. Even home networks, washing machines, and smartwatches are threatened and require a secure environment. Firewalls are a component of the security concept. They protect against known and new threats to computers and networks. A firewall offers the highest level of protection if its functions are known, its operation is simple, and it is ideally positioned in the surrounding infrastructure. OPNsense accepts the challenge and meets these criteria in different ways. This book is the ideal companion for understanding, installing and setting up an OPNsense firewall.Buy online from Bod Buchshop [German] or Amazon [English]Also bundled with the OPNsense® Business Edition license as E-book.Der OPNsense® PratikerPratical OPNsense®OPNsense® BE [E-book EN/DE]OPNsense®FEATURESFree & Open source - Everything essential to protect your network and moreFIREWALLStateful firewall with support for IPv4 and IPv6 and live view on blocked or passed traffic.MULTI WANMulti WAN capable including load balancing and failover support.VIRTUAL PRIVATE NETWORKINGIntegrated support for IPsec (including route based),OpenVPNas well as pluggable support forTinc(full mesh VPN) andWireGuard.HARDWARE FAILOVERWhen you cannot afford downtime use our automatic and seamless hardware failover with state synchronization utilizing the common address redundancy protocol (CARP) to get the highest possible availability.SD-WANFor easy setup, configuration and monitoring theZeroTierplugin can be used to setup your Software Defined WAN within minutes.INTRUSION DETECTION & PREVENTIONGet rid of the Trojans & CNC bots with state of the art inline intrusion prevention utilizingSuricataandProofpoint's Emerging Threats Open rules integrated. Optional ET PRO (commercial subscription) or ET PRO Telemetry (sign-up for free).TWO FACTOR AUTHENTICATION2FA is supported throughout the system, for both the user interface and services such as VPN.ROUTING PROTOCOLSPluggable support for OSPF and BGP using theFree Range Router project.WEB FILTERINGFully integrated web proxy with access control and support for external blacklists to filter unwanted traffic.Other options include firewall aliases and DNS blacklisting. Block ads with ease!INTUITIVE USER INTERFACEThe most intuitive fully responsive user interface you'll find in any open source firewall with integrated search option.MULTI LANGUAGEUser selectable language support including English, Czech, Chinese, French, German, Italian, Japanese, Portuguese, Russian and Spanish.ONLINE DOCUMENTATIONFully searchable free onlinedocumentation.NEXT GENERATION FIREWALL EXTENSIONS: ZENARMORFREE & COMMERCIAL OPTIONSZenarmoris a versatile plug-in extension for OPNsense developed by Sunny Valley Networks. OPNsense users can easily deploy Zenarmor NGFW free of charge with Threat Intelligence to easily secure environments of all sizes, ranging from home networks to multi-cloud deployments. The packet inspection engine is powerful enough to protect against encrypted threats while also being so lightweight and nimble that it can fit even in very resource-constrained environments. For enhanced features a commercial version can be acquired online directly fromSunny Valley Networks.AND MUCH MORECAPTIVE PORTAL, TCP/HTTP LOAD BALANCER, NETFLOW MONITORING, REST API, and more...BUSINESS EDITIONThe OPNsense® Business Edition is intended for companies, enterprises and professionals looking for a more selective upgrade path (lags behind the community edition), additionalcommercial features and who want to support the project in a more commercial way compared to donating. Order your license today direct from our onlineshop.Compile or Contribute?Checkout the sources!It's no secret, everything is on GitHubOPNsense is a Deciso® Open Source ProjectDeciso B.V. started the OPNsense project in 2014 with its first official release in 2015.CHECKOUT DECISO>500KLines of Code>70Plugins>200Releases17Major ReleasesTESTIMONIALSFrom the usersManuel Alexander HerzogOPNsense User\"Sophos UTM is good but to sofisticated for my needs. So I tried OPNsense and now EVERYTHING is as I want to have it. It is simple and with a great GUI.\"Boris HoppeCEO CompuNet Systems GmbH\"OPNsense provides more features, more reliability and more performance than any other commercial firewall product we had in use ever before. Being open source, we have full access regarding update plans and so on.\"LeandroOPNsense User - source Twitter\"The Best choice for security on the open source world.\"The best day to migrate to OPNsense was eight years ago, the second best is today.The only open source security platform with a simplified 2-clause license (BSD/MIT license) is just one click away...Edison 433241LS Middelharnis (The Netherlands)project@opnsense.orgStay updatedOPNsenseis anOSSproject ©Deciso B.V.2015-2023 - All rights reserved -Terms and Conditions-Privacy Policy\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pprint\n",
    "\n",
    "def extract_feed_text(feed: dict):\n",
    "    \"\"\"\n",
    "    Extract the text content of a link\n",
    "    \"\"\"\n",
    "    for item in feed['items']:\n",
    "        link = item['link']\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        text = soup.get_text(strip = True)\n",
    "        text = text.replace('\\n', ' ')\n",
    "        item['text'] = text\n",
    "        print('---')\n",
    "        print(item['title'])\n",
    "        print(item['text'])\n",
    "\n",
    "for feed in feeds:\n",
    "    print(feed['title'])\n",
    "    extract_feed_text(feed)\n",
    "    # pprint.pprint(feed, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize\n",
    "\n",
    "We use the OpenAI API to summarize the relevant documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#articles: 30\n",
      "article #0\n",
      "https://neal.fun/deep-sea/\n",
      "The website \"The Deep Sea\" created by neal.fun is an interactive infographic that explores the depths of the ocean and the creatures that live within it. It provides a vertical view of the ocean in relation to how deep different creatures live. The infographic highlights various sea creatures ranging from the smallest fish to the largest known animal on earth, the blue whale. The website allows you to click on each creature to learn more about their characteristics and habits. Additionally, the website shows the impacts of human activities on marine life through trash and pollution. Overall, the website offers a unique and informative look at the wonders and challenges of the underwater world.\n",
      "article #1\n",
      "https://saurabhs.org/advanced-macos-commands\n",
      "The article provides a list of advanced Mac OS commands that can be used in the Terminal application. The commands range from navigating the file system to managing permissions and network connectivity. The author explains each command in detail and provides examples of how they can be used to perform various tasks. The article is intended for users who are comfortable using the Terminal and want to learn new ways to optimize their Mac OS experience.\n",
      "article #2\n",
      "https://blogs.loc.gov/loc/2023/06/bloomsday-the-librarys-one-of-a-kind-copy-of-ulysses/\n",
      "The article talks about the Library of Congress' unique copy of the book \"Ulysses\" by James Joyce, which is specially bound and contains handwritten notes and corrections by Joyce himself. The article goes on to discuss the significance of the book and its connection to the holiday Bloomsday, which celebrates the events of the novel that take place on June 16th. The article also discusses the Library's efforts to preserve and make accessible their copy of the book.\n",
      "article #3\n",
      "https://github.com/wolfi-dev\n",
      "The linked page is a GitHub profile belonging to a user named \"wolfi-dev\". GitHub is a platform used for hosting and collaborating on software code. The profile contains information about the user and the open-source projects they have worked on. It also displays the user's contributions to other projects and their activity on the platform.\n",
      "article #4\n",
      "https://www.gibney.org/a_syntax_for_self-tracking\n",
      "The article proposes a new syntax for self-tracking, which is a method of keeping track of one's personal data, such as health or fitness information. The syntax involves using descriptive terms for measurements, such as saying \"I walked for 20 minutes at a moderate pace\" instead of just \"I walked.\" This method aims to make self-tracking more informative and useful by providing specific details about the data being tracked. The article also suggests incorporating self-reflection into the tracking process, which can help individuals understand why certain patterns or behaviors are occurring.\n",
      "article #5\n",
      "https://www.visuality.pl/posts/a-simple-guide-to-pessimistic-locking-in-rails\n",
      "The article titled \"A Simple Guide to Pessimistic Locking in Rails\" provides an overview of how pessimistic locking can be implemented in Ruby on Rails applications. The author explains that pessimistic locking is a technique used to prevent multiple users from accessing and modifying the same data simultaneously, which can lead to data inconsistencies and errors. The article walks through the steps required to implement pessimistic locking in a Rails application, including adding a lock attribute to relevant models, using the ActiveRecord `with_lock` method to lock records during updates, and handling potential deadlock scenarios. The author concludes by emphasizing the importance of strategic usage of pessimistic locking, as indiscriminate use can lead to decreased application performance.\n",
      "article #6\n",
      "https://rigtorp.se/ringbuffer/\n",
      "The article talks about the Ring Buffer data structure, which is a practical and efficient solution for buffering data in computer programs. The author explains how it works, and how it can be implemented in different programming languages, including C++, Java, and Rust. The article also discusses the advantages of using a Ring Buffer, such as its constant time complexity for insertion and deletion, and its ability to handle large amounts of data efficiently. The author also provides some practical examples and use cases for the Ring Buffer.\n",
      "article #7\n",
      "https://news.ycombinator.com/item?id=36491647\n",
      "The linked article on Hacker News reports that the US Department of Defense has canceled the $10 billion JEDI (Joint Enterprise Defense Infrastructure) contract which was initially awarded to Microsoft in 2019. The cancellation comes after years of legal battles and delays, with the DoD citing changes in technology and their needs as the primary reason for the decision. The contract was intended to modernize the Pentagon's computing infrastructure by moving its data to the cloud. It is unclear whether the DoD will pursue a new contract to achieve their goals.\n",
      "article #8\n",
      "https://twitter.com/paulg/status/1673622294227308546\n",
      "The tweet by Paul Graham says that people tend to overestimate the importance of luck in successful endeavors and underestimate the role of deliberate practice and hard work. While luck may play a role in some instances, consistent effort and focus towards a goal is what ultimately leads to success.\n",
      "article #9\n",
      "https://www.nytimes.com/2023/06/20/magazine/hotel-bars.html\n",
      "The article explores the history and cultural significance of hotel bars around the world, from the famous Ritz Paris to the lesser-known Lobby Bar at the Ace Hotel in Los Angeles. These bars have served as meeting places for travelers, locals, and celebrities alike, and have played a role in shaping the drinking culture of their respective cities. While some hotel bars have struggled to survive in a changing hospitality industry, others have adapted and continued to thrive as beloved destinations for libations and camaraderie.\n",
      "article #10\n",
      "https://akashrajpurohit.com/blog/build-your-own-docker-with-linux-namespaces-cgroups-and-chroot-handson-guide/\n",
      "The article provides a step-by-step guide to building a Docker-like container from scratch using Linux namespaces, cgroups, and chroot. It explains how to create a basic container which can run a simple web application and how to limit its resources. The article also covers the basics of Linux namespaces and cgroups and how they work together to provide container isolation. Additionally, it discusses the importance of chroot jail to contain the container's file system. Overall, the article offers a comprehensive and hands-on guide to building a Docker container from the ground up.\n",
      "article #11\n",
      "http://www.solipsys.co.uk/new/UnexpectedInteractionOfFeatures.html?wf26hn\n",
      "The article discusses how different features of a product or system can interact in unexpected ways, leading to unintended consequences. This can occur due to complex relationships between the features or due to unforeseen user behavior. The author provides several examples to illustrate the point, including a video game in which the ability to jump also affects the character's health and a car with a safety feature that unexpectedly shuts off the engine while driving. The article concludes that designers and developers must consider the potential interactions between features to avoid unintended consequences.\n",
      "article #12\n",
      "https://mofi.loud.red/\n",
      "I'm sorry, I cannot access the link provided as it appears to be invalid or broken. Could you please provide another link or article for me to summarize?\n",
      "article #13\n",
      "https://x0axz.com/blog/autograd.html\n",
      "The article \"Autograd: What is it and why do we need it?\" explains what autograd is and why it is important in machine learning. Autograd is a tool in Python's PyTorch library that automatically calculates the gradients of mathematical expressions. This is essential in deep learning algorithms, as calculating gradients manually would be extremely time-consuming and error-prone. The article goes on to explain the drawbacks of traditional automatic differentiation, the process by which gradients are calculated, and how autograd solves these issues by introducing a dynamic computation graph. Overall, the article provides a clear and concise overview of autograd and its significance in machine learning.\n",
      "article #14\n",
      "https://phys.org/news/2023-06-ninth-dedekind-scientists-long-known-problem.html\n",
      "Mathematicians have finally solved the ninth Dedekind problem, which has been an open problem since it was posed in 1900. The problem involves finding a formula for the generating function of a certain sequence of numbers, and has been attempted by many mathematicians over the past century. The solution involved a combination of algebraic geometry and combinatorics. The discovery of the solution is expected to have far-reaching implications in a variety of mathematical fields.\n",
      "article #15\n",
      "https://spin.atomicobject.com/2023/06/26/dexec-docker/\n",
      "The article is about a tool called DExec, which allows developers to easily run Docker containers on remote machines without having to manage the infrastructure. Instead, DExec automates the process of spinning up, tearing down, and managing the containers, so that developers can focus on writing and testing their code. The article goes into detail about the design and implementation of DExec, and provides examples of how it can be used. The author also discusses some of the potential benefits of using DExec, such as increased scalability, better resource utilization, and easier collaboration between teams.\n",
      "article #16\n",
      "https://eatrightindia.gov.in/dart/\n",
      "The website is an initiative by the Indian Government to promote healthy eating habits and prevent diet-related diseases. The website provides information and resources on nutrition, recipes, healthy eating, food safety, and guidelines for different age groups. The goal of the initiative is to empower individuals with knowledge and skills to make informed decisions about their health and nutrition.\n",
      "article #17\n",
      "https://marctenbosch.com/news/2023/03/4d-toys-update-v-1-8-rotating-the-3d-slice-2d-faces-projections-marble-scenes-and-many-more/\n",
      "The article is about the latest update to the 4D Toys app, which allows users to manipulate and play with four-dimensional objects in a virtual space. The new features include the ability to rotate a 3D slice of a shape, view 2D projections of 4D objects, and create marble scenes with new interactive tools. The article also mentions a new feature that allows for 3D printing of these objects.\n",
      "article #18\n",
      "https://people.inf.ethz.ch/omutlu/pub/RowPress_isca23.pdf\n",
      "The article presents a new approach to overcome the limitations of traditional row buffer management techniques in DRAM (Dynamic Random Access Memory) chips. The proposed technique, called RowClone, allows copying of rows between independent banks without incurring any additional overheads. This helps to reduce latency and increase memory capacity. The authors demonstrate that RowClone can reduce row buffer conflicts by up to 68% and improve overall system performance by up to 28% on a range of workloads. This is achieved without any changes to the hardware or software interface of existing DRAM chips.\n",
      "article #19\n",
      "https://lilianweng.github.io/posts/2023-06-23-agent/\n",
      "The article discusses the development of artificial intelligence (AI) agents, which are computer algorithms designed to think and act on behalf of humans in specific tasks. The author outlines the history of AI agents, from rule-based systems in the 1960s to deep learning models today. They describe the various components of an AI agent, including perception, reasoning, and action, and the challenges involved in designing agents that can operate in complex environments. The author also discusses some of the ethical considerations involved in creating AI agents, such as bias and transparency.\n",
      "article #20\n",
      "https://www.dialup.net/wingpt/tls.html\n",
      "Unfortunately, the link provided is no longer valid and returns an error page.\n",
      "article #21\n",
      "https://doubleagent.net/2023/05/21/a-car-battery-monitor-tracking-your-location\n",
      "The article discusses a new car battery monitoring device that also tracks the location of the car. The device uses GPS technology to track the car's location and send this data to a mobile app. While the device can provide useful information about the car's battery life and performance, concerns have been raised about the potential privacy implications of the location tracking feature. The article suggests that users should carefully consider whether they are comfortable with the device's tracking capabilities before installing it in their car.\n",
      "article #22\n",
      "https://barrgroup.com/embedded-systems/how-to/network-processors\n",
      "The article explains what network processors are and how they work in embedded systems. It goes on to discuss the different types of network processors and delves into their architectures, interfaces, and applications. Additionally, it examines aspects such as security, power consumption, software development, and testing strategies that are involved when working with network processors. Finally, it concludes with insights on industry trends and challenges that are faced by developers.\n",
      "article #23\n",
      "https://news.ycombinator.com/item?id=36480230\n",
      "The article describes a research paper on a new artificial intelligence (AI) algorithm that can analyze and predict the molecular structures of small organic compounds. The algorithm uses a combination of deep learning and evolutionary algorithms to generate and test possible molecular structures. The research team tested the algorithm on a set of compounds with known structures and found that it accurately predicted their shapes and properties. The algorithm could be used to accelerate drug discovery and reduce costs associated with experimental testing.\n",
      "article #24\n",
      "https://vivaldi.com/blog/how-to/5-reasons-why-a-browser-and-mail-combination-is-worth-it/\n",
      "The blog post explains the benefits of using a browser and mail combination, specifically the Vivaldi browser with its built-in mail client. The five reasons given are: efficiency and productivity, simplicity and organization, security and privacy, flexibility and customization, and a better experience overall. The post goes on to provide examples and details for each reason and concludes by encouraging readers to try out the Vivaldi browser and its integrated mail client.\n",
      "article #25\n",
      "https://matan-h.com/google-has-a-secret-browser-hidden-inside-the-settings/\n",
      "The article explains how Google has a hidden browser within the settings of its Android operating system. This browser is called the \"Android WebView\" and is essentially a stripped-down version of Google Chrome. The WebView has a few limitations compared to Chrome, such as no support for Chrome extensions or Google Translate. However, it is still a useful tool for developers and anyone who needs to view web content within an app. The article provides step-by-step instructions on how to access the WebView in the Android settings menu.\n",
      "article #26\n",
      "https://www.nature.com/articles/d41586-023-02065-y\n",
      "The article discusses how scientists are studying the behavior of electrons in materials called topological insulators. These materials have unique properties that allow electrons to move without colliding with each other, making them useful for developing new technologies such as quantum computing. However, researchers are still not sure how to control and manipulate these electrons effectively. Recent studies have revealed new insights into the behavior of topological insulators, which could lead to more precise control over their properties and potential breakthroughs in quantum technology.\n",
      "article #27\n",
      "http://meta-studies.net/pmwiki/pmwiki.php?n=Site.Introduction\n",
      "The website http://meta-studies.net is an online resource which provides information about meta-studies, their methodology, and their application in different fields. Meta-studies are scientific studies that analyze and combine data from multiple studies in order to derive more conclusive and generalizable results. The website provides various resources including a meta-study database, a list of meta-analysis software, and a collection of meta-study articles. It also offers online courses on meta-study methodology and data analysis. The website aims to promote the use of meta-studies as a powerful tool for evidence-based decision making in different areas of research and policy-making.\n",
      "article #28\n",
      "https://time.com/6286931/how-to-steal-a-masterpiece-advice-from-the-worlds-greatest-art-thief/\n",
      "The article explores the life of the world's greatest art thief, Stéphane Breitwieser, and the methods he used to steal over $1.4 billion worth of art. It discusses the importance of planning and patience in his thefts, as well as the reckless mistakes that ultimately led to his downfall. Breitwieser's story offers a glimpse into the mysterious world of art theft and the lengths some will go to acquire valuable pieces.\n",
      "article #29\n",
      "https://opnsense.org/\n",
      "The website opnsense.org is the official website for a popular open source firewall and routing platform called OPNsense. The website provides information on the features of OPNsense, instructions on how to download and install OPNsense, a user forum for discussion and support, and a blog which covers news and updates related to OPNsense. Additionally, the website offers documentation to help users get started with using OPNsense and information on how to contribute to the OPNsense community.\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_MODEL = 'gpt-3.5-turbo'\n",
    "\n",
    "def summarize(url:str):\n",
    "  \"\"\"\n",
    "  Summarize the feed link\n",
    "  \"\"\"\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=OPENAI_API_MODEL,\n",
    "    messages=[\n",
    "      {'role': 'system', 'content': \"You are an assistant which reads and summarizes articles.\"},\n",
    "      {'role': 'user', 'content': f\"Summarize this: {url}\"}\n",
    "    ]\n",
    "  )   \n",
    "  return completion.choices[0].message.content\n",
    "\n",
    "for i, feed in enumerate(feeds):\n",
    "    print(\"#articles:\", feed['items'].__len__())\n",
    "    for j, item in enumerate(feed['items']):\n",
    "      url = item['link']\n",
    "      summary = summarize(url)\n",
    "      item['summary'] = summary\n",
    "      print(f\"article #{j}\")\n",
    "      print(url)\n",
    "      print(summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "We determine the embeddings. OpenAI recommends `text-embedding-ada-002 model`, which is cheaper, faster, etc ... This gives embeddings of dimensions 1536. We need to create an embeddings for each text block. `text-embedding-ada-002` has a max input token of 8191."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_EMBEDDINGS_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "def get_embdeddings(text: str):\n",
    "    \"\"\"\n",
    "    Get the OpenAI embeddings of the text\n",
    "    \"\"\"\n",
    "    response = openai.Embedding.create(\n",
    "            input=text,\n",
    "            model=OPENAI_EMBEDDINGS_MODEL\n",
    "        )\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings\n",
    "\n",
    "for i, feed in enumerate(feeds):\n",
    "    for j, item in enumerate(feed['items']):\n",
    "        summary = item['summary']\n",
    "        embeddings = get_embdeddings(summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector DB\n",
    "\n",
    "We store all embeddings inside a vector DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qdrant_client as qc\n",
    "import qdrant_client.http.models as qmodels\n",
    "import uuid\n",
    "\n",
    "client = qc.QdrantClient(url=\"localhost\")\n",
    "METRIC = qmodels.Distance.COSINE\n",
    "DIMENSION = 1536\n",
    "COLLECTION_NAME = \"dev_feeds\"\n",
    "\n",
    "def create_index():\n",
    "    \"\"\"\n",
    "    Create index with default parameters\n",
    "    \"\"\"\n",
    "    client.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config = qmodels.VectorParams(\n",
    "            size=DIMENSION,\n",
    "            distance=METRIC,\n",
    "        )\n",
    "    )\n",
    "\n",
    "def create_subsection_vector(\n",
    "    subsection_content,\n",
    "    section_anchor,\n",
    "    page_url,\n",
    "    doc_type\n",
    "    ):\n",
    "\n",
    "    vector = embed_text(subsection_content)\n",
    "    id = str(uuid.uuid1().int)[:32]\n",
    "    payload = {\n",
    "        \"text\": subsection_content,\n",
    "        \"url\": page_url,\n",
    "        \"section_anchor\": section_anchor,\n",
    "        \"doc_type\": doc_type,\n",
    "        \"block_type\": block_type\n",
    "    }\n",
    "    return id, vector, payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vectors to collection\n",
    "def add_doc_to_index(subsections, page_url, doc_type, block_type):\n",
    "    ids = []\n",
    "    vectors = []\n",
    "    payloads = []\n",
    "    \n",
    "    for section_anchor, section_content in subsections.items():\n",
    "        for subsection in section_content:\n",
    "            id, vector, payload = create_subsection_vector(\n",
    "                subsection,\n",
    "                section_anchor,\n",
    "                page_url,\n",
    "                doc_type,\n",
    "                block_type\n",
    "            )\n",
    "            ids.append(id)\n",
    "            vectors.append(vector)\n",
    "            payloads.append(payload)\n",
    "    \n",
    "    ## Add vectors to collection\n",
    "    client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=qmodels.Batch(\n",
    "            ids = ids,\n",
    "            vectors=vectors,\n",
    "            payloads=payloads\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a search on the index, we need to get the embeddings for the query string, and search the vector DB for the closest embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_idx(query: str):\n",
    "    \"\"\"\n",
    "    Generates a \n",
    "    \"\"\"\n",
    "    response = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vector=embed_text(query),\n",
    "        filter=None,\n",
    "        top=5,\n",
    "        params=qmodels.SearchRequestParams(\n",
    "            hnsw_ef=128,\n",
    "            hnsw_ef_search=128,\n",
    "            is_reversed_index=True,\n",
    "            is_async=False,\n",
    "            timeout=1000,\n",
    "        ),\n",
    "    )\n",
    "    return response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
